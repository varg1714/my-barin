#知识大纲 #数据库 

# 1. 数据库基础概念

## 1.1. 数据库中的键

1. 超键：唯一标记元祖的属性集
2. 候选键：超键中不包含多余的属性
3. 主键：候选键选择一个作为主键
4. 外键
5. 主属性：包含在任意一个候选键中的属性。
6. 非主属性：不在任意一个候选键中的属性。

## 1.2. 数据库范式

1. 1NF：列不可拆分
2. 2NF：每一个非主属性完全依赖于任意一个候选键。
    非主属性完全依赖候选键，不能部分依赖，否则造成数据冗余与耦合。消除非主属性对键的部分函数依赖。
    
    假设有以下关系模式：(Sno, Sdept, Sloc, Cno, Grade)，各个属性分别为：（学号，系，系住址，课程号，成绩），其中主键为 (Sno, Cno)。
    
    对于以上关系，有以下依赖：
    1.  $(Sno, Cno) \xrightarrow{\text{完全依赖}} Grade$
    2. $Sno \rightarrow Sdept$, $(Sno, Cno) \xrightarrow{\text{部分依赖}} Sdept$
    3. $Sno \rightarrow Sloc$, $(Sno, Cno) \xrightarrow{\text{部分依赖}} Sloc$
    4. $Sdept \rightarrow Sloc$, $Sno \xrightarrow{\text{传递依赖}} Sloc$
    
    若不满足 2NF，则可能会出现以下几类异常：
    - 插入异常
        由于部分依赖，所以插入的源数据中某个主属性缺失值，由于值的缺失导致该数据无法确定主键而无法插入。
    
        例如若学生未选定任何课，即 Cno 为空，此时却无法插入数据。
    - 删除异常
        由于部分依赖，所以当想删除某个主属性的数据时，会连带的将该主键的其他属性一起删除。
        
        假设学生只选了一门课，现在要删除这门课，由于该属性为主属性，所以删除该条记录的同时会连带的将其他属性也一起给删除了。
3. 3NF：每一个非主属性不能传递依赖于候选键，也不能部分依赖于候选键。即不存在这样的键 X，属性组 Y 以及非主属性 Z，使得 $X \rightarrow Y$，$Y \rightarrow Z$ 成立，且 $Y \nrightarrow X$ 。3NF 用于消除非主属性对键的传递函数依赖。
    基于以上的例子，由于 Sloc 传递依赖于 Sno，所以会出现修改复杂的问题：当需要修改 Sdept 时，还需要同步修改 Sloc，这会造成修改的复杂性。 
4. BCNF：若每一个决定因素都包含键，则满足 BCNF。即 $X \rightarrow Y$ 且 $Y \nsubseteq X$ 时 X 必含有键。
    BCNF 下，任意字段不能存在传递依赖与部分依赖。消除主属性对键对传递函数依赖。
    
    举例如下：假设关系模式 STJ (S, T, J) 中，S 表示学生，T 表示教师，J 表示课程。每一位教师只教一门课，每门课有若干个教师，某一学生选定某门课，就对应一个固定的教师。由语义可得以下的函数依赖：
    1. $(S,T) \rightarrow J$
    2. $(S,J) \rightarrow T$
    3. $T \rightarrow J$
    
    由于没有任何非主属性对键存在传递依赖或者部分依赖，因此该范式属于 3NF。但由于 T 并不是键，因此不满足 BCNF 范式。
    
    此时当更新属性 J 时，属性 T 必须做相应更新，反之亦然。

## 1.3. truncate、drop、delete 区别

1. TRUNCATE
    - TRUNCATE 用于删除表中的所有数据，但保留表结构。
    - TRUNCATE 操作不会记录在事务日志中，因此无法回滚。
    - TRUNCATE 操作比 DELETE 操作更快，因为它不会逐行删除数据，而是通过释放数据页来进行操作。
2. DROP
    - DROP 用于完全删除表，包括表结构和数据。
    - DROP 操作将被记录在事务日志中，并可以通过使用 ROLLBACK 语句进行回滚。
    - DROP 操作比 TRUNCATE 操作稍慢，因为它需要删除表的元数据和相关索引。

## 1.4. varchar (11) 与 int (11) 区别

varchar 指定存储长度，int 指定显示长度。注意 varchar 的 order by 排序时使用 fixed_length 计算 col 长度。

## 1.5. 数据库事务 ACID

## 1.6. 并发带来的问题

- 脏读
- 丢失修改
- 不可重复读
- 幻读

## 1.7. 数据库隔离级别

- Read-UnCommitted
- Read-Committed
- Repeatable-Read
	在此隔离级别下，存在 MVCC 模式。对于每一个操作，都会产生一个 undo 日志，undo 日志会和事务产生关联。因此如果一个事务非常长的话那么就会占用很大的 undo 日志空间。**Undo 日志删除的条件是没有比这个日志更早的 read-view，所以要尽量避免长事务**。
- Serializable

# 2. Mysql 基础知识

## 2.1. Mysql 常用引擎

- MyISAM，全表锁，无事务、外键，非聚集索引。
- InnoDB，行级锁，有提交回滚等事务特性。支持自增列，外键，并发强。占用空间是 MyISAM 的 2.5 倍。主键为聚集索引。
- Memory，表锁。

## 2.2. 常见语句执行过程

### 2.2.1. KILL 语句的执行过程

Kill 语句分为两个：
- `kill query` + 线程 ID
	该语句执行后，做了以下两件事情：
	1. 把 session 的运行状态改成： `THD::KILL_QUERY`，即将变量 `killed` 赋值为 `THD::KILL_QUERY`  。
	2. 给 session 的执行线程发一个信号。
- `kill connection` + 线程 ID

对于 kill，实际操作是按以下方式进行的：
1. 一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 `THD::KILL_QUERY`，才开始进入语句终止逻辑。
2. 如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处。比如 IO 阻塞的话，就不会随便被唤醒。
3. 语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。

Kill 语句执行后耗时长的原因：
- 线程没有执行到判断线程状态的逻辑
- 终止逻辑耗时长。如执行大事务期间被 kill，需要回滚所有操作，比如删除中间的临时文件之类。

### 2.2.2. JOIN 语句的执行过程

`select * from t1 straight_join t2 on (t1.a=t2.a);`，执行以上这条语句，Mysql 内部是如何处理的呢？

在决定哪个表做驱动表的时候，应该是**两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表**。

#### 2.2.2.1. 被驱动表有索引的情况

1. 从表 t1 中读入一行数据 R。
2. 从数据行 R 中，取出 a 字段到表 t2 里去查找。
3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分。
4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。

这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为 `Index Nested-Loop Join`，简称 NLJ。

#### 2.2.2.2. 被驱动表无索引的情况

由于被驱动表无索引，因此是全表扫描。所以先要从驱动表中取出一条数据，然后到被驱动表去做全表扫描判断是否匹配。假设驱动表行数为 N，被驱动表为 M，则实际扫描行数就是 N\*M。这种直接扫描的做法我们称之为 `Simple Nested-Loop Join`。

显然如果直接扫描的话，那么代价太大了。因此 Mysql 实现时对这种查询做了以下优化：
1. 把表 t1 的数据读入线程内存 `join_buffer` 中，由于我们这个语句中写的是 `select *`，因此是把整个表 t1 放入了内存。如果表数据超过 `join_buffer` 限制（默认大小为 128KB），就只会先放一批数据，等这批数据扫描完了再读取下一批数据。
2. 扫描表 t2，把表 t2 中的每一行取出来，跟 `join_buffer` 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

优化的算法我们称之为 `Block Nested-Loop Join`，简称 BNL

#### 2.2.2.3. NLJ 算法优化途径-BAK 算法

NLJ 通过索引查询被驱动表，效率对比无索引的情况已经好很多了。但是还有一个问题时驱动表往被驱动表匹配数据时还是按行匹配的，即驱动表数据有多少条，被驱动表就要扫描索引多少次。而当每次扫描的索引比较散乱时，那么性能就相对较差。

能不能有一种方式顺序扫描被驱动表的索引呢？将**被驱动表的随机读转化为顺序读**，这是我们想到的一种优化途径。由此我们引入了 `Multi-Range Read 优化 (MRR)` 这一设计。

如果**按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能并且更能利用预读缓存的优势**。这就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：
1. 根据索引 a，定位到满足条件的记录，将 id 值放入 `read_rnd_buffer` 中。
2. 将 `read_rnd_buffer` 中的 id 进行递增排序。
3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

`read_rnd_buffer` 的大小是由 `read_rnd_buffer_size` 参数控制的。如果步骤 1 中，`read_rnd_buffer` 放满了，就会先执行完步骤 2 和 3，然后清空 `read_rnd_buffer`。之后继续找索引 a 的下个记录，并继续循环。

![](https://r2.129870.xyz/img/20220515173810.png)

有了以上概念，我们就可以优化 NLJ 算法了。MySQL 在 5.6 版本后开始引入的 Batched Key Access (BKA) 算法了。这个 BKA 算法，其实就是对 NLJ 算法的优化。

基于 MRR，将驱动表的数据查询出来后放到 `join buffer` 中，然后再去被驱动表查询。这就进行了一定程度的优化。通过设置 `set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';` 来启用 BAK 算法。

> [!info] MRR 的使用
> 
> 如果你想要稳定地使用 MRR 优化的话，需要设置 `set optimizer_switch="mrr_cost_based=off"`。（官方文档的说法是现在的优化器策略判断消耗的时候，会更倾向于不使用 MRR。这里把 `mrr_cost_based` 设置为 off，就是固定使用 MRR 了。）

#### 2.2.2.4. BNL 转 BAK 算法

通过给无索引的被驱动表加索引的方式，可以将 BNL 算法优化为 BAK 算法。如果被驱动表上数据量太大不方便加索引的话，考虑将需要的数据抽取到临时表，使用临时表来查询也是一种方式。

#### 2.2.2.5. Hash Join

在上面我们发现一个问题，对于驱动表与被驱动表的匹配，匹配次数是 $驱动表行数N \times 被驱动表行数 M$。这个原因是因为驱动表的数据在内存中是一个数组，如果我们将内存中存储的方式改为哈希表，那么只需要匹配被驱动表的次数 M 就行了。

在 Mysql 老版本的方式中还不支持 Hash Join 的方式，在新版本 Mysql8.0.18 已经支持 Hash-Join。 8.0.20 版本以上官方已经移除 BNL 的支持, 全部替换成 Hash-Join。

> [!info] Hash Join
> 在执行 Hash Join 时，MySQL 首先会选择一个较小表作为驱动表（称为构建表），然后将该表的数据加载到内存中的希表中。接来，MySQL 会扫描一个较大的表（称为被驱动表），并将每一行的连接列的值与哈希表中值进行比较。如果匹配成功，则返回连接结果。


### 2.2.3. IN 语句的执行过程

对于一条 IN 语句，Mysql 会如何执行呢？
```sql
SELECT * FROM t WHERE key1 IN ('b', 'c');
```

如果优化器选择使用二级索引执行上述语句，那它是如何执行的呢？优化器会将 IN 子句中的条件看成是 2 个范围区间（虽然这两个区间中都仅仅包含一个值）：
- `['b', 'b']`
- `['c', 'c']`

那么在语句执行过程中就需要通过 `B+` 树去定位两次记录所在的位置：
1. 先定位键值在范围区间 `['b', 'b']` 的记录：
    1. 先通过 `idx_key1` 索引对应的 `B+` 树快速定位到 `key1` 列值为 `'b'`、并且最靠左的那条二级索引记录，之后回表将其发送给 server 层后再发送给客户端。
    2. 再沿着记录组成的单链表把符合 `key1=b` 的二级索引记录找到，并且回表后发送给 server 层，之后再发送给客户端。
    3. 重复上述过程，直到找到的二级索引记录的 key1 列的值不满足 `key1 = 'b'` 的这个条件为止。
2. 再定位键值在范围区间 `['c', 'c']` 的记录：

对于 IN 查询的使用，需要注意的是：
1. IN 查询中的条件 Mysql 会自动去重
2. 会将 IN 条件中的值进行排序
	**这么做的目的是防止出现死锁的情况**，如两个 IN 查询为锁定读语句，但顺序相反，若不进行排序就可能出现死锁情况。
3. IN 中数量太多时会影响[[Mysql的查询优化#1 1 2 使用索引的成本|索引评估]]，可能会走不上索引。

### 2.2.4. COUNT 语句执行过程

count 的各个区别：
- count (\*)，取出一条数据就 +1，这是 Mysql 官方的处理方式。
- count (1)，取出一条数据就 +1，这是人为操作的优化方式。
- count (field)，取出一条数据的 field 字段，若字段不为 null，则 +1，否则不加。

> [!question] 是否可以使用 `PAGE_N_RECS` 来统计数量？
> 
> InnoDB 的记录都是存储在数据页中的（页面大小默认为 16KB），而每个数据页的 [[Mysql的存储结构#3 4 Page Header（页面头部）|Page Header]] 部分都有一个统计当前页面中记录数量的属性 `PAGE_N_RECS`。这个属性不能用于直接统计数量，**对于普通的 SELECT 语句，每次查询都要从记录的版本链上找到可见的版本才算是读到了记录；对于加了 FOR UPDATE 或 LOCK IN SHARE MODE 后缀的 SELECT 语句，每次查询都要给记录添加合适的锁**。所以这个读取每一条记录的过程在 InnoDB 的目前实现中是无法跳过的。

### 2.2.5. LIMIT 的执行过程

MySQL 内部其实是分为 server 层和存储引擎层的：
- server 层负责处理一些通用的事情，诸如连接管理、SQL 语法解析、分析执行计划之类
- 存储引擎层负责具体的数据存储，诸如数据是存储到文件上还是内存里，具体的存储格式之类

MySQL 中一条 SQL 语句的执行是通过 server 层和存储引擎层的多次交互才能得到最终结果的。

MySQL 是在 server 层准备向客户端发送记录的时候才会去处理 LIMIT 子句中的内容：

```sql
SELECT * FROM t ORDER BY key1 LIMIT 5000, 1;
```

如果使用 idx_key1 执行上述查询：
1. server 层向 InnoDB 层要第 1 条记录，InnoDB 从 idx_key1 中获取到第一条二级索引记录，然后进行回表操作得到完整的聚簇索引记录，然后返回给 server 层
2. server 层发现不满足 limit 的条件，重复获取数据直到满足 limit 条件

由于是在实际向客户端发送记录前才会去判断 LIMIT 子句是否符合要求，所以如果使用二级索引执行上述查询意味着要进行 5001 次回表操作。server 层在进行执行计划分析的时候会觉得执行这么多次回表的成本太大了，还不如直接全表扫描+filesort 快呢，所以就选择了后者执行查询。

由于 MySQL 实现 LIMIT 子句的局限性，在处理诸如 `LIMIT 5000, 1` 这样的语句时就无法通过使用二级索引来加快查询速度了么？其实也不是，只要把上述语句改写成：

```sql
SELECT * FROM t, (SELECT id FROM t ORDER BY key1 LIMIT 5000, 1) AS d
    WHERE t.id = d.id;
```

这样，`SELECT id FROM t ORDER BY key1 LIMIT 5000, 1` 作为一个子查询单独存在，由于该子查询的查询列表只有一个 `id` 列，MySQL 可以通过仅扫描二级索引 idx_key1 执行该子查询，然后再根据子查询中获得到的主键值去表 t 中进行查找。这样就省去了前 5000 条记录的回表操作，从而大大提升了查询效率！

> [!note] Limit 的机制
> 
> 其实 limit 只能逐行访问的原因是数据存储是以类似链表形式存储的，读取数据过程中不断加载磁盘页的数据，所以只能提供 `O(n)` 时间复杂度的访问。


## 2.3. 临时表

### 2.3.1. 临时表概念

通过 `create temporary table` 来创建临时表，临时表有以下特性：
- 一个临时表只能被创建它的 session 访问，对其他线程不可见。在 session 结束的时候临时表自动删除。
- 临时表可以与普通表同名。
- session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。
- show tables 命令不显示临时表。
- 临时表的表名存储为临时文件目录下，文件名的后缀是 `.frm`，前缀是 `#sql {进程 id}_{线程 id}_ 序列号`，这就可以使同一个表名达到复用的效果。这个进程 id 也会写入 binlog 日志，方便备注重放日志时可以获取到 id 进行表的建立。
- **当 binlog 日志格式设置为 statement 时，临时表的操作语句会同步到备库。而设置为 row 格式时，不会同步。因为 row 格式避免了对临时表的数据依赖，而 statement 无法避免**。

临时表与内存表的区别：
- 内存表：是使用 Memory 引擎的表，建表语法是 `create table … engine=memory`。
- 内存表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。

### 2.3.2. 临时表处理分库查询问题

由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。

例如语句 `select v from ht where k >= M order by t_modified desc limit 100;` 通过 proxy 层无法很好的实现查询的需求，因此一种做法可以是从多个分库中查到数据汇聚到一个临时表中，然后利用生成的临时表执行该语句。

![](https://r2.129870.xyz/img/20220515194528.png)

## 2.4. 内存表

### 2.4.1. 内存表出现的原因

- 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果。
- `join_buffer` 是无序数组，`sort_buffer` 是有序数组，临时表是二维表结构。
- 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如 union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。

### 2.4.2. 内存表出现的场景

- 使用 union 操作，会生成一个临时表。表中存放 union 的结果，将插入的数据作为主键判断是否重复达到去重的效果。如果是使用 union all 操作，就不会生成临时表了。
- 使用 dintinct 操作，也会生成临时表，利用唯一键的特性去重。
- 使用 group by 操作，若 group by 中途需要临时存储数据，则会用到临时表。如 `select id%10 as m, count(*) as c from t1 group by m order by null;` 语句需要临时表来存储 id%10 的结果。

	像上面这条 sql，可以采用新增一列存储数据来避免临时表的生成。如 `alter table t1 add column z int generated always as(id % 100), add index(z);` 来实现数据的级联更新。这样统计时直接走到索引上去就不会生成临时表了。
	
	直接使用排序来代替临时表的生成，`select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;` 来告诉优化器，直接使用磁盘临时表来进行排序。该语句将会按以下策略执行：
	1. 初始化 `sort_buffer`，确定放入一个整型字段，记为 m。
	2. 扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中。
	3. 扫描完成后，对 `sort_buffer` 的字段 m 做排序（如果 `sort_buffer` 内存不够用，就会利用磁盘临时文件辅助排序）。
	4. 排序完成后，就得到了一个有序数组。
	5. 根据数组统计结果

### 2.4.3. 内存的组织结构

![](https://r2.129870.xyz/img/20220515215434.png)

内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。

可见，InnoDB 和 Memory 引擎的数据组织方式是不同的：
- InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为**索引组织表（Index Organizied Table）**。
- Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为**堆组织表（Heap Organizied Table）**。
- InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的。
- 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值。
- 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引。
- InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
- InnoDB 支持变长数据类型，不同记录的长度可能不同。
- 内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar (N)，实际也当作 char (N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

内存表的特性：
- 除了 hash 索引，也可以使用 B-tree 索引。
- 锁的粒度是表锁。
- 数据在内存中，不能持久化。
- 主从之间数据会丢失，从库重启后数据就没了。互为主备的数据库，备库重启后也会产生删除数据的 binlog 日志传给主库。
- 内存表不支持事务。
- 如果从 `MEMORY` 表中删除单独的行，则不会回收内存。只有当整个表被删除时才会回收内存。

> [!note] 临时表与内存表
> 
> 注意内存表和临时表的概念，临时表使用 `temporary`，用于表示这个表是临时的，是 session 独占的。而内存表是使用 `engine=memory`，数据存放到内存中，这是两个概念。这两者也可以结合使用，如：`create temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;`

> [!warning] [内存表的复制](https://dev.mysql.com/doc/refman/8.0/en/replication-features-memory.html)
> 
> 当复制源服务器关闭并重新启动时，其 `MEMORY` 表将变空。为了将此效果复制到副本，源在启动后第一次使用给定的 `MEMORY` 表时，会记录一个事件，通知副本必须通过将该表的 `DELETE` 或（从 MySQL 8.0.22 开始） `TRUNCATE TABLE` 语句写入二进制日志来清空该表。生成的事件可以通过二进制日志中的注释来识别，并且如果服务器上正在使用 GTID，则它会分配一个 GTID。即使二进制日志记录格式设置为 `ROW` ，该语句也始终以语句格式记录，并且即使在服务器上设置 `read_only` 或 `super_read_only` 模式，也会写入该语句。
> 
> 请注意，在源重新启动和首次使用表之间的时间间隔内，副本的 `MEMORY` 表中仍然有过时的数据。为了避免在对副本的直接查询可能返回过时数据时出现此间隔，您可以设置 `init_file` 系统变量来命名一个文件，该文件包含在启动时填充源上的 `MEMORY` 表的语句。
> 
> 当副本服务器关闭并重新启动时，其 `MEMORY` 表将变空。这会导致副本与源不同步，并可能导致其他故障或导致副本停止。副本还会将 `DELETE` 或（从 MySQL 8.0.22 开始） `TRUNCATE TABLE` 语句写入其自己的二进制日志，该语句会传递到任何下游副本，导致它们清空自己的 `MEMORY` 表。
> 
> 重新启动正在复制 `MEMORY` 表的副本的安全方法是首先删除或删除源上 `MEMORY` 表中的所有行，然后等待这些更改已复制到副本。然后就可以安全地重新启动副本了。

## 2.5. 主键自增规则

通过 `show create table 't';` 能查询到关于表结构的信息，同时还有一个字段是 `AUTO_INCREMENT='number'`，这个值就是下一次自增应当生成的数据主键值，那么这个值是如何生成与存储的呢？

### 2.5.1. 自增值的存储

表的结构定义放在 `.frm` 文件中，但是不会保存自增值。各个引擎对自增值有不同的保存策略：
- MyISAM 引擎保存在数据文件中。
- InnoDB 存储引擎保存在内存中，到 Mysql8.0 版本以后才有了自增值持久化保存的能力。
	- 对于 MySQL5.7 及以前的版本：自增值保存在内存，重启后通过 `max(id)` 计算下一个自增值。这意味着重启后计算的自增值可能与当前不同。
	- 对于 8.0 版本，自增值记录在了 redolog 中，重启依靠 redolog 恢复。

### 2.5.2. 自增值修改

对于一条新数据的插入，执行以下步骤
- 插入数据未指定主键值，使用当前自增值，使用完后自增值自增。
- 指定主键值，直接使用给定值。插入后判断主键值与子增值关系，若主键值>自增值，则自增值更新新的自增值。

自增值生成算法是：从 `auto_increment_offset` 开始，以 `auto_increment_increment` 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。其中，`auto_increment_offset` 和 `auto_increment_increment` 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。

在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 `auto_increment_increment=2`，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突。

### 2.5.3. 自增值不连续的场景

什么时候会出现数据库中自增主键不连续的情况呢？

- 人为修改数据
    手动删除/更改了中间数据。
- 已分配但后续被回滚
    1. 插入数据时例如唯一键冲突，导致分配的自增值插入失败，但自增值已被改变。
    2. 事务回滚。
- 分配多了
    1. 使用类似于 `insert table t1 select t2` 的场景，因为不确定插入的数据量，因此 MySQL 插入时申请的主键值时按 2 的幂次方申请的，这就可能造成申请的数据用不完浪费的情况。
    2. 执行混合插入的语句：如 `INSERT INTO t1 (c1,c2) VALUES (1,'a'), (NULL,'b'), (101,'c'), (NULL,'d');`，其中 `c1` 列为自增列。此时不确定插入数据量，会导致多分配。

### 2.5.4. 自增值不能回退的原因

上面提到了如事务回滚，插入冲突时自增值不会回退的现象。这样做的原因时为了解决以下问题：
- 如果允许回退，则需要做到多事务之间的自增值控制，这个锁的粒度大影响性能。
- 在回滚的前提下，避免多个事务之间申请到同一个自增值。要实现这个代价高。

### 2.5.5. 自增锁的优化

自增锁是申请完即释放的，但这个规则其实是可以配置的。从 MySQL 8.0 开始，交错锁模式 ( `innodb_autoinc_lock_mode=2` ) 是默认设置。在 MySQL 8.0 之前，连续锁定模式是默认的（ `innodb_autoinc_lock_mode=1` ），MySQL 8.0 中**交错锁模式的默认设置反映了默认复制类型从基于语句的复制到基于行的复制的变化**。
- 设置为 0 ：传统模式
    表示采用之前 MySQL 5.0 版本的策略，语句执行结束后才释放锁。对于普通的插入以及未确定数量的批量插入（如 `insert ... select`）都需要获取表级锁来生成自增值。
- 设置为 1 ：连续模式
    类似 `insert ... select` 这样的批量插入数据的语句，需要获取表级锁，等语句结束后才被释放；普通 insert 语句，使用的是内存级别的轻量级锁（在表级锁未被其他线程持有的情况下），自增锁在申请之后就马上释放。
- 设置为 2 ：交错模式
    所有的申请自增主键的动作都是申请后就释放锁，在这种模式下类似 `insert ... select` 这样的批量插入数据的语句的自增值可能并不连续，在并发的情况下会交错生成。

    **当使用此模式时，binlog 格式必须要设置成 row**。否则可能会出现 `insert … select` 这个语句日志重放效果与执行效果不一致的现象。如原本事务 A 在执行 `insert … select` 期间，事务 B 插入了一条数据。若事务 A 在插入数据之后又申请了主键值，则事务 A 的主键值是不连续的。但这个操作对于使用 statement 格式的日志，重放 binlog 日志是还原不回来的。

## 2.6. Mysql 授权语句

![](https://r2.129870.xyz/img/20220516124736.png)

授权语句的变化情况如上所示，注意，在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 ua@ip1 和 ua@ip2 代表的是两个不同的用户。

`flush privileges` 使用场景：当未通过授权语句 grant 或者 revoke 进行授权，而直接更改了授权表的数据时，需要手动刷新授权数据。当然不建议直接更改数据库当数据！

## 2.7. Mysql 分区表

创建表的时候可以使用 `PARTITION BY RANGE (YEAR(ftime))` 来让 Mysql 根据字段创建分区表。如以下 SQL 语句：
```sql
CREATE TABLE `t` (
  `ftime` datetime NOT NULL,
  `c` int(11) DEFAULT NULL,
  KEY (`ftime`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1
PARTITION BY RANGE (YEAR(ftime))
(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
 PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
 PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);

insert into t values('2017-4-1',1),('2018-4-1',1);
```

分区表的特性：
- 分区表对引擎层是多张表，对 server 层是一张表。
- 分区表对行加锁时只会在引擎层涉及到的数据进行加锁，不会锁住全部的分区表。
- 分区表加表加锁时是持有的整个表的 MDL 锁，因为对于 server 层来说只有一张表。
- MySQL 在第一次打开分区表的时候，需要访问所有的分区。

分区表的应用场景：
- 分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。
- 可以直接通过 `alter table t drop partition ...` 这个语法删掉分区，从而删掉过期的历史数据。
- 除范围分区外，MySQL 还支持 hash 分区、list 分区等分区方法。

## 2.8. Mysql 中的那些 ID

- 表自增值 ID，自增值 ID 从 1 开始，最大值为定义整数的最大值。当达到最大值时，再次插入相同的值就会报错。
- 系统自增 `row_id`，当未指定主键值时，就会生成一个隐式的 row_id。
    InnoDB 维护了一个全局的 `dict_sys.row_id` 值，用于分配给无主键的表，这也是自增的。长度为 6 字节无符号整数。
    
    当超过这个值时，会从 0 开始重新循环分配。而且对于重复的数据会覆盖数据，不会报出键重复错误。
- XID，redo log 日志与 binlog 日志关联的 ID。Mysql 维护了一个全局的 `global_query_id`，执行语句时将其赋值给 `Query_id`。
	- 若当前语句是事务的第一条语句，就会把这个 ID 分配给当前事务。
	- global_query_id 是一个纯内存变量，重启之后就清零了。所以 XID 是会重复的，但重启后 binlog 日志也会重新生成，因此对于同一个 binlog 日志，理论上不会重复。
	- 同一个 binlog 日志中重复出现的情况是事务已经执行了 $2^{64}-1$ 次，然后从 0 开始重新循环生成。
- `Innodb trx_id`，用于记录事务的 ID。
	- InnoDB 内部维护了一个 `max_trx_id` 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。
	- update 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1，因此在一个事务中至少加 2。
	- 当未真正开始事务时，这个值计算规则为：把当前事务的 trx 变量的指针地址转成整数，再加上 $2^{48}$。
	- max_trx_id 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个 MySQL 服务跑得足够久，就可能出现 max_trx_id 达到 $2^{48}-1$ 的上限，然后从 0 开始的情况。这就会引起脏读的出现。但这个需要的事务量和时间非常大。
	- 只读事务不分配事务 ID
		- 第一点是为了减少活跃事务的数量，例如 MVCC 视图就不用判断那么多的事务。
		- 减少 trx_id 的申请次数。

- ThreadId，当前执行线程 id，4 字节。保存在内存中，每次递增。

## 2.9. binlog 使用 row 格式的因素

- row 格式避免同步数据错误，statement 格式受事务提交顺序影响大。
- 在使用临时表时 row 格式无需同步临时表操作到备库，statement 格式需要。因为 row 格式避免了对临时表的数据依赖，而 statement 无法避免。
- 使用 row 格式，无需担心 `insert...select` 这种语句的主键申请问题。
- 对于主从备份，采用 binlog 格式可以尽早发现备库与主库的数据不一致问题（在主备切换策略采取的是[[数据库/Mysql大纲#7 3 2 可用性优先策略|可用性优先策略]]下）。

## 2.10. OnlineDDL

### 2.10.1. OnlineDDL 的原理

在 MySQL 的早期版本中，DDL 操作因为锁表会和 DML 操作发生锁冲突，大大降低并发性。在早期版本中，大部分 DDL 操作的执行原理就是通过重建表的方式，因为要复制原表数据，所以会长时间锁表，只能读不能写，DDL 操作和 DML 操作有很严重的冲突。从 MySQL5.6 开始，很多 DDL 操作过程都进行了改进，出现了 Online DDL，用于支持 DDL 执行期间 DML 语句的并行操作，提高数据库的吞吐量。

MySQL 在线 DDL 分为 `INPLACE` 和 `COPY` 两种方式，通过在 ALTER 语句的 ALGORITHM 参数指定：
-   `ALGORITHM=INPLACE`，可以避免重建表带来的 IO 和 CPU 消耗，保证 ddl 期间依然有良好的性能和并发。
-   `ALGORITHM=COPY`，需要拷贝原始表所以不允许并发 DML 写操作，可读。由于需要记录 undo 和 redo log 因此性能不如 INPLACE 的方式，而且因为临时占用 buffer pool 引起短时间内性能受影响。

上面只是 Online DDL 内部的实现方式，此外还有 LOCK 选项控制是否锁表，根据不同的 DDL 操作类型有不同的表现：默认 MySQL 尽可能不去锁表，但是像修改主键这样的昂贵操作不得不选择锁表：
-   `LOCK=NONE`，即 DDL 期间允许并发读写涉及的表，比如为了保证 ALTER TABLE 时不影响用户注册或支付，可以明确指定。好处是如果不幸该 alter 语句不支持对该表的继续写入则会提示失败，而不会直接发到库上执行。
-   `LOCK=SHARED`，即 DDL 期间表上的写操作会被阻塞，但不影响读取。
-   `LOCK=DEFAULT`，让 mysql 自己去判断 lock 的模式，原则是 mysql 尽可能不去锁表。
-   `LOCK=EXCLUSIVE`，即 DDL 期间该表不可用，堵塞任何读写请求。如果你想 alter 操作在最短的时间内完成，或者能接受短时间表内不可用，可以手动指定该策略。

但是有一点需要说明，**无论任何模式下，Online DDL 开始之前都需要一个短时间排它锁 (exclusive) 来准备环境**。所以 alter 命令发出后，会首先等待该表上的其它操作完成，在 alter 命令之后的请求会出现等待 `waiting meta data lock`。同样在 DDL 结束之前，也要等待 alter 期间所有的事务完成，也会堵塞一小段时间。所以尽量在 ALTER TABLE 之前确保没有大事务在执行，否则一样出现连环锁表。

| 操作                                | 支持方式       | Allow R/W      | 说明                                                                      |
| --------------------------------- | ---------- | -------------- | ----------------------------------------------------------------------- |
| add/create index                  | online     | 允许读写           | 当表上有 FULLTEXT 索引除外，需要锁表，阻塞写                                             |
| drop index                        | online     | 允许读写           | 操作元数据，不涉及表数据。所以很快，可以放心操作                                                |
| optimize table                    | online     | 允许读写           | 当带有 fulltext index 的表用 copy table 方式并且阻塞写                               |
| alter table... engine=innodb      | online     | 允许读写           | 当带有 fulltext index 的表用 copy table 方式并且阻塞写                               |
| add column                        | online     | 允许读写 (增加自增列除外) | 1、添加 auto_increment 列要锁表，阻塞写; 2、虽采用 online 方式，但是表数据需要重新组织，所以增加列依然是昂贵的操作 |
| drop column                       | online     | 允许读写 (增加自增列除外) | 同 add column，重新组织表数据，昂贵的操作                                              |
| Rename a column                   | online     | 允许读写           | 操作元数据; 不能改列的类型，否则就锁表                                                    |
| Reorder columns                   | online     | 允许读写           | 重新组织表数据，昂贵的操作                                                           |
| Make column NOT NULL              | online     | 允许读写           | 重新组织表数据，昂贵的操作                                                           |
| Change data type of column        | copy table | 仅支持读，阻塞写       | 创建临时表，复制表数据，昂贵的操作                                                       |
| Set default value for a column    | online     | 允许读写           | 操作元数据，因为 default value 存储在 frm 文件中，不涉及表数据。所以很快，可以放心操作                   |
| alter table xxx auto_increment=xx | online     | 允许读写           | 操作元数据，不涉及表数据。所以很快，可以放心操作                                                |
| Add primary key                   | online     | 允许读写           | 昂贵的操作                                                                   |
| Convert character set             | copy table | 仅支持读，阻塞写       | 如果新字符集不同，需要重建表，昂贵的操作                                                    |

### 2.10.2. OnlineDDL 的过程

OnlieDDL 执行过程：
1. 拿 MDL 写锁
2. 降级成 MDL 读锁
3. 真正做 DDL，这里不会阻塞读写操作。对于这段期间的数据库操作，会存放到临时日志文件中。
4. 升级成 MDL 写锁，并重放 DDL 期间产生的数据变更命令。
5. 释放 MDL 锁

在获取或者升级 MDL 写锁的过程中，如果其他事务持有 MDL 读锁并长期未释放的话，则写锁获取过程可能会耗时很长。同时测试发现，**DDL 语句是不受事务控制的**，无法采用 begin/rollback 控制语句的执行过程。

### 2.10.3. gh-ost 方案

**gh-ost**（GitHub Online Schema Migration）是 GitHub 开源的一款工具，用于在 MySQL 中**无锁执行在线表结构变更**（如修改列、添加索引等），避免传统 `ALTER TABLE` 操作导致的锁表问题。

为什么需要 gh-ost：

- **传统在线 DDL 的局限性**：  
    MySQL 原生的 `ALTER TABLE` 可能锁表（尤其全表重建操作），导致业务阻塞。具体来说并不是任意类型的 DDL 操作都能利用上 inplace 的特性，并且 OnlineDDL 操作开始和结束时需要获取 MDL 写锁，这个过程同样可能导致阻塞。
- **gh-ost 的优势**：
    - **无锁迁移**：通过复制数据到影子表（ghost 表），避免直接修改原表。
    - **可控制性**：支持暂停、回滚、动态调整迁移速度。
    - **低延迟**：减少对业务写入的影响。

 gh-ost 的工作原理：

1. **创建影子表**：  
    新建一个与原表结构一致的空表（例如 `_mytable_gho`），并应用目标 DDL（如添加索引）。
2. **增量数据同步**：
    - 通过解析 MySQL 的 binlog，捕获原表的写入操作（INSERT/UPDATE/DELETE）。
    - 将这些操作同步应用到影子表。
3. **数据迁移**：
    - 分批将原表数据复制到影子表。
    - 最终确保影子表数据与原表完全一致。
4. **原子切换**：
    - 通过 `RENAME TABLE` 将原表重命名为备份表（例如 `_mytable_del`），同时将影子表更名为原表名。
    - 切换过程在毫秒级完成，业务几乎无感知。

使用 gh-ost 的典型场景：

- **添加/删除索引**：避免锁表导致查询阻塞。
- **修改列类型**：如将 `VARCHAR(100)` 改为 `VARCHAR(200)`。
- **分库分表前的结构变更**：为数据迁移做准备。

注意事项：

- **主从架构**：建议在从库上执行迁移，再切换主从角色。
- **外键约束**：gh-ost 不支持有外键关联的表。
- **触发器**：需禁用原表的触发器，避免重复执行。
- **性能监控**：关注复制延迟和服务器负载。

# 3. Mysql 索引

## 3.1. 索引类型

### 3.1.1. Mysql 常见索引分类

- [[Mysql的存储结构#4 3 聚簇索引|聚簇索引]]，Mysql 会自动将主键索引放到其他索引的后面
- 联合索引
	- 联合索引的最左匹配原则，从左边开始的字段能走上索引，遇到范围查询 (>,<, between, like 停止)
	- 若 (a, b) 为联合索引，查询条件 b = xx and a = xx 也能走上索引，引擎会自动优化。
- 前缀索引
    Mysql 支持指定字符串或二进制的前 n 位构建索引。当前缀区分度不高时，可以考虑使用后缀，即 reverse (field) 代替。或者新加一个字段，这个字段调用 crc32 () 这样的 hash 函数进行拓展字段建立。需要注意的时候**当使用了前缀索引后就无法使用到覆盖索引这个特性了，因为数据库就无法判断该索引上是否包含完整的值因此需要回表判断。**
- 唯一索引
- 普通索引：如果没有特别要求，索引尽量选择普通索引。普通索引可以使用 **[[Mysql的存储结构#6.4. ChangeBuffer 的使用|ChangeBuffer]] 进行缓冲**，从而改善性能。

### 3.1.2. 普通索引和唯一索引查询的区别

唯一索引：
- 查询时通过 B+树查找，找到第一个满足条件的记录后就停止检索。
- 更新时首先判断内存中是否有该数据，有的话就直接更新，否则需要加载到内存中然后更新。

普通索引：
- 查询时通过 B+树查找，找到满足条件的数据后还要判断下一条数据是否满足条件。大部分情况下这两条数据都在同一个页中，因此这个多出来的判断时间其实很小。但当下一条数据不在同一页，正好分页的时候，就需要多一次磁盘 IO 操作将其加载到页中了。当然这种情况比较少。
- 更新时如果发现内存中有该数据，则直接更新内存。**内存中没有的话就在 ChangeBuffer 中记录该更新操作然后返回**。所以这个会比唯一索引的操作快很多。
    ChangeBuffer 记录仅针对二级索引有效，**因为主键索引和唯一索引需要确定唯一性，所以就必须要把数据页加载到内存中进行检查**。当操作的二级索引不在内存中时就会缓存下来。等到下次读取该页时就与 ChangeBuffer 合并。

## 3.2. 索引特性

### 3.2.1. 索引覆盖

在联合索引上就有待查询待全部字段无需回表。

### 3.2.2. 索引下推

有些搜索条件中虽然出现了索引列，但却并不能用来形成范围区间，也就是不能被用来减少需要扫描的记录数量，比如下边这个查询：

```sql
SELECT * FROM s1 WHERE key1 > 'z' AND key1 LIKE '%a';
```

其中的 `key1 > 'z'` 可以用来形成范围区间，但是 `key1 LIKE '%a'` 却不能。`server` 层生成执行计划后，按照以下步骤来执行查询：

1. server 层首先调用存储引擎的接口定位到满足 `key1 > 'z'` 的第一条记录。
2. 存储引擎根据 `B+` 树索引快速定位到该条二级索引记录后，根据该二级索引记录的主键值进行回表操作，将完整的用户记录返回给 `server` 层。
3. `server层` 再判断其他的搜索条件是否成立，如果成立则将其发送给客户端，否则的话跳过该记录，然后向存储引擎层要下一条记录。
4. 由于每条记录都有一个 `next_record` 的属性，根据该属性可以快速定位到符合 `key1 > 'z'` 条件的下一条二级索引记录，再执行回表操作，将完整的用户记录返回给 `server层`，然后重复上一步骤，直到将索引 `idx_key1` 的范围区间 `('z', +∞)` 的所有记录都扫描过为止。

虽然 `key1 LIKE '%a'` 不能被用于组成范围区间来减少需要被扫描的二级索引记录数量，但这个搜索条件毕竟只涉及到了 `key1` 列，而 `key1` 列是包含在索引 `idx_key1` 中的。所以可以进行以下优化：

1. `server` 层首先调用存储引擎的接口定位到满足 `key1 > 'z'` 的第一条记录。
2. 存储引擎根据 `B+` 树索引快速定位到该条二级索引记录后，先判断一下所有关于 `idx_key1` 索引的条件是否成立，也就是 `key1 > 'z' AND key1 LIKE '%a'` 是否成立，如果这些条件不成立，则直接跳过该二级索引记录，然后去找下一条二级索引记录；如果这些条件成立，则执行回表操作，将完整的用户记录返回给 `server层`。
3. `server层` 再判断其他的搜索条件是否成立（本例中没有其他的搜索条件了），如果成立则将其发送给客户端，否则的话跳过该记录，然后向存储引擎层要下一条记录。
4. 由于每条记录都有一个 `next_record` 的属性，然后重复上一步骤，直到将索引 `idx_key1` 的范围区间 `('z', +∞)` 的所有记录都扫描过为止。

利用以上特性可以节省回表操作的成本，这个改进称之为 `索引条件下推`（`Index Condition Pushdown`）。

## 3.3. 索引优化

### 3.3.1. 索引重建

目的：索引可能因为删除，页分裂等原因造成数据空洞。重建索引会创建新的索引，使页面利用率最高。索引更紧凑，更省空间。

- 重建非主键索引
	`drop index`
- 重建主键索引
	避免使用 `drop primary key`，因为这个会先删除旧的主键索引，然后 innodb 又自己使用了一个临时主键索引，最后又自己指定了主键索引，导致主键重构两次。可以用 `alter table T engine=InnoDB` 代替。

	`alter table T engine=InnoDB` 是一个重建表的操作，会基于原来的表 inplcae 一个新的表出来。过程是 Online 的，在语句执行的时候会先获取 MDL 的写锁，之后会退化成读锁，避免阻塞增删改查。
	
	`analyze table t` 是一个重建表“索引数据评估情况”的操作。
	
	`optimize table t` 等于 recreate + analyze。
- 索引评估
	数据库评估索引的扫描行数是基于采样分析的，可能不准确。可以使用 `analyze table t` 来使数据库对索引情况进行重新评估，从而使扫描行数变准确。
- 自适应哈希索引
    自适应哈希索引是 MySQL InnoDB 存储引擎中的一个特性，它能够自动地为经常访问的数据页建立哈希索引，从而加速数据查询过程。其核心思想是根据某个检索条件，直接查询到对应的数据页，跳过逐层定位数据页的步骤
    
    工作原理：
    
    1. InnoDB 监控对表的查询模式
    2. 当检测到对某个索引页的访问频率达到阈值时，会建立哈希索引
    3. 哈希索引使用索引键的前缀作为哈希表的键
    4. 在内存中维护这个哈希表，指向对应的 B+树索引页
    
    使用条件：
    
    -  索引树要被使用足够多次
    -  索引树上的某个检索条件被使用足够多次
    -  索引树上的某个数据页要被使用足够多次

## 3.4. 索引的代价

-   空间上的代价
    每建立一个索引都要建立一棵 `B+` 树，每一棵 `B+` 树的每一个节点都是一个数据页，一个页默认会占用 `16KB` 的存储空间。
-   时间上的代价
    每次对表中的数据进行增、删、改操作时，都需要去修改各个 `B+` 树索引。增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，页面分裂、页面回收等操作来维护节点和记录的排序。

## 3.5. 索引的访问类型

- `system`
	当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的（比如 MyISAM、Memory），那么对该表的访问方法就是 `system`。
- `const`
	通过主键或者唯一二级索引列与常数的等值比较来定位一条记录的访问方法定义为：`const`，意思是常数级别的，代价是可以忽略不计的。

	![](https://r2.129870.xyz/img/202209080844435.png)
- `eq_ref`
	在 const 的基础上，在连接查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：`eq_ref`。
- `ref`
	二级索引列与常数等值比较，采用二级索引来执行查询的访问方法称为：`ref`。由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，也就是说使用二级索引来执行查询的代价取决于等值匹配到的二级索引记录条数。

	![](https://r2.129870.xyz/img/202209080845837.png)
	- 二级索引值为 null 的情况
		**不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含 `NULL` 值的数量并不限制**，所以我们采用 `key IS NULL` 这种形式的搜索条件最多只能使用 `ref` 的访问方法，而不是 `const` 的访问方法。
	- 联合索引左边连续列是常数的等值比较
		对于某个包含多个索引列的二级索引来说，只要是最左边的连续索引列是与常数的等值比较就可能采用 `ref` 的访问方法，比方说下边这几个查询。
		
		```sql
		SELECT * FROM single_table WHERE key_part1 = 'god like'; 
		SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 = 'legendary'; 
		SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 = 'legendary' AND key_part3 = 'penta kill';
		```

		但是如果最左边的连续索引列并不全部是等值比较的话，它的访问方法就不能称为 `ref` 了，比方说这样：

		```sql
		SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 > 'legendary';
		```

- `ref_or_null`
    有时候我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为 `NULL` 的记录也找出来，就像下边这个查询：
    
    ```sql
    SELECT * FROM single_table WHERE key1 = 'abc' OR key1 IS NULL;
    ```

    当使用二级索引而不是全表扫描的方式执行该查询时，这种类型的查询使用的访问方法就称为 `ref_or_null`，这个 `ref_or_null` 访问方法的执行过程如下：
    
    ![](https://r2.129870.xyz/img/202209080849362.png)
- `range`
    上面介绍的几种访问方法都是在对索引列与某一个常数进行等值比较的时候才可能使用到（`ref_or_null` 比较奇特，还计算了值为 `NULL` 的情况），但是有时候我们面对的搜索条件更复杂，比如下边这个查询：
    ```sql
    SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 >= 38 AND key2 <= 79);
    ```

    此时的搜索条件就不只是要求索引列与常数的等值匹配了，而是索引列需要匹配某个或某些范围的值，在本查询中 `key2` 列的值只要匹配下列 3 个范围中的任何一个就算是匹配成功了：
	- `key2` 的值是 `1438`
	- `key2` 的值是 `6328`
	- `key2` 的值在 `38` 和 `79` 之间。
    
    这种利用索引进行范围匹配的访问方法称之为：`range`。
    
    也就是从数学的角度看，每一个所谓的范围都是数轴上的一个 `区间`，3 个范围也就对应着 3 个区间：
	- 范围 1：`key2 = 1438`
	- 范围 2：`key2 = 6328`
	- 范围 3：$key2 \in [38, 79]$，注意这里是闭区间。
    
    我们可以把那种索引列等值匹配的情况称之为 `单点区间`，上边所说的 `范围1` 和 `范围2` 都可以被称为单点区间，像 `范围3` 这种的我们可以称为连续范围区间。
- `index`
    看下边这个查询：
    
    ```sql
    SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = 'abc';
    ```

    由于 `key_part2` 并不是联合索引 `idx_key_part` 最左索引列，所以我们无法使用 `ref` 或者 `range` 访问方法来执行这个语句。但是这个查询符合下边这两个条件：
	- 它的查询列表只有 3 个列：`key_part1`, `key_part2`, `key_part3`，而索引 `idx_key_part` 又包含这三个列。
	- 搜索条件中只有 `key_part2` 列。这个列也包含在索引 `idx_key_part` 中。
 
    也就是说我们可以直接通过遍历 `idx_key_part` 索引的叶子节点的记录来比较 `key_part2 = 'abc'` 这个条件是否成立，把匹配成功的二级索引记录的 `key_part1`, `key_part2`, `key_part3` 列的值直接加到结果集中就行了。
    
    由于二级索引记录比聚簇索记录小的多（聚簇索引记录要存储所有用户定义的列以及所谓的隐藏列，而二级索引记录只需要存放索引列和主键），而且这个过程也不用进行回表操作，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多，设计 `MySQL` 的大叔就把这种采用遍历二级索引记录的执行方式称之为：`index`。

- `index_merge`
    一般情况下对于某个表的查询只能使用到一个索引，但在某些场景下可以使用 `Intersection`、`Union`、`Sort-Union` 这三种[[Mysql大纲#3.7. 索引合并|索引合并]]的方式来执行查询。
- `unique_subquery`
    类似于两表连接中被驱动表的 `eq_ref` 访问方法，`unique_subquery` 是针对在一些包含 `IN` 子查询的查询语句中，如果查询优化器决定将 `IN` 子查询[[Mysql的查询优化#3 4 派生表查询优化|转换为 EXISTS 子查询]]，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的 `type` 列的值就是 `unique_subquery`。
- `index_subquery`
    `index_subquery` 与 `unique_subquery` 类似，只不过访问子查询中的表时使用的是普通的索引。
- `all`
    最直接的查询执行方式就是我们已经提了无数遍的全表扫描，对于 `InnoDB` 表来说也就是直接扫描聚簇索引，设计 `MySQL` 的大叔把这种使用全表扫描执行查询的方式称之为：`all`。

## 3.6. 索引使用条件分析

假设针对表建有索引 `key1`，`key2`，那么以下语句能否走上索引呢？如果能走上索引，那么索引的使用的是哪些条件呢？
- `SELECT * FROM single_table WHERE key2 > 100 AND common_field = 'abc';`
	由于 common_field 字段上无索引，所以该语句就可以简化成 `SELECT * FROM single_table WHERE key2 > 100 AND TRUE`，所以该查询可以走上 key1 的索引。
- `SELECT * FROM single_table WHERE key2 > 100 OR common_field = 'abc';`
	该语句就可以简化成 `SELECT * FROM single_table WHERE key2 > 100 OR TRUE`，此时由于 `OR` 的条件，因此不管 key2 的索引是否满足条件，这个综合条件最后都是 `TRUE`，所以无法走上索引。

对于那些可能用到的索引，分析它们的范围区间。我们需要把那些用不到该索引的搜索条件暂时移除掉，移除方法也简单，直接把它们替换为 `TRUE` 就好了。换成 `TRUE` 之后，就进行索引条件的化简，判断最后是否可以走上索引。

## 3.7. 索引合并

### 3.7.1. Intersection 合并

#### 3.7.1.1. Intersection 合并介绍

某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集：

```sql

SELECT * FROM single_table WHERE key1 = 'a' AND key3 = 'b';

```

假设这个查询使用 `Intersection` 合并的方式执行的话：

1. 从 `idx_key1` 二级索引对应的 `B+` 树中取出 `key1 = 'a'` 的相关记录
2. 从 `idx_key3` 二级索引对应的 `B+` 树中取出 `key3 = 'b'` 的相关记录
3. 计算两个结果集中 `id` 值的交集
4. 按照上一步生成的 `id` 值列表进行回表操作

为啥不直接使用 `idx_key1` 或者 `idx_key3` 只根据某个搜索条件去读取一个二级索引，然后回表后再过滤另外一个搜索条件呢？这里要分析一下两种查询执行方式之间需要的成本代价：只读取一个二级索引的成本和读取多个二级索引之后取交集成本。

虽然读取多个二级索引比读取一个二级索引消耗性能，但是读取二级索引的操作是 `顺序I/O`，而回表操作是 `随机I/O`，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，**当节省的因为 `回表` 而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低**。

#### 3.7.1.2. Intersection 合并限制

`MySQL` 在某些特定的情况下才可能会使用到 `Intersection` 索引合并：
- 二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。
	比方说下边这个查询可能用到 `idx_key1` 和 `idx_key_part` 这两个二级索引进行 `Intersection` 索引合并的操作：
 
	```sql
	SELECT * FROM single_table WHERE key1 = 'a' AND key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c';
	```

	而下边这两个查询就不能进行 `Intersection` 索引合并：

	```sql
	SELECT * FROM single_table WHERE key1 > 'a' AND key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c';
	 SELECT * FROM single_table WHERE key1 = 'a' AND key_part1 = 'a';
	```

	第一个查询是因为对 `key1` 进行了范围匹配，第二个查询是因为联合索引 `idx_key_part` 中的 `key_part2` 和 `key_part3` 列并没有出现在搜索条件中，所以这两个查询不能进行 `Intersection` 索引合并。
- 主键列可以是范围匹配
	比方说下边这个查 a 询可能用到主键和 `idx_key1` 进行 `Intersection` 索引合并的操作：
	```sql
	SELECT * FROM single_table WHERE id > 100 AND key1 = 'a';
	```

    为啥呢？这话还得从 `InnoDB` 的索引结构说起，对于 `InnoDB` 的二级索引来说，记录先是按照索引列进行排序，如果该二级索引是一个联合索引，那么会按照联合索引中的各个列依次排序。而二级索引的用户记录是由 `索引列 + 主键` 构成的，二级索引列的值相同的记录可能会有好多条，这些索引列的值相同的记录又是按照 `主键` 的值进行排序的。所以**之所以在二级索引列都是等值匹配的情况下才可能使用 `Intersection` 索引合并，是因为只有在这种情况下根据二级索引查询出的结果集是按照主键值排序的**。

`Intersection` 索引合并会把从多个二级索引中查询出的主键值求交集，如果从各个二级索引中查询的到的结果集本身就是已经按照主键排好序的，那么求交集的过程就很简单：逐个取出这两个结果集中最小的主键值，如果两个值相等，则加入最后的交集结果中；否则丢弃当前较小的主键值，再取该丢弃的主键值所在结果集的后一个主键值来比较，直到某个结果集中的主键值用完了。

### 3.7.2. Union 合并

有时候 `OR` 关系的不同搜索条件会使用到不同的索引：

```sql
SELECT * FROM single_table WHERE key1 = 'a' OR key3 = 'b'
```

`Union` 适用于使用不同索引的搜索条件之间使用 `OR` 连接起来的情况。与 `Intersection` 索引合并类似，`MySQL` 在某些特定的情况下才可能会使用到 `Union` 索引合并：

- 情况一：二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只出现匹配部分列的情况。
- 情况二：主键列可以是范围匹配。
- 情况三：使用 `Intersection` 索引合并的搜索条件。

**优化器只有在单独根据搜索条件从某个二级索引中获取的记录数比较少，通过 `Union` 索引合并后进行访问的代价比全表扫描更小时才会使用 `Union` 索引合并**。

### 3.7.3. Sort-Union 合并

`Union` 索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用到 `Union` 索引合并：

```sql
SELECT * FROM single_table WHERE key1 < 'a' OR key3 > 'z';
```

这是因为根据 `key1 < 'a'` 从 `idx_key1` 索引中获取的二级索引记录的主键值不是排好序的，根据 `key3 > 'z'` 从 `idx_key3` 索引中获取的二级索引记录的主键值也不是排好序的，但是 `key1 < 'a'` 和 `key3 > 'z'` 这两个条件又特别让我们动心，所以我们可以这样：
1. 先根据 `key1 < 'a'` 条件从 `idx_key1` 二级索引中获取记录，并按照记录的主键值进行排序。
2. 再根据 `key3 > 'z'` 条件从 `idx_key3` 二级索引中获取记录，并按照记录的主键值进行排序。
3. 因为上述的两个二级索引主键值都是排好序的，剩下的操作和 `Union` 索引合并方式就一样了。

我们把上述这种先按照二级索引记录的主键值进行排序，之后按照 `Union` 索引合并方式执行的方式称之为 `Sort-Union` 索引合并，很显然，这种 `Sort-Union` 索引合并比单纯的 `Union` 索引合并多了一步对二级索引记录的主键值排序的过程。

为啥有 `Sort-Union` 索引合并，就没有 `Sort-Intersection` 索引合并么？是的，的确没有 `Sort-Intersection` 索引合并这么一说。

`Sort-Union` 的适用场景是单独根据搜索条件**从某个二级索引中获取的记录数比较少**，这样即使对这些二级索引记录按照主键值进行排序的成本也不会太高。而 Intersection 索引合并的适用场景是单独根据搜索条件**从某个二级索引中获取的记录数太多，导致回表开销太大，合并后可以明显降低回表开销**。但是如果加入 `Sort-Intersection` 后，就需要为大量的二级索引记录按照主键值进行排序，这个成本可能比回表查询都高了，所以也就没有引入 `Sort-Intersection` 。

# 4. SQL 语句的执行过程

## 4.1. SQL 各关键字执行顺序

1. from 表做笛卡尔积
2. 执行 on 过滤
3. 添加外部行，这里在左连接或右连接才会有
4. 执行 where 过滤
5. 执行 group By 分组
6. 执行 having 过滤
7. 执行 select 列选择
8. 执行 distinct 过滤数据 (这里会生成临时表，在过滤列上加唯一索引)
9. 执行 order by 语句
   - order by 的排序算法
     如果**满足了索引覆盖的条件的话，那么就不会有排序动作**了。从 B+树取出来的数据本身就是有序的。当不满足索引覆盖特性时，有以下两种排序算法：
     - 全字段排序
       使用时会根据条件筛选出所有满足条件的数据，然后对数据按给定的字段排序。排序过程中每条数据是全字段，排序完即可返回数据。
     - RowId 排序
       排序时若一条数据过长，超过 `max_length_for_sort_data` 时，就会采用 rowId 排序。此时排序的数据只有排序关键字与主键 ID。**排序完毕后根据主键 ID 回表再次查出数据**。这里回表时可能涉及到磁盘的读写。
     
     排序过程：
       1. 排序时会优先在内存中进行快速排序，当内存数据不足时会使用磁盘进行辅助排序。
       2. 使用磁盘辅助排序时，将数据分割成小文件，每个小文件使用归并排序，排序完毕后进行合并返回。
   - `order by rand ()` 的实现
     1. 首先会在内存中新建临时表，临时表长度不够的话会在磁盘中建。当超过 `internal_tmp_disk_storage_engine` 值时就会生成磁盘的临时表。临时表的内容为排序字段与为每条数据生成的一个随机数 r。
     2. 在生成的临时表中使用随机数 r 进行排序。
        - 对生成的临时表排序，会优先使用 rowId 排序算法。因为这样可以减少数据量。
        - 对于排序过程，若是指定的 limit 小的话，会使用优先队列排序。如 limit3 则只会维护三个最大值/最小值，避免全排序。
        - 若是 limit 大的话，超过排序的 `sort_buffer_size` 时就会使用归并排序了。
     3. 排序完毕按 limit 取数。
     4. 执行 limit 语句。

## 4.2. SQL 语句在 Mysql 内部的执行过程

 ![](https://r2.129870.xyz/img/20220508232841.png)

1. 取得数据库连接器
2. 查询缓存
   缓存在 8.0 中已经移除了，不建议使用缓存。Mysql 维护缓存有非常大的性能开销。
3. SQL 词法语法分析
   在分析器就完成了 SQL 语句的检查。分析器处理语法和解析查询，生成一颗解析树。进而检查解析树是否合法，列名是否有歧义等。通过则生成新的解析树再交给优化器。
4. 优化器优化，如使用哪个索引，join 连接顺序
5. 执行器执行
   **权限的判断是在执行器的时候进行的**。因为部分操作 Mysql 无法在前面的步骤进行，比如触发器只能到执行阶段才能确认。

## 4.3. 数据流转过程

![](https://r2.129870.xyz/img/20220515155935.png)

数据是一个**边读边发**的过程：
1. 获取一行数据，将其写入到 `net_buffer` 中。这块内存的大小是由参数 `net_buffer_length` 定义的，默认是 16k。**该区域每个线程独有**。
2. 重复获取行，直到 `net_buffer` 写满或者行读取结束。
3. 调用网络接口将数据发送给客户端。
4. 发送完成，清空 `net_buffer`。若还有数据，就继续上面的流程。
    如果发送函数返回 `EAGAIN` 或 `WSAEWOULDBLOCK`，就表示本地网络栈（`socket send buffer`）写满了，进入等待。直到网络栈重新可写，再继续发送。
    
    在发送数据给客户端这一阶段，线程的状态是 `Sending to client`。还有一个状态是 `Sending data`，当 SQ 语句进入执行阶段后，状态就会设置成 `Sending data`。
    
    对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，建议你使用 `mysql_store_result` 这个接口，直接把查询结果保存到本地内存。防止客户端未及时读取而阻塞数据库。

如果发现一个语句长时间处于 `Sending to client` 状态，可以按以下方向排查处理：
- 使用 `mysql_store_result` 这个接口，直接把查询结果保存到本地内存。
- 优化查询结果，并评估这么多的返回结果是否合理。
- 如果要快速减少处于这个状态的线程的话，将 `net_buffer_length` 参数设置为一个更大的值是一个可选方案。`net_buffer_length` 调大以后查询结果就会扔到缓存中，执行器就可以认为查询结束了。虽然网络栈还是慢慢发的，但是那些没发完的都缓存在 net_buffer 中，对于执行器来说，都是“已经写出去了”。

# 5. MVCC (Multi-Version Concurrency Control) 的实现原理

## 5.1. undo 日志

记录数据的历史变化情况，通过 [[Mysql的一致性保证#4. uodo 日志|undo 日志]]可以追溯到以前的数据。

## 5.2. ReadView

Mysql 的数据隐藏列中包含以下几个字段：
- `roll_pointer`：指向 undo 日志。
- `trx_id`：指向这条日志产生的源事务 ID。
- `row_id`：当没有主键时隐藏的主键 ID。

在执行增/删/改的时候，每操作一次就会产生一条 undo 日志。Undo 日志包含上述的字段内容，根据 `roll_pointer` 就可以产生一条版本链。基于版本链的情况下，当查询操作产生的时候就会构造 ReadView 视图，从版本链中获取数据。

生成 ReadView 视图时会包含以下内容：
- `m_ids`：生成 ReadView 视图时活跃的事务 ID 列表。
- `creator_trx_id`：生成 ReadView 视图的事务 ID，即当前事务 ID。
- `max_trx_id`：生成 ReadView 视图时应该分配给下一个事务的 ID。
- `min_trx_id`：生成 ReadView 视图时活跃事务列表中最小的事务 ID。

MVCC 的规则如下：
1. 若当前版本链上数据的事务 ID 等于 `creator_trx_id`，表示数据由当前事务产生，可读。
2. 若当前版本链上数据的事务 ID 大于 `max_trx_id`，表示数据是视图创建之后产生的，不可读，往版本链往前找。
3. 若当前版本链上数据的事务 ID 小于 `min_trx_id`，表示数据是视图创建之前产生的，可读。
4. 若当前版本链上数据的事务 ID 在 `m_ids` 列表中
   - 事务未提交：不可读。
   - 事务已提交
      - RC 级别下，数据可读。
      - RR 级别下，需要保持可重复读的特性，因此不可读。有一种特殊情况，若当前事务先对其进行更新操作，**更新会触发当前读**获取到最新数据更新。更新完之后该数据事务 ID 会变成当前事务 ID，当前事务就可读到了。

# 6. Mysql 的锁

## 6.1. 锁分类

- 按范围分类
	- 数据库锁：对数据库加锁。
		- `flush tables with read lock (FTWRL)`，使数据库处于只读状态。
    		如果只是备份的话可以使用 `mysqldump–single-transaction` 来保证隔离型的读。注意使用这个语句需要所有数据表都是 InnoDB 引擎的。
		- 使用 `set global readonly=true` 的方式。
    		这种方式有两个问题，其一是这个值通常用来处理一些其他情况，例如区分是主库还是从库（从库一般设置为只读库）。另一个是修改 global 影响大，FTWRL 中断后自动释放锁，而 readonly 设置却不会。
	- 表锁
		- `lock tables ... read/write`
			主动开启与释放锁。例如线程 A 中执行 `lock tables t1 read, t2 write;` 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。

			`lock tables ... read/write` 是由引擎层提供的锁。
		- `MDL (metadata lock)`
			是 Mysql5.5 版本增加的，会在操作一个表的时候自动加读/写锁。需要注意的是：在修改表结构的时候，**若前面有事务没释放锁，则修改表结构操作会阻塞。表结构操作阻塞后后续所有的请求都会阻塞。**

			`MDL` 是由 Server 层提供的锁。
	- 行锁
	- 共享锁
	- 排他锁
- 按锁机制分
	- 悲观锁
	- 乐观锁
- 按锁实现分类
    - S 锁：共享锁
    - X 锁：独占锁
    - 意向锁
        `InnoDB` 支持多粒度锁定，允许行锁和表锁共存。例如，诸如 `LOCK TABLES ... WRITE` 之类的语句在指定的表上获取独占锁（ `X` 锁）。为了使多粒度级别的锁定切实可行， `InnoDB` 使用意向锁。**意向锁是表级锁，指示事务稍后需要对表中的行使用哪种类型的锁（共享或独占）**。
        - IS 锁：意向共享锁。
            意向共享锁 ( `IS` ) 表示事务打算在表中的各个行上设置共享锁。
        - IX 锁：意向排他锁。
            意向排它锁 ( `IX` ) 表示事务打算对表中的各个行设置排它锁。
        
        意向锁定协议如下：
        - 在事务可以获取表中行的共享锁之前，它必须首先获取表上的 `IS` 锁或更强的锁。
        - 在事务可以获取表中行的排他锁之前，它必须首先获取表的 `IX` 锁。
        
        表级锁类型兼容性总结在以下矩阵：
        
        ![image.png](https://r2.129870.xyz/img/202307231407272.png)
        
        意向锁不会阻止除全表请求（例如 `LOCK TABLES ... WRITE` ）之外的任何内容。意向锁的主要目的是表明有人正在锁定一行，或者将要锁定表中的一行。当其他事务需要对该表进行加锁时如果发现意向锁的存在那么可以直接阻塞等待而不需要扫描是否存在冲突的锁。因此意向锁的核心作用在于**减少锁冲突检测的成本**。
    - Gap 锁
        **间隙锁是对索引记录之间间隙的锁定**，或者对第一个索引记录之前或最后一个索引记录之后的间隙的锁定。例如， `SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE;` 阻止其他事务将 `15` 值插入到列 `t.c1` 中，无论该列中是否已经存在任何此类值，因为该范围内所有现有值之间的间隙已被锁定。

        对于使用唯一索引锁定行来搜索唯一行的语句，不需要间隙锁定（在该行记录存在的情况下）。
        
        `InnoDB` 中的**间隙锁是“纯粹抑制性的”**，这意味着它们的唯一目的是防止其他事务插入间隙。**间隙锁可以共存**。一个事务获取的间隙锁不会阻止另一事务在同一间隙上获取间隙锁。共享间隙锁和独占间隙锁之间没有区别。它们彼此不冲突，并且执行相同的功能。
    - `next-key` 锁
        `next-key` 锁是索引记录上的记录锁和索引记录之前的间隙上的间隙锁的组合。
    - Insert Intention Locks
        插入意向锁是一种间隙锁，在行插入之前由 `INSERT` 操作设置。此锁表明插入的意图是，插入同一索引间隙的多个事务如果没有插入间隙内的同一位置，则无需彼此等待。假设存在值为 4 和 7 的索引记录。尝试分别插入值 5 和 6 的单独事务在获得插入行上的排他锁之前，每个事务都使用插入意向锁锁定 4 和 7 之间的间隙，但不会相互阻塞，因为这些行不冲突。
        
        一个事务在插入一条记录时需要判断一下插入位置是否 `gap 锁`，如果存在插入操作需要等待，直到拥有 `gap 锁` 的那个事务提交。

        Mysql 规定事务在等待的时候也需要在内存中生成一个 `锁结构`，表明有事务想在某个 `间隙` 中插入新记录，但是现在在等待，这种类型的锁命名为 `Insert Intention Locks`。
    - 空间索引的谓词锁
        `InnoDB` 支持对包含空间数据的列进行 `SPATIAL` 索引，为了处理涉及 `SPATIAL` 索引的操作的锁定，`next-key` 锁不能很好地支持 `REPEATABLE READ` 或 `SERIALIZABLE` 事务隔离级别。多维数据中不存在绝对的排序概念，因此并不清楚哪个是 `next-key` 键。

        为了支持具有 `SPATIAL` 索引的表的隔离级别， `InnoDB` 使用谓词锁。 `SPATIAL` 索引包含最小边界矩形 (MBR) 值，因此 `InnoDB` 通过在用于查询的 MBR 值上设置谓词锁来强制对索引进行一致读取。其他事务无法插入或修改与查询条件匹配的行。

## 6.2. 锁升级

- 当行锁无法匹配数据时，会升级到表锁
- 当索引记录超过整表 1/2 时，会走到全表查询。行锁变表锁。

## 6.3. 隐式锁

一个事务在执行 `INSERT` 操作时，如果即将插入的 `间隙` 已经被其他事务加了 `gap 锁`，那么本次 `INSERT` 操作会阻塞，并且当前事务会在该间隙上加一个 `插入意向锁`，否则**一般情况下 `INSERT` 操作是不加锁的**。那如果一个事务首先插入了一条记录（此时并没有与该记录关联的锁结构），然后另一个事务使用锁定读读取或修改该记录时该如何处理呢？

- 对于聚簇索引
    聚簇索引有一个 `trx_id` 隐藏列，该隐藏列记录着最后改动该记录的 `事务 id`。那么如果在当前事务中新插入一条聚簇索引记录后，该记录的 `trx_id` 隐藏列代表的的就是当前事务的 `事务 id`。

    如果其他事务此时想对该记录添加 `S 锁` 或者 `X 锁` 时，首先会看一下该记录的 `trx_id` 隐藏列代表的事务是否是当前的活跃事务，如果是的话，那么就帮助当前事务创建一个 `X 锁`（也就是为当前事务创建一个锁结构，`is_waiting` 属性是 `false`），然后自己进入等待状态（也就是为自己也创建一个锁结构，`is_waiting` 属性是 `true`）。
- 对于二级索引
    二级索引本身并没有 `trx_id` 隐藏列，但是在二级索引页面的 `Page Header` 部分有一个 `PAGE_MAX_TRX_ID` 属性，该属性代表对该页面做改动的最大的 `事务 id`。

    如果 `PAGE_MAX_TRX_ID` 属性值小于当前最小的活跃 `事务 id`，那么说明对该页面做修改的事务都已经提交了，否则就需要在页面中定位到对应的二级索引记录，然后回表找到它对应的聚簇索引记录，然后再重复 `情景一` 的做法。

一个事务对新插入的记录可以不显式的加锁（生成一个锁结构），但是由于 `事务 id` 的存在，相当于加了一个 `隐式锁`。其他事务在对这条记录加 `S 锁` 或者 `X 锁` 时，由于 `隐式锁` 的存在，会先帮助当前事务生成一个锁结构，然后自己再生成一个锁结构后进入等待状态。

## 6.4. 两段锁协议

在 InnoDB 事务中，行锁是需要的时候加上去的，但并不是不需要了就立刻释放，而是等到事务结束才释放。这就是两阶段锁协议。

如果事务需要锁多个行，那么尽可能把造成锁冲突的，影响并发的语句往后放。

## 6.5. InnoDB 锁的内存结构

对一条记录加锁的本质就是在内存中创建一个 `锁结构` 与之关联，那么是不是一个事务对多条记录加锁，就要创建多个 `锁结构` 呢？

在一定条件可以进行锁合并：

1. 在同一个事务中进行加锁操作
2. 被加锁的记录在同一个页面中
3. 加锁的类型是一样的
4. 等待状态是一样的

如果满足这些条件，那么锁就可以被放到一个 `锁结构` 中：

![](https://r2.129870.xyz/img/202209200027113.png)

- 锁所在的事务信息
	不论是 `表锁` 还是 `行锁`，都是在事务执行过程中生成的，哪个事务生成了这个 `锁结构`，这里就记载着这个事务的信息。
 - 索引信息
	对于 `行锁` 来说，需要记录一下加锁的记录是属于哪个索引的。
- 表锁／行锁信息
	`表锁结构` 和 `行锁结构` 在这个位置的内容是不同的：
	- 表锁：
		记载着这是对哪个表加的锁，还有其他的一些信息。
	-   行锁：
		记载了三个重要的信息：
		- `Space ID` ：记录所在表空间。
		- `Page Number` ：记录所在页号。
		- `n_bits` ：对于行锁来说，一条记录就对应着一个比特位，一个页面中包含很多记录，用不同的比特位来区分到底是哪一条记录加了锁。为此在行锁结构的末尾放置了一堆比特位，这个 `n_bits` 属性代表使用了多少比特位。
- `type_mode`
    这是一个 32 位的数，被分成了 `lock_mode`、`lock_type` 和 `rec_lock_type` 三个部分：
    
    ![](https://r2.129870.xyz/img/202209200030219.png)

    - 锁的模式（`lock_mode`），占用低 4 位，可选的值如下：
        - `LOCK_IS`（十进制的 `0`）：表示共享意向锁，也就是 `IS 锁`。
        - `LOCK_IX`（十进制的 `1`）：表示独占意向锁，也就是 `IX 锁`。
        - `LOCK_S`（十进制的 `2`）：表示共享锁，也就是 `S 锁`。
        - `LOCK_X`（十进制的 `3`）：表示独占锁，也就是 `X 锁`。
        - `LOCK_AUTO_INC`（十进制的 `4`）：表示 `AUTO-INC 锁`。
    - 锁的类型（`lock_type`），占用第 5～8 位，不过现阶段只有第 5 位和第 6 位被使用：
        - `LOCK_TABLE`（十进制的 `16`），也就是当第 5 个比特位置为 1 时，表示表级锁。
        - `LOCK_REC`（十进制的 `32`），也就是当第 6 个比特位置为 1 时，表示行级锁。
    - 行锁的具体类型（`rec_lock_type`），使用其余的位来表示。只有在 `lock_type` 的值为 `LOCK_REC` 时，也就是只有在该锁为行级锁时，才会被细分为更多的类型：
        - `LOCK_ORDINARY`（十进制的 `0`）：表示 `next-key 锁`。
        - `LOCK_GAP`（十进制的 `512`）：也就是当第 10 个比特位置为 1 时，表示 `gap 锁`。
        - `LOCK_REC_NOT_GAP`（十进制的 `1024`）：也就是当第 11 个比特位置为 1 时，表示 `正经记录锁`。
        - `LOCK_INSERT_INTENTION`（十进制的 `2048`）：也就是当第 12 个比特位置为 1 时，表示插入意向锁。
        - 其他的类型：还有一些不常用的类型。
        
         `is_waiting` 属性也被放到了 `type_mode` 这个 32 位的数字中。`LOCK_WAIT`（十进制的 `256`） ：也就是当第 9 个比特位置为 `1` 时，表示 `is_waiting` 为 `true`，也就是当前事务尚未获取到锁，处在等待状态；当这个比特位为 `0` 时，表示 `is_waiting` 为 `false`，也就是当前事务获取锁成功。
- 其他信息
	为了更好的管理系统运行过程中生成的各种锁结构而设计了各种哈希表和链表。
- 一堆比特位
	如果是 `行锁结构` ，在该结构末尾还放置了一堆比特位，比特位的数量是由 `n_bits` 属性表示。页面中的每条记录在[[Mysql的存储结构#2.1.1.3. 记录头信息|记录头信息]]中都包含一个 `heap_no` 属性，伪记录 `Infimum` 的 `heap_no` 值为 `0`，`Supremum` 的 `heap_no` 值为 `1`，之后每插入一条记录，`heap_no` 值就增 1。`锁结构` 最后的一堆比特位就对应着一个页面中的记录，一个比特位映射一个 `heap_no`。

	![](https://r2.129870.xyz/img/202209200036066.png)

## 6.6. 加锁过程

### 6.6.1. RU/RC 级别

- 主键索引
	- 等值查询
		加 X/S 锁，若是更新操作，会为涉及数据字段的二级索引加锁。若是删除操作，会对涉及数据的所有二级索引加锁。
	- 范围查询
		从满足条件的数据开始加锁，加锁规则与等值查询相同。当下一条数据不满足条件时，会先加锁再释放锁 (5.7 版本实验结果)。所以要注意锁争用问题。
- 普通索引
	- 等值查询
		加 X/S 锁，若是不满足索引下推条件需要回表，还会对主键索引进行加锁。这里不会出现对下一个不满足条件对数据加锁的情况。
	- 范围查询
		加锁同等值查询。若是查询语句，当下一个数据不满足条件时，会将二级索引加锁，但是不会释放锁。若是更新语句，则会先对二级索引和主键索引加锁，然后发现不满足条件又释放锁。(5.7 版本实验结果)。**更新操作无法使用索引下推特性**，因此才会对二级索引和主键索引都加锁。
- 无索引
	存储引擎扫描一行就对该行加 S/X 锁，返回 Server 层发现不满足条件后又释放锁。若是更新操作，还会对涉及到对二级索引加锁。
- 半一致性读
	在 RC 级别下，update/detele 语句有个 `semi-consistent` 优化，当语句碰见一个已经被锁住的行，会取出最新数据判断是否满足查询条件：如果不满足条件就直接跳过；如果满足条件就进入锁等待。
	
	半一致性读不适用于 select 的原因如下：
	1. 本身该优化是为了提升常见场景下的性能而提升的，`select xx for update` 这种使用并不场景，查询语句更多是为了精准定位数据
	2. 从数据一致性的角度考虑，查询需优先保证**读取准确性**，而非最大化吞吐量

### 6.6.2. RR 级别

- 加锁规则
    加锁原则：
    - 原则 1：加锁的基本单位是 `next-key` lock。`next-key` lock 是前开后闭区间。`next-key` 锁实际上是间隙锁+行锁组成的。
    - 原则 2：查找过程中访问到的对象才会加锁。

    优化措施：
    - 优化 1：索引上的等值查询，给主键索引加锁的时候，next-key lock 退化为行锁。
    - 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

    一个 Bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。在 8.0.18 后已修复。
    
    - 利用索引的有序性，若一个数据的索引不在被加锁的区间内就不会受到影响。
    - 对于唯一索引，insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock (S 锁)。
- 加锁示例
    数据准备：准备表 t (id, c, d)，其中 id 为主键，c 为普通索引，d 无索引。数据准备为 (0, 0)，(5, 5)，(10, 10)，(15, 15)，(20, 20)，(25, 25)
    - `update t set d = d+1 where id = 7;`
        会对主键索引 (5, 10) 区间加间隙锁。
    - `select id from t where c = 5 lock in share mode;`
        会对二级索引 c 加 Next-key 锁 (0, 5]与间隙锁 (5, 10)。由于索引覆盖，所以不会对主键索引加锁。Sql 查询字段若是改为 d，则回表会导致主键索引也被加锁。
    - `select * from t where id>=10 and id<11 for update;`
        会对主键索引行 10 以及 next-key 锁 (10, 15]进行加锁。其实这里发现 15 是不满足条件的，没必要进行加锁。在版本 8.0.19 上已经退化成间隙锁 (10, 15) 了。
    - `select * from t where c>=10 and id<11 for update;`
        这里 c 是普通索引，会对二级索引 c 加 next-key 锁 (5, 10]及 next-key 锁 (10, 15]进行加锁。同时对主键索引 10 加行锁。同 8.0.19 上后一个 next-key 锁会退化成间隙锁 (10, 15)。

        如果 c 是 unique 唯一索引的话，也还是 next-key 锁 (5, 10]及 next-key 锁 (10, 15)，前一个锁不会退化成行锁，只有主键索引会。测试版本为 8.0.20。
    - `select * from t where id>10 and id<=15 for update;`
        会对主键索引加 next-key 锁 (10, 15]及 (15, 20]进行加锁。8.0.18 后已优化唯一索引范围查询的加锁方式，只会有 (10, 15]的 next-key 锁。
    
    多增加一条数据 `insert into t values (30, 10, 30);`
    - `delete from t where c = 10;`
        此时存在两条 c=10 的数据，会对二级索引 c 加 $\left( \begin{array}{c} 5 & 10 \\ 5 & 10 \end{array} \right]$，$\left( \begin{array}{c} 10 & 10 \\ 10 & 30 \end{array} \right]$，$\left( \begin{array}{c} 10 & 15 \\ 30 & 15 \end{array} \right)$ （其中第一行为 c 列的值，第二行为 id 的值），同时对主键索引  10，30 加行锁。
    -  `delete from t where c = 10 limit 2;`
        由于多了 limit 条件，因此扫描到两行后就会结束。此时加锁情况为对二级索引 c 加  $\left( \begin{array}{c} 5 & 10 \\ 5 & 10 \end{array} \right]$，$\left( \begin{array}{c} 10 & 10 \\ 10 & 30 \end{array} \right]$，，对主键索引 10，30 加行锁。所以删除时如果行数确定的话尽量加上 limit 条件，这样可以减少锁的范围。
    -  `select * from t where c >= 15 and c <= 20 order by c desc for update;`
        会对二级索引 c 加 (20, 25]，(15, 20]，(10, 15]，(5, 10]的 next-key 锁，同时对主键索引 10, 15, 20, 25 加行锁。在 8.20 版本二级索引 c (20, 25]已优化为 (20, 25)，且主键索引无 25 的行锁。

        原因是因为这是倒序排序，所以索引会从后往前扫。扫描数据 15 时会发现仍满足条件，因此继续往前扫描一条数据，所以就对 10 也加上了锁。
    - 事务 A 执行 `select c from t where c > 5 for update;`，而后事务 B 先执行 `update t set c = 1 where c = 5`，之后再执行 `update t set c = 5 where c = 1;`
        首先 A 执行时会对二级索引 c 加 (5, 10], (10, 15], (15, 20], (20, 25], (25, supermum) 锁。事务 B 执行第一条语句时，c=5 列无锁，因此可以执行。但是执行后事务 A 的锁范围蔓延了，会变成 (1, 10)。之后事务 B 再次执行时，将 c=1 改为 c=5，更新操作其实是一个先删后增的操作，因此增加 c=5 这一列时就会被阻塞。
    - 死锁的例子
        ![](https://r2.129870.xyz/img/20220513130251.png)
        事务 A 加了 (5, 10]和 (10, 15) 的锁，事务 B 加 (5, 10]的锁时失败阻塞，事务 A 再次插入时进入死锁状态。
        
        原因如下：本质是因为 next-key 锁实际上是由间隙锁+行锁组成的。
        1.  B 加锁时其实是先加 (5, 10) 的间隙锁，成功，后加行锁时阻塞。
        2. 事务 A 再次插入时被事务 B 的间隙锁锁住，因此阻塞进入死锁。

## 6.7. 死锁避免

- 设定超时时间。
- 设定资源访问顺序。
- 一次性申请全部资源。
- 银行家算法进行死锁避免。
- 避免事务交叉。
- 使用低隔离级别。
- 主动死锁检测，在尝试获取锁的时候进行死锁检测。当发现自己的操作可能发生阻塞时，就主动回滚事务让其他事务执行。`innodb_deadlock_detect` 默认就是开启的。这里检测的时候不会扫描所有事务，只会扫描和当前线程操作资源相关的事务。可以采用资源位图法进行死锁检测。

## 6.8. 死锁解除

当线程持有锁时间超过 `innodb_lock_wait_timeout` 时，会导致 `InnoDB` 回滚当前语句（正在等待锁并遇到超时的语句），而不是回滚整个事务。你仍然可以获取该异常并再次进行重试，或者选择回滚该事物。这个值默认是 50s。

# 7. Mysql 的高可用

## 7.1. 主备模式

![](https://r2.129870.xyz/img/20220514143924.png)

在状态 1 中，虽然节点 B 没有被直接访问，但是依然建议把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：

- 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
- 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
- 可以用 readonly 状态，来判断节点的角色。

备库设置成只读了，还怎么跟主库保持同步更新呢？readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

主备的流程：

![](https://r2.129870.xyz/img/20220514144050.png)

主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。

一个事务日志同步的完整过程是这样的：
1. 在备库 B 上通过 `change master` 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
2. 在备库 B 上执行 `start slave` 命令，这时候备库会启动两个线程： `io_thread` 和 `sql_thread`。
3. `io_thread` 负责与主库建立连接。主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
4. 备库 B 拿到 binlog 后，写到本地文件，称为 `中转日志（relay log）`。
5. `sql_thread` 读取中转日志，解析出日志里的命令，并执行。这里需要说明，后来由于多线程复制方案的引入，`sql_thread` 演化成为了多个线程。
6. 对于后续主库产生的新日志，就推送给备库执行。
    基于 [[数据库/Mysql的一致性保证#2 binlog 日志|binlog日志]] 进行数据备份。

在 MySQL 多源复制中，副本打开多个复制通道，每个源服务器一个。复制通道表示事务从源流向副本的路径。每个复制通道都有自己的接收器 (I/O) 线程、一个或多个应用程序 (SQL) 线程和中继日志。当通道的接收器线程接收到来自源的事务时，它们将被添加到通道的中继日志文件中，并传递到通道的应用程序线程。这使得每个通道能够独立运行。

## 7.2. 主备延迟

对于主库上发生的更改，延迟了一段时间才到达从库。从库在执行当前事务时，可以在事务的 binlog 日志中看到该事务在主库中执行的时间。通过这个时间与系统时间的插值，就可以得到主备之间的延迟时间，称之为 `seconds_behind_master`。

主备延迟产生的情况可能如下：
- 从库配置低于主库，导致执行慢。
- 从库压力大，在从库上可能有许多其它的操作。
	如数据分析查询之类，影响同步速度。针对这种，可以进行一主多从的配置来分摊从库压力，或者将部分逻辑迁移到其它组件中，例如使用 Hadoop 来进行数据统计。
- 大事务
	当有大事务时，事务提交才会同步给从库。因此事务执行时间长的话也会导致从库同步慢。
- 大表 DDL
	影响类似于大事务。对于计划内的 DDL，推荐使用 `gh-ost` 方案。
- 备库的并行复制能力

若需要迫切的提升从库的读写能力，可以进行以下策略的优化：
- 从库开启 [[Mysql大纲#7 4 2 4 按 WRITESET 分发策略|writeset]]
- 将 [[Mysql的一致性保证#2 2 binlog 写盘状态与控制|sync_binlog]] 改为 0，[[数据库/Mysql的一致性保证#1 4 1 2 刷盘控制|innodb_flush_log_at_trx_commit]] 改为 2 提升写数据能力。

## 7.3. 主备切换策略

![](https://r2.129870.xyz/img/20220514154847.png)

### 7.3.1. 可靠性优先策略

1. 判断当前从库的 `seconds_behind_master` 是否小于某个值，不小于就一直重试，小于开始进行主备切换。
2. 将主库改为只读状态。
3. 判断从库的 `seconds_behind_master` 是否为 0，不为 0 等待直到变为 0。
4. 将从库状态改为读写。
5. 请求切换到从库。

在从库提升为读写这段期间服务不可用，这是为了保证可靠性做出的妥协。主库异常时，若从库存在未同步完的数据，此时从库也无法切换。

### 7.3.2. 可用性优先策略

可用性策略下：不等到从库同步完主库的数据就直接将从库改为主库，接受读写请求。这可能会导致数据不一致的情况，因为从原来主库同步的数据可能与新写入的数据发生冲突。

如果使用该模式，binlog 建议使用 row 格式的。这样可以尽可能减少数据冲突的情况，也能尽可能早的发现数据错误的情况。

## 7.4. 备库日志重放

### 7.4.1. 日志重放职责划分

当备库接收到主库的 binlog 日志后，需要进行重放操作。Mysql 最开始的版本提供的是单线程的重放模式，当主库日志非常多或者主库大事务阻塞之后提交给从库，那么这时候就会造成主从之间的数据延迟增大。为了改善这一情况引入了并行复制的能力。

并行复制采用了以下的算法：
- Coordinator 事务协调者：负责读取日志与将日志转发给后续的日志处理线程。
	协调者在分发日志时，需要注意以下要求：
	- 不能造成数据破坏，同一行的数据更改操作必须分发给同一个 worker。
	- 不能造成事务破坏，同一个事务操作必须分发给同一个 worker。
- Worker 日志重做者：负责对接受到的日志进行重放操作。

### 7.4.2. 事务分发协调算法

#### 7.4.2.1. 按库按表分发

对于同一个库/表操作的分发给同一个 worker，这样就避免了改动同一个库表。但是如果存在热点库/表，极端情况只有一个库/表的情况下，那么会退化成单线程模式。

按表分发时，可按以下规则判断：
- 若当前事务涉及表没有其它 worker 在操作，可直接分发给一个空闲的 worker。
- 若当前事务涉及表有一个 worker 在操作，直接分发给这个 worker。
- 若当前事务涉及表有多个 work，等待。

#### 7.4.2.2. 按行分发策略

针对事务影响的行进行分发，需要注意不仅仅从主键维度考虑，还需要从其它索引的维度考虑，一条数据可能会有多个索引。

以行为维度 binlog 日志解析时会占用更多的计算资源。

#### 7.4.2.3. 按组提交时 CommitId 分发策略

对于[[Mysql的一致性保证#3 4 组提交策略|同一组提交的事务]]，其数据操作一定不会出现冲突。若冲突，则必然会等到前一个操作提交后后一个事务才可继续操作。

基于这一个策略，所以可以对同一组内提交的事务分发给不同的 worker，当然还是得注意同一个事务的是不能分开的。

对于 Mysql 来说，其实不一定需要等到 Commit 标记才认为事务没有冲突，在 redolog 的 prepare 阶段就可以确认了。当到达 prepare 阶段，就代表已经通过了锁的检测，所以可以分开进行操作了。因此可以考虑优化 `binlog_group_commit_sync_delay` 与 `binlog_group_commit_sync_no_delay_count` 这两个参数的配置来控制主从之间同步的效率。

#### 7.4.2.4. 按 WRITESET 分发策略

在 Mysql5.7.22 的版本增加了一个新的策略，该策略有以下几种选择：
- `COMMIT_ORDER` ：基于 prepare 和 commit 来判断是否可以并行。
- `WRITESET` ：对事务涉及的每一行，计算这一行的 hash，组成集合 writeset。若两个事务没有操作同一行，则认为可以并行。
- `WRITESET_SESSION` ：在 WRITESET 的基础上增加了一个限制，主库上存在先后关系的事务从库上也要保证这个顺序。

为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。**Writeset 是在主库生成后直接写入 binlog 中的，因此不会额外占用从库的计算资源，这占用的是主库的计算资源**。

**对于数据上没有主键或存在外键约束的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型**。

可以通过数据库的配置 `binlog-transaction-dependency-tracking` 来决定是否开启 WRITESET 策略。

## 7.5. 从库拉取主库数据

现在的数据库架构大多都是一主多从架构，那么这些从库如何拉取主库的数据呢？在主库发生切换的时候，从库基于什么规则拉取才能做到数据一致呢？

![](https://r2.129870.xyz/img/20220514175012.png)
![](https://r2.129870.xyz/img/20220514175033.png)

### 7.5.1. 基于 binlog 的 position 拉取

1. 等待新主库 `A'` 把中转日志（relay log）全部同步完成。
2. 在 A’上执行 `show master status` 命令，得到当前 A’上最新的 File 和 Position。
3. 原主库 A 故障的时刻 T。
4. 用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。

这样得到的位点并不一定准确，时刻 T 时若主库 A 产生了 binlog 发给从库，后续从库会接受到这个日志。而时刻 T 从 A‘上读取位点的时候还不包含这个日志，因此这个日志就可能被重复执行。

对于插入操作，就会抛出主键重复错误，因此主备切换时通常要跳过这些错误。跳过作物的常用方法有：
- 主动跳过一个事务：`set global sql_slave_skip_counter=1;`
- 跳过一些指定类型错误
    `slave_skip_errors`，如 1062 是唯一键冲突错误，1032 是删除时找不到行错误。这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。等主备同步完需要切换回去。

### 7.5.2. GTID 算法

由上可以看到，通过位点的方式同步数据并不准确，而且还要处理同步过程中的错误。在 Mysql5.6 版本引入了 `GTID：Global Transaction Identifier，全局事务 ID`。GTID 由两部分组成：`server_uuid: gno`，`server_uuid` 在 mysql 启动时生成，`gno` 在事务**提交时自增**。

在 GTID 模式下，每个事务都会与一个 GTID 对应。这个 GTID 有两种生成方式，取决于 session 中 `gtid_next` 的值：
- `gtid_next=automatic`
	使用默认自增值，在事务提交时 Mysql 会自动自增生成一个 GTID 并分配给该事务。同步将生成的 GTID 写入到 Mysql 的 GTID 集合与该事务的 binlog 中。
- Session 指定值
	- 若指定值已存在 Mysql 实例的 GTID 集合，则该事务被忽略。
	- 不存在，将 GTID 分配给该事务并执行。一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 GTID 或者 automatic。

有了 GTID 算法，在进行主备切换时就无需指定位点了。同步时从库将自己的 GTID 集合传递给主库，主库与自己的 GTID 集合做差集。对于差集结果有以下处理：
- 差集中包含不在主库中的 GTID，代表主库已经将该 binlog 给删除了，返回错误。
- 若全部包含，就将需要的 binlog 发送给从库。

这个逻辑里面包含了一个设计思想：**在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的**。因此，如果实例 B 需要的日志已经不存在，A 就拒绝把日志发给 B。这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。

对于有问题的事务日志，可以通过 `set gtid_next='id';` 将其排除，不影响主备流程。

## 7.6. 读写分离保证读数据准确性

![](https://r2.129870.xyz/img/20220514205909.png)

### 7.6.1. 读写分离的方案

- 客户端主动做负载均衡：这种情况下将数据库连接放在客户端，由客户端选择从哪个数据库查询。这种模式需要客户端管理配置，并且对数据库配置信息改动时需要增加处理机制。
- 中间层代理：客户端与中间代理层交互，代理层分发请求到不同数据库。这种模式会略微损失一些行能，但客户端侧就无需关注过多关于数据库的细节。

### 7.6.2. 读写分离延迟问题

读写分离，写操作发生在主库，读操作发生在从库。当主库的变更日志未到达从库之前，从库读到的都不是最新的数据。解决这一问题有以下几种办法，需要说明的是，以下延迟解决方案都是基于强一致性目的设计的，与此对应的还有一些[[数据密集系统设计/数据密集型系统设计2：复制与分区#1.4. 复制滞后问题|弱一致性方案]]，扩展到更大的分布式领域的话，则还会有分布式的[[分布式/分布式大纲#2.3.2. 最终一致性|最终一致性问题]]。

#### 7.6.2.1. 强制走主库读

对于必须拿到最新数据的请求，从主库查。可以读到旧数据的请求，从从库查。这个方案的问题是当所有请求都无法接受读到旧数据时，所有请求都会落到主库中。

#### 7.6.2.2. Sleep 方案

针对主从之间的延迟，估算一个时间，然后读请求产生的时候先 sleep 一下，以此来保证主从同步。这个方案的问题是时间估算并不一定准确。

另一个思路是**将这个延迟做在用户端**，让前端先直接将数据展示到页面而不是从数据库查，下次刷新时再从数据库查。

#### 7.6.2.3. 判断主备无延迟方案

在查询从库时，判断当前主从是否有延迟。若当前主从无延迟，就可以从从库读。判断延迟有以下几种方案：

- 利用 `show slave status;` 返回的 `seconds_behind_master` 查看，若这个值不为 0，则需要等待。
- 对比位点判断延迟
	`Master_Log_File` 和 `Read_Master_Log_Pos`，表示的是读到的主库的最新位点；`Relay_Master_Log_File` 和 `Exec_Master_Log_Pos`，表示的是备库执行的最新位点。
	
	如果 `Master_Log_File` 和 `Relay_Master_Log_File`、`Read_Master_Log_Pos` 和 `Exec_Master_Log_Pos` 这两组值完全相同，就表示接收到的日志已经同步完成。
- 对比 GTID 集合判断延迟
	`Auto_Position=1` ，表示这对主备关系使用了 GTID 协议。`Retrieved_Gtid_Set` 是备库收到的所有日志的 GTID 集合；`Executed_Gtid_Set` 是备库所有已经执行完成的 GTID 集合。如果这两个集合相同，也表示备库接收到的日志都已经同步完成。

需要注意的一点是 `show slave status;` 这只能表示当前从库收到的日志的处理情况，对于那些**主库还未同步到从库的日志，这段延时从库是判断不出来的**。 `seconds_behind_master` 是计算收到的日志与当前时间的差值，这个日志并不一定是主库最新的日志。

同理位点和 GTID 集合也不一定是主库最新的数据。**同时还有另一点是若主库源源不断的有日志过来，那么这个延迟就一直不为 0**。

#### 7.6.2.4. semi-sync 半同步方案

半同步方案设计如下：
1. 事务提交的时候，主库把 binlog 发给从库。
2. 从库收到 binlog 以后，发回给主库一个 ack，表示收到了。
3. 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。

采用半同步方案，就能确保至少有一个从库是最新的数据。如果是一主一从，那么读延迟就可以解决了，如果一主多从的话，那么其它从库还是不能保证读取到最新数据。

#### 7.6.2.5. 等主库位点方案

`select master_pos_wait (file, pos[, timeout]);` 可以从数据库查询位点信息，各参数作用如下：
- file，pos：数据库文件名和位置。
- timeout：从数据库执行该命令的超时时间。

返回结果可能有以下几种：
- NULL：发生异常
- -1：timeout 超时
- 0：该 pos 位置的事务已在数据库库执行
- 大于 0 的整数 M：从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。

基于这个命令，可以进行如下操作：
1. 执行完更新语句后从主库获取当前的 file 和 position。
2. 选定一个从库执行上面的查询语句。
3. 如果返回值 >= 0，就在从库上执行该查询。
4. 否则到主库查询。

![](https://r2.129870.xyz/img/20220514211034.png)

#### 7.6.2.6. 等主库 GTID 方案

如果开启了 GTID 模式，则 GTID 也有类似的查询。`select wait_for_executed_gtid_set (gtid_set, 1);` 用于实现 GTID 的等待查询。

对于 GTID 的获取，可以主动查询，也可以在执行完请求后让数据库直接返回。具体做法如下：
1. 将参数 `session_track_gtids` 设置为 `OWN_GTID`。
2. 通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值。
3. 或者在客户端代码调用 `mysql_session_track_get_first;` 函数。

## 7.7. 可用性监控

### 7.7.1. 外部监控

需要注意的是外部监控有随机性，**监控的时刻正常并不一定代表过去一直正常**。

#### 7.7.1.1. `select 1;` 判断

通过 select 1 可以判断是否可以连接上数据库，但是无法判断当前数据库能否执行请求。比如当前数据库并发查询连接数已到了最大值 `innodb_thread_concurrency`，后续的请求都会阻塞，但是 select 1 仍会正常返回。

并发连接与并发查询不一样，并发连接可以很大，如上千个查询同时进入数据库。但是并发查询不同，并发查询是数据库真正在执行查询的请求，其它未执行的会等待。比如线程锁等待后，并发查询数减一，但并发连接不变。

#### 7.7.1.2. 查表判断

可以建立一个系统表，然后查询该系统表数据，看是否能正常返回。使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。但是无法检查空间占用达到 100%而无法写入的场景。

#### 7.7.1.3. 更新判断

通过更新系统表，来判断更新请求能否正常执行。对于一主一丛或一主多从，可以直接更新系统表就行了。但是如果是一主多从的话，需要注意主与主之间 binlog 会互传，所以会出现更新失败的情况。因此两主之间的数据 id 需要做到差异，如主键 ID 设置为 `@@server_id`。

### 7.7.2. 内部监控

MySQL 5.6 版本以后提供的 `performance_schema` 库，就在 `file_summary_by_event_name` 表里统计了每次 IO 请求的时间。开启这个功能数据库性能会下降 10%左右。`update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';`，可以通过这个命令开启监控功能。

## 7.8. 内存管理策略

Mysql 使用 LRU 算法进行内存缓冲区的管理，淘汰最近最少使用的数据。同时利用 [[Mysql的存储结构#6 1 4 LRU 链表的管理|缓存区间拆分的策略]]，避免偶然读请求覆盖调所有的缓存数据。

# 8. 数据备份与恢复

## 8.1. 误删数据恢复

- 误删行数据，可以利用 binlog 反向操作还原数据。对于此类情况，考虑使用稳定的工具进行日志回放，回放过程优先找个临时库测试与验证。
- 误删库/表
	- 取出数据库的备份记录，然后取出日志备份，将备份记录之后的日志进行回放操作。
	- 取出备份记录，将其恢复出一个临时实例。然后将这个实例作为从库去同步数据。
- 预防措施
	- 延迟复制从库，可以保留一个从库采取延迟复制策略，通过 `CHANGE MASTER TO MASTER_DELAY = N` 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。
	- 完善的权限管理机制，SQL 执行规范，Review 流程等。

## 8.2. 数据导出

- 逻辑导出
	```sql
	# 使用 mysqldump 命令导出一组 insert 语句
	mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
	
	# 执行导出的 sql
	mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"
	
	# 导出 CSV 文件
	select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
	
	# 加载导出的文件
	load data infile '/server_tmp/t.csv' into table db2.t;
	```
- 物理拷贝

# 9. 性能优化

## 9.1. 一条 SQL 执行慢的原因

### 9.1.1. 偶尔慢

- 数据库在刷新脏页
    - redo 日志满了
    - 内存满了
    - MySql 正常刷新脏页
    - 正在关机

    脏页刷新的快慢和 Myql 的 iops 变量设置与当前脏页比例有关。
    
- 获取不到锁
    - 可以通过 `show processlist` 来查看是否有阻塞表锁的线程。
    - 可以通过 `select * from t sys. Innodb_lock_waits where locked_table=\` 'test'.'t\'\`\G\`来查看锁阻塞情况。
- 查询是快照读，有事务进行了大量更新操作没提交，产生大量 undo 日志。快照读需要解析这些 undo 日志因此耗时长。
- 机器性能消耗
    比如突然 QPS 暴涨，导致 Mysql 压力过大

### 9.1.2. 一直慢

- 没正确使用索引
	- 联合索引使用了范围语句导致没用上
	- 使用了函数计算导致没用上。如 month () 这类。当两个表连接时，字段类型不同。如 `t1.a = t2.b`，`t1.a` 的编码是 utf-8，, `t2.b` 的编码是 utf8mb4，此时 `t1.a` 会发生隐式函数计算 `CONVERT(t1.a USING utf8mb4) = t2.b;` 而导致无法使用索引。
	- 隐式类型转换导致没用上，比如 `.. where c = 1`，若 c 是字符串类型，相当于隐式执行了 `CAST(c AS signed int)` 这个转换。而如果索引是数值类型条件是字符串则不会有这个情况。
- 索引没建
- 由于数据库原因导致索引失效。如是否使用临时表，是否排序，估算的索引扫描行数等。

## 9.2. SQL 优化的途径

- 不要使用 select *
- 减少子查询，用关联查询代替。子查询会生成临时表，关联查询不会。
- 部分场景使用 exists 替换 in 查询。当子查询表大时，用 exists。子查询表小时，用 in。另无论哪个表大，not in 会扫全表，not exists 可以使用到索引。
- or 的查询看情况是否可以使用 union 或 union all 代替。
- 减少 != 条件的使用，否则会全表扫描。
- 避免在 where 条件中进行 null 值判断，否则可能会全表扫描。
- 避免在 where 条件中对字段进行函数计算。
- 如果 binlog 是 row 格式，可以将 `innodb_autoinc_lock_mode` 设置为 2，使主键分配结束就释放自增锁。
- 增大 `net_buffer` 的值，避免数据发送给客户端时阻塞。

## 9.3. 大表优化的思路

- 限定查询范围
- 读写分离
- 垂直分区，拆列
- 水平分区，拆行
- 分库分表

## 9.4. 数据库性能瓶颈优化

- 设置 `binlog_group_commit_sync_delay` 和 `binlog_group_commit_sync_no_delay_count` 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
- 将 `sync_binlog` 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
- 将 `innodb_flush_log_at_trx_commit` 设置为 2。这样做的风险是，主机掉电的时候会丢数据。
- 如果 binlog 是 row 格式，可以将 `innodb_autoinc_lock_mode` 设置为 2，使主键分配结束就释放自增锁。
- 增大 `net_buffer` 的值，避免数据发送给客户端时阻塞。

# 10. 分布式数据库

## 10.1. 数据库分片两种常见方案

- 客户端代理，如 Sharding-Jdbc。封装在 jar 包中，通过修改或封装 jdbc 实现。
- Mycat，中间件代理。处于应用和数据层之间。

该问题的本质在于客户端如何感数据与节点的关系，与[[数据密集型系统设计2：复制与分区#2.4. 请求路由|请求路由]]有些类似。

## 10.2. 分库分表后 id 解决方案

- UUID
- 数据库自增 ID。设置不同步长与 ID 生成策略。
- 利用 Redis 中间件生成。
- SnowFlake 算法。
- 其他分布式 ID 生成系统，如美团的 Leaf。