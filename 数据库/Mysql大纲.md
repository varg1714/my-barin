#知识大纲 #数据库 

# 1. 数据库基础概念

## 1.1. 数据库中的键

1. 超键：唯一标记元祖的属性集
2. 候选键：超键中不包含多余的属性
3. 主键：候选键选择一个作为主键
4. 外键
5. 主属性
6. 非主属性

## 1.2. 数据库范式

1. 1NF：列不可拆分
2. 2NF：非主属性完全依赖候选键，不能部分依赖，否则造成数据冗余与耦合。消除非主属性对键的部分函数依赖。
3. 3NF：非主属性不能与候选键存在传递依赖。消除非主属性对键的传递函数依赖。
4. BCNF：任意字段不能与候选键存在传递依赖。消除主属性对键对传递函数依赖。

## 1.3. Truncate、drop、delete 区别

- Truncate 和 drop 不走事务，不触发 trigger。
- Truncate 和 drop 是 ddl 语句。Delete 是 dml 语句。

## 1.4. Varchar (11) 与 Int (11) 区别

varchar 指定存储长度，int 指定显示长度。注意 varchar 的 order by 排序时使用 fixed_length 计算 col 长度。

## 1.5. Count 的区别

- Count 是扫描表中有多少条数据，然后将数据行数求和返回结果的。为什么不缓存一个表的记录数这样一个字段呢？因为每个事务可能查到不同的条数。
- Count 的各个区别
	- Count (\*)，取出一条数据就 + 1，这是 Mysql 官方的优化方式。
	- Count (1)，取出一条数据就 + 1，这是人为操作的优化方式。
	- Count (field)，取出一条数据的 field 字段，若字段不为空，则 +1，否则不加。

## 1.6. 数据库事务 ACID

## 1.7. 并发带来的问题

- 脏读
- 丢失修改
- 不可重复读
- 幻读

## 1.8. 数据库隔离级别

- Read-UnCommitted
- Read-Committed
- Repeatable-Read
	在此隔离级别下，存在 MVCC 模式。对于每一个操作，都会产生一个 undo 日志，undo 日志会和事务产生关联。因此如果一个事务非常长的话那么就会占用很大的 undo 日志空间。Undo 日志删除的条件是没有比这个日志更早的 read-view，所以要尽量避免长事务。
- Serializable

# 2. Mysql 基础知识

## 2.1. Mysql 常用引擎

- MyISAM，全表锁，无事务、外键，非聚集索引。
	- Innodb，行级锁，有提交回滚等事务特性。支持自增列，外键，并发强。占用空间是 MyISAM 的 2.5 倍。主键为聚集索引。
	- Memory，表锁
	- Merge，MyISAM 表的组合

## 2.2. Kill 语句的执行过程

Kill 语句分为两个：
- Kill query + 线程 ID
	该语句执行后，做了以下两件事情：
	1. 把 session B 的运行状态改成 THD :: KILL_QUERY (将变量 killed 赋值为 THD :: KILL_QUERY)。
	2. 给 session B 的执行线程发一个信号。
- Kill connection + 线程 ID

对于 kill，实际操作是按以下方式进行的：
1. 一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 THD :: KILL_QUERY，才开始进入语句终止逻辑。
2. 如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处。比如 IO 阻塞的话，就不会随便被唤醒。
3. 语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。

Kill 语句执行后耗时长的原因
- 线程没有执行到判断线程状态的逻辑
- 终止逻辑耗时长。如执行大事务期间被 kill，需要回滚所有操作，比如删除中间的临时文件之类。

## 2.3. Join 语句的执行过程

`select * from t1 straight_join t2 on (t1.a=t2.a);`，执行以上这条语句，Mysql 内部是如何处理的呢？

在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

### 2.3.1. 被驱动表有索引的情况

1. 从表 t1 中读入一行数据 R。
2. 从数据行 R 中，取出 a 字段到表 t2 里去查找。
3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分。
4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。

这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为 `Index Nested-Loop Join`，简称 NLJ。

### 2.3.2. 被驱动表无索引的情况

由于被驱动表无索引，因此是全表扫描。所以先要从驱动表中取出一条数据，然后到被驱动表去做全表扫描判断是否匹配。假设驱动表行数为 N，被驱动表为 M，则实际扫描行数就是 N\*M。这种直接扫描的做法我们称之为 `Simple Nested-Loop Join`。

显然如果直接扫描的话，那么代价太大了。因此 Mysql 实现时对这种查询做了以下优化：
1. 把表 t1 的数据读入线程内存 `join_buffer` 中，由于我们这个语句中写的是 select \*，因此是把整个表 t1 放入了内存。如果表数据超过 `join_buffer` 限制，就只会先放一批数据，等这批数据扫描完了再读取下一批数据。
2. 扫描表 t2，把表 t2 中的每一行取出来，跟 `join_buffer` 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

优化的算法我们称之为 `Block Nested-Loop Join`，简称 BNL

### 2.3.3. NLJ 算法优化途径-BAK 算法

NLJ 通过索引查询被驱动表，效率对比无索引的情况已经好很多了。但是还有一个问题时驱动表往被驱动表匹配数据时还是按行匹配的，即驱动表数据有多少条，被驱动表就要扫描索引多少次。而当每次扫描的索引比较散乱时，那么性能就相对较差。

能不能有一种方式顺序扫描被驱动表的索引呢？将被驱动表的随机读转化为顺序读，这是我们想到的一种优化途径。由此我们引入了 `Multi-Range Read 优化 (MRR)` 这一设计。

如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：
1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中。
2. 将 read_rnd_buffer 中的 id 进行递增排序。
3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

`read_rnd_buffer` 的大小是由 `read_rnd_buffer_size` 参数控制的。如果步骤 1 中，`read_rnd_buffer` 放满了，就会先执行完步骤 2 和 3，然后清空 `read_rnd_buffer`。之后继续找索引 a 的下个记录，并继续循环。另外需要说明的是，如果你想要稳定地使用 MRR 优化的话，需要设置 `set optimizer_switch="mrr_cost_based=off"`。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 `mrr_cost_based` 设置为 off，就是固定使用 MRR 了。）

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220515173810.png)

有了以上概念，我们就可以优化 NLJ 算法了。MySQL 在 5.6 版本后开始引入的 Batched Key Access (BKA) 算法了。这个 BKA 算法，其实就是对 NLJ 算法的优化。

基于 MRR，将驱动表的数据查询出来后放到 `join buffer` 中，然后再去被驱动表查询。这就进行了一定程度的优化。通过设置 `set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';` 来启用 BAK 算法。

### 2.3.4. BNL 转 BAK 算法

通过给无索引的被驱动表加索引的方式，可以将 BNL 算法优化为 BAK 算法。如果被驱动表上数据量太大不方便加索引的话，考虑将需要的数据抽取到临时表，使用临时表来查询也是一种方式。

### 2.3.5. Hash Join

在上面我们发现一个问题，对于驱动表与被驱动表的匹配，匹配次数是驱动表行数 N\*被驱动表行数 M。这个原因是因为驱动表的数据在内存中是一个数组，如果我们将内存中存储的方式改为哈希表，那么只需要匹配被驱动表的次数 M 就行了。

在 Mysql 老版本的方式中还不支持 Hash Join 的方式，在新版本 Mysql8.0.18 已经支持 Hash-Join。 8.0.20 版本以上官方已经移除 BNL 的支持, 全部替换成 Hash-Join。

## 2.4. 临时表

### 2.4.1. 临时表概念

通过 `create temporary table` 来创建临时表，临时表有以下特性：
- 一个临时表只能被创建它的 session 访问，对其他线程不可见。在 session 结束的时候临时表自动删除。
- 临时表可以与普通表同名。
- session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。
- show tables 命令不显示临时表。
- 临时表的表名存储为临时文件目录下，文件名的后缀是. frm，前缀是“#sql{进程 id}\_{线程 id}\_ 序列号"，这就可以使同一个表名达到复用的效果。这个进程 id 也会写入 binlog 日志，方便备注重放日志时可以获取到 id 进行表的建立。
- 当 binlog 日志格式设置为 statement 时，临时表的操作语句会同步到备库。而设置为 row 格式时，不会同步。因为 row 格式避免了对临时表的数据依赖，而 statement 无法避免。

临时表与内存表的区别：
- 内存表，是使用 Memory 引擎的表，建表语法是 `create table … engine=memory`。
- 这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。

### 2.4.2. 临时表处理分库查询问题

由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。

例如语句 `select v from ht where k >= M order by t_modified desc limit 100;` 通过 proxy 层无法很好的实现查询的需求，因此一种做法可以是从多个分库中查到数据汇聚到一个临时表中，然后利用生成的临时表执行该语句。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220515194528.png)

## 2.5. 内存表

### 2.5.1. 内存表出现的原因

- 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果。
- join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构。
- 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如 union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。

### 2.5.2. 内存表出现的场景

- 使用 union 操作，会生成一个临时表。表中存放 union 的结果，将插入的数据作为主键判断是否重复达到去重的效果。如果是使用 union all 操作，就不会生成临时表了。

- 使用 dintinct 操作，也会生成临时表，利用唯一键的特性去重。

- 使用 group by 操作，若 group by 中途需要临时存储数据，则会用到临时表。如 `select id%10 as m, count(*) as c from t1 group by m order by null;` 语句需要临时表来存储 id%10 的结果。

	像上面这条 sql，可以采用新增一列存储数据来避免临时表的生成。如 `alter table t1 add column z int generated always as(id % 100), add index(z);` 来实现数据的级联更新。这样统计时直接走到索引上去就不会生成临时表了。
	
	直接使用排序来代替临时表的生成，`select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;` 来告诉优化器，直接使用磁盘临时表来进行排序。该语句将会按以下策略执行：
		1. 初始化 sort_buffer，确定放入一个整型字段，记为 m。
		2. 扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中。
		3. 扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）。
		4. 排序完成后，就得到了一个有序数组。
		5. 根据数组统计结果

### 2.5.3. 内存的组织结构

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220515215434.png)

内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。

可见，InnoDB 和 Memory 引擎的数据组织方式是不同的：
- InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为**索引组织表（Index Organizied Table）**。
- Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为**堆组织表（Heap Organizied Table）**。
- InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的.
- 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值.
- 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引。
- InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
- InnoDB 支持变长数据类型，不同记录的长度可能不同。
- 内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar (N)，实际也当作 char (N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

内存表的特性：
- 除了 hash 索引，也可以使用 B-tree 索引。
- 锁的粒度是表锁。
- 数据在内存中，不能持久化。
- 主从之间数据会丢失，从库重启后数据就没了，备库重启后也会产生删除数据的 binlog 日志传给主库。
- 内存表不支持事务。

注意内存表和临时表的概念，临时表使用 `temporary`，用于表示这个表是临时的，是 session 独占的。而内存表是使用 `engine=memory`，数据存放到内存中，这是两个概念。这两者也可以结合使用，如：`create temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;`

## 2.6. 主键自增规则

通过 `show create table 't';` 能查询到关于表结构的信息，同时还有一个字段是 `AUTO_INCREMENT='number'`，这个值就是下一次自增应当生成的数据主键值，那么这个值是如何生成与存储的呢？

### 2.6.1. 自增值的存储

表的结构定义放在. frm 文件中，但是不会保存自增值。各个引擎对自增值有不同的保存策略：
- MyISAM 引擎保存在数据文件中。
- InnoDB 存储引擎保存在内存中。到 Mysql8.0 版本以后才有了自增值持久化保存的能力。
	- 对于 MySQL5.7 及以前的版本：自增值保存在内存，重启后通过 `max(id)` 计算下一个自增值。这意味着重启后计算的自增值可能与当前不同。
	- 对于 8.0 版本，自增值记录在了 redolog 中，重启依靠 redolog 恢复。

### 2.6.2. 自增值修改

对于一条新数据的插入，执行以下步骤
- 插入数据未指定主键值，使用当前自增值，使用完后自增值自增。
- 指定主键值，直接使用给定值。插入后判断主键值与子增值关系，若主键值>自增值，则自增值更新新的自增值。

自增值生成算法是：从 `auto_increment_offset` 开始，以 `auto_increment_increment` 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。其中，`auto_increment_offset` 和 `auto_increment_increment` 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。

在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 `auto_increment_increment=2`，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突。

### 2.6.3. 自增值不连续的场景

什么时候会出现数据库中自增主键不连续的情况呢？
1. 手动删除/更改了中间数据。
2. 插入数据时例如唯一键冲突，导致分配的自增值插入失败，但自增值已被改变。
3. 事务回滚。
4. 使用类似于 `insert table t1 select t2` 的场景，因为不确定插入的数据量，因此 MySQL 插入时申请的主键值时按 2 的幂次方申请的，这就可能造成申请的数据用不完浪费的情况。

### 2.6.4. 自增值不能回退的原因

上面提到了如事务回滚，插入冲突时自增值不会回退的现象。这样做的原因时为了解决以下问题：
- 如果允许回退，则需要做到多事务之间的自增值控制，这个所的粒度大影响性能。
- 在回滚的前提下，避免多个事务之间申请到同一个自增值。要实现这个代价高。

### 2.6.5. 自增锁的优化

自增锁是申请完即释放的，但这个规则其实是可以配置的，MySQL 5.1.22 版本引入了一个新策略，新增参数 `innodb_autoinc_lock_mode`，默认值是 1：
- 设置为 0 ，表示采用之前 MySQL 5.0 版本的策略，语句执行结束后才释放锁。
- 设置为 1 ：普通 insert 语句，自增锁在申请之后就马上释放；类似 `insert … select` 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放。
- 设置为 2 ，所有的申请自增主键的动作都是申请后就释放锁。

注意如果这个值设置为 2 的话，那么 binlog 格式必须要设置成 row。否则可能会出现 `insert … select` 这个语句日志重放效果与执行效果不一致的现象。如原本事务 A 在执行 `insert … select` 期间，事务 B 插入了一条数据。若事务 A 在插入数据之后又申请了主键值，则事务 A 的主键值是不连续的。但这个操作对于使用 statement 格式的计期，重放 binlog 日志是还原不回来的。

## 2.7. Mysql 授权语句

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220516124736.png)
授权语句的变化情况如上所示，注意，在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 ua@ip1 和 ua@ip2 代表的是两个不同的用户。

`flush privileges` 使用场景：
当未通过授权语句 grant 或者 revoke 进行授权，而直接更改了授权表当数据时，需要手动刷新授权数据。当然不建议直接更改数据库当数据！

## 2.8. Mysql 分区表

创建表的时候可以使用 `PARTITION BY RANGE (YEAR(ftime))` 来让 Mysql 根据字段创建分区表。如以下 SQL 语句：
```sql

CREATE TABLE `t` (
  `ftime` datetime NOT NULL,
  `c` int(11) DEFAULT NULL,
  KEY (`ftime`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1
PARTITION BY RANGE (YEAR(ftime))
(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
 PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
 PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);
insert into t values('2017-4-1',1),('2018-4-1',1);

```

分区表的特性
- 分区表对引擎层是多张表。
- 分区表对 server 层是一张表。
- 分区表对行加锁时只会在引擎层涉及到的数据进行加锁，不会锁住全部的分区表。
- 分区表加表加锁时是持有的整个表的 MDL 锁，因为对于 server 层来说只有一张表。
- MySQL 在第一次打开分区表的时候，需要访问所有的分区。

分区表的应用场景：
- 分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。
- 可以直接通过 `alter table t drop partition ...` 这个语法删掉分区，从而删掉过期的历史数据。
- 除范围分区外，MySQL 还支持 hash 分区、list 分区等分区方法。

## 2.9. Mysql 中的那些 ID

- 表自增值 ID，自增值 ID 从 1 开始，最大值为定义整数的最大值。当达到最大值时，再次插入相同的值就会报错。

- 系统自增 `row_id`，当未指定主键值时，就会生成一个隐式的 row_id。
	- InnoDB 维护了一个全局的 `dict_sys.row_id` 值，用于分配给无主键的表，这也是自增的。长度为 6 字节无符号整数。
	- 当超过这个值时，会从 0 开始重新循环分配。而且对于重复的数据会覆盖数据，不会报出键重复错误。

- XID，redo log 日志与 binlog 日志关联的 ID。Mysql 维护了一个全局的 `global_query_id`，执行语句时将其赋值给 `Query_id`。
	- 若当前语句是事务的第一条语句，就会把这个 ID 分配给当前事务。
	- global_query_id 是一个纯内存变量，重启之后就清零了。所以 XID 是会重复的，但重启后 binlog 日志也会重新生成，因此对于同一个 binlog 日志，理论上不会重复。
	- 同一个 binlog 日志中重复出现的情况是事务已经执行了 `2^64-1` 次，然后从 0 开始重新循环生成。

- `Innodb trx_id`，用于记录事务的 ID。
	- InnoDB 内部维护了一个 `max_trx_id` 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。
	- update 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1，因此在一个事务中至少加 2；
	- 当未真正开始事务时，这个值计算规则为：把当前事务的 trx 变量的指针地址转成整数，再加上 2^48。
	- max_trx_id 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个 MySQL 服务跑得足够久，就可能出现 max_trx_id 达到 2^48-1 的上限，然后从 0 开始的情况。这就会引起脏读的出现。但这个需要的事务量和时间非常大。
	- 只读事务不分配事务 ID
		- 第一点是为了减少活跃事务的数量，例如 MVCC 视图就不用判断那么多的事务。
		- 减少 trx_id 的申请次数。

	- threid，当前执行线程 id，4 字节。保存在内存中，每次递增。

## 2.10. binlog 使用 row 格式的因素

- row 格式避免同步数据错误，statement 格式受事务提交顺序影响大。
- 在使用临时表时 row 格式无需同步临时表操作到备库，statement 格式需要。
- 使用 row 格式，无需担心 `insert...select` 这种语句的主键申请问题。
- 对于主从备份，采用 binlog 格式可以尽早发现备库与主库的数据不一致问题（在主备切换策略采取的是可用性优先策略下）。

## 2.11. OnlineDDL

### 2.11.1. OnlineDDL 的原理

在 MySQL 的早期版本中，DDL 操作因为锁表会和 DML 操作发生锁冲突，大大降低并发性。在早期版本中，大部分 DDL 操作的执行原理就是通过重建表的方式，因为要复制原表数据，所以会长时间锁表，只能读不能写，DDL 操作和 DML 操作有很严重的冲突。从 MySQL5.6 开始，很多 DDL 操作过程都进行了改进，出现了 Online DDL，用于支持 DDL 执行期间 DML 语句的并行操作，提高数据库的吞吐量。

MySQL 在线 DDL 分为 `INPLACE` 和 `COPY` 两种方式，通过在 ALTER 语句的 ALGORITHM 参数指定：
-   `ALGORITHM=INPLACE`，可以避免重建表带来的 IO 和 CPU 消耗，保证 ddl 期间依然有良好的性能和并发。
-   `ALGORITHM=COPY`，需要拷贝原始表，所以不允许并发 DML 写操作，可读。这种 copy 方式的效率还是不如 inplace ，因为前者需要记录 undo 和 redo log，而且因为临时占用 buffer pool 引起短时间内性能受影响。

上面只是 Online DDL 内部的实现方式，此外还有 LOCK 选项控制是否锁表，根据不同的 DDL 操作类型有不同的表现：默认 MySQL 尽可能不去锁表，但是像修改主键这样的昂贵操作不得不选择锁表：
-   `LOCK=NONE`，即 DDL 期间允许并发读写涉及的表，比如为了保证 ALTER TABLE 时不影响用户注册或支付，可以明确指定，好处是如果不幸该 alter 语句不支持对该表的继续写入，则会提示失败，而不会直接发到库上执行。
-   `LOCK=SHARED`，即 DDL 期间表上的写操作会被阻塞，但不影响读取。
-   `LOCK=DEFAULT`，让 mysql 自己去判断 lock 的模式，原则是 mysql 尽可能不去锁表。
-   `LOCK=EXCLUSIVE`，即 DDL 期间该表不可用，堵塞任何读写请求。如果你想 alter 操作在最短的时间内完成，或者表短时间内不可用能接受，可以手动指定。

但是有一点需要说明，无论任何模式下，Online DDL 开始之前都需要一个短时间排它锁 (exclusive) 来准备环境，所以 alter 命令发出后，会首先等待该表上的其它操作完成，在 alter 命令之后的请求会出现等待 `waiting meta data lock`。同样在 DDL 结束之前，也要等待 alter 期间所有的事务完成，也会堵塞一小段时间。所以尽量在 ALTER TABLE 之前确保没有大事务在执行，否则一样出现连环锁表。

| 操作                              | 支持方式   | Allow R/W                | 说明                                                                                                          |
| --------------------------------- | ---------- | ------------------------ | ------------------------------------------------------------------------------------------------------------- |
| add/create index                  | online     | 允许读写                 | 当表上有 FULLTEXT 索引除外，需要锁表，阻塞写                                                                    |
| drop index                        | online     | 允许读写                 | 操作元数据，不涉及表数据。所以很快，可以放心操作                                                              |
| optimize table                    | online     | 允许读写                 | 当带有 fulltext index 的表用 copy table 方式并且阻塞写                                                            |
| alter table... engine=innodb       | online     | 允许读写                 | 当带有 fulltext index 的表用 copy table 方式并且阻塞写                                                            |
| add column                        | online     | 允许读写 (增加自增列除外) | 1、添加 auto_increment 列要锁表，阻塞写; 2、虽采用 online 方式，但是表数据需要重新组织，所以增加列依然是昂贵的操作 |
| drop column                       | online     | 允许读写 (增加自增列除外) | 同 add column，重新组织表数据，，昂贵的操作                                                                    |
| Rename a column                   | online     | 允许读写                 | 操作元数据; 不能改列的类型，否则就锁表                                                                         |
| Reorder columns                   | online     | 允许读写                 | 重新组织表数据，昂贵的操作                                                                                    |
| Make column NOT NULL              | online     | 允许读写                 | 重新组织表数据，昂贵的操作                                                                                    |
| Change data type of column        | copy table | 仅支持读，阻塞写         | 创建临时表，复制表数据，昂贵的操作                                                                            |
| Set default value for a column    | online     | 允许读写                 | 操作元数据，因为 default value 存储在 frm 文件中，不涉及表数据。所以很快，可以放心操作                            |
| alter table xxx auto_increment=xx | online     | 允许读写                 | 操作元数据，不涉及表数据。所以很快，可以放心操作                                                              |
| Add primary key                   | online     | 允许读写                 | 昂贵的操作                                                                                                    |
| Convert character set             | copy table | 仅支持读，阻塞写         | 如果新字符集不同，需要重建表，昂贵的操作                                                                      |

### 2.11.2. OnlineDDL 的过程

OnlieDDL 执行过程：
1. 拿 MDL 写锁
2. 降级成 MDL 读锁
3. 真正做 DDL，这里不会阻塞读写操作。对于这段期间的数据库操作，会存放到临时日志文件中。
4. 升级成 MDL 写锁，并重放 DDL 期间产生到数据变更命令。
5. 释放 MDL 锁

同时测试发现，**DDL 语句是不受事务控制的**，无法采用 begin/rollback 控制语句的执行过程。

# 3. Mysql 索引

- 聚集索引，Mysql 会自动将主键索引放到其他索引的后面
- 覆盖索引：在联合索引上就有待查询待全部字段无需回表。
	- 索引下推：当索引上条件能判断时就不会回表判断。
- 联合索引
	- 联合索引的最左匹配原则，从左边开始的字段能走上索引，遇到范围查询 (>,<, between, like 停止)
	- 若 (a, b) 为联合索引，查询条件 b = xx and a = xx 也能走上索引，引擎会自动优化。
- 前缀索引，Mysql 支持指定字符串或二进制的前 n 位构建索引。当前缀区分度不高时，可以考虑使用后缀，即 reverse (field) 代替。或者新加一个字段，这个字段调用 crc32 () 这样的 hash 函数进行拓展字段建立。需要注意的时候**当使用了前缀索引后就无法使用到覆盖索引这个特性了，因为数据库就无法判断该索引上是否包含完整的值因此需要回表判断。**
- 唯一索引
- 普通索引：如果没有特别要求，索引尽量选择普通索引。普通索引可以使用 **ChangeBuffer 进行缓冲**，从而改善性能。
- 索引重建
	- 目的：索引可能因为删除，页分裂等原因造成数据空洞。重建索引会创建新的索引，时页面利用率最高。索引更紧凑，更省空间。
	- 重建非主键索引：`drop index`
	- 重建主键索引：避免使用 `drop primary key`，因为这个会先删除旧的主键索引，然后 innodb 又自己使用了一个临时主键索引，最后又自己指定了主键索引。导致主键重构两次。用 `alter table T engine=InnoDB` 代替。
		- `alter table T engine=InnoDB` 是一个重建表的操作，会基于原来的表 inplcae 一个新的表出来。过程是 Online 的，在语句执行的时候会先获取 MDL 的写锁，之后会退化成读锁，避免阻塞增删改查。
		- `analyze table t` 是一个重建表“索引数据评估情况”的操作。
		- `optimize table t` 等于 recreate + analyze。
- 索引评估：数据库评估索引的扫描行数是基于采样分析的，可能不准确。可以使用 `analyze table t` 来使数据库对索引情况进行重新评估，从而使扫描行数变准确。
- 自适应哈希索引

# 4. SQL 语句的执行过程

## 4.1. SQL 各关键字执行顺序

1. from 表做笛卡尔积
2. 执行 on 过滤
3. 添加外部行，这里在左连接或右连接才会有
4. 执行 where 过滤
5. 执行 group By 分组
6. 执行 having 过滤
7. 执行 select 列选择
8. 执行 distinct 过滤数据 (这里会生成临时表，在过滤列上加唯一索引)
9. 执行 order by 语句
	- order by 排序算法有两种，全字段排序与 rowId 排序
		- 全字段排序，使用时会根据条件筛选出所有满足条件的数据，然后对数据按给定的字段排序。排序过程中每条数据是全字段，排序完即可返回数据
		- RowId 排序，排序时若一条数据过长，超过 `max_length_for_sort_data` 时，就会采用 rowId 排序。此时排序的数据就只有排序关键字与主键 ID。**排序完毕后根据主键 ID 回表再次查出数据**。这里回表时就可能涉及到磁盘的读写了。
		- 如果**满足了索引覆盖的条件的话，那么就不会有排序动作**了。从 B+树取出来的数据本身就是有序的。
	- 排序过程
		- 排序时会优先在内存中进行快速排序，当内存数据不足时会使用磁盘进行辅助排序。
		- 使用磁盘辅助排序时，将数据分割成小文件，每个小文件使用归并排序，排序完毕后进行合并返回。
	- `order by rand ()` 的实现
		- 首先会在内存中新建临时表，临时表长度不够的话会在磁盘中建。当超过 `internal_tmp_disk_storage_engine` 值时就会生成磁盘的临时表。临时表的内容为排序字段与为每条数据生成的一个随机数 r。
		- 在生成的临时表中使用随机数 r 进行排序。
			- 对生成的临时表排序，会优先使用 rowId 排序算法。因为这样可以减少数据量。
			- 对于排序过程，若是指定的 limit 小的话，会使用优先队列排序。如 limit3 则只会维护三个最大值/最小值。避免全排序。
			- 若是 limit 大的话，超过排序的 `sort_buffer_size` 时就会使用归并排序了。
		- 排序完毕按 limit 取数。
10. 执行 limit 语句

## 4.2. SQL 语句在 Mysql 内部的执行过程

1. 取得数据库连接器
2. 查询缓存，Mysql8.0 中已移除
3. SQL 词法语法分析
4. 优化器优化，如使用哪个索引，join 连接顺序
5. 执行器执行

## 4.3. 数据流转过程

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220515155935.png)

数据是一个**边读边发**的过程：
1. 获取一行数据，将其写入到 `net_buffer` 中。这块内存的大小是由参数 `net_buffer_length` 定义的，默认是 16k。**该区域每个线程独有**。
2. 重复获取行，直到 `net_buffer` 写满或者行读取结束。
3. 调用网络接口将数据发送给客户端。
4. 发送完成，清空 `net_buffer`。若还有数据，就继续上面的流程。
5. 如果发送函数返回 `EAGAIN` 或 `WSAEWOULDBLOCK`，就表示本地网络栈（`socket send buffer`）写满了，进入等待。直到网络栈重新可写，再继续发送。
6. 在发送数据给客户端这一阶段，线程的状态是 `Sending to client`。还有一个状态是 `Sending data`，当 SQ 语句进入执行阶段后，状态就会设置成 `Sending data`。
7. 对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，建议你使用 `mysql_store_result` 这个接口，直接把查询结果保存到本地内存。放置客户端未及时读取而阻塞数据库。

如果发现一个语句长时间处于 `Sending to client` 状态，可以按以下方向排查处理：
- 使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。
- 优化查询结果，并评估这么多的返回结果是否合理。
- 如果要快速减少处于这个状态的线程的话，将 `net_buffer_length` 参数设置为一个更大的值是一个可选方案。`net_buffer_length` 调大以后查询结果就会扔到缓存中，执行器就可以认为查询结束了。虽然网络栈还是慢慢发的，但是那些没发完的都缓存在 net_buffer 中，对于执行器来说，都是“已经写出去了”。

# 5. MVCC 的实现原理

## 5.1. undo 日志

记录数据的历史变化情况，通过 undo 日志可以追溯到以前的数据。

## 5.2. ReadView

Mysql 的数据隐藏列中包含以下几个字段：
- roll_pointer，指向 undo 日志。
- trx_id，指向这条日志产生的源事务 ID。
- row_id，当没有主键是隐藏的主键 ID。

在执行增/删/改的时候，每操作一次就会产生一条 undo 日志。Undo 日志包含上述的字段内容，根据 roll_pointer 就可以产生一条版本链。基于版本链的情况下，当查询操作产生的时候就会构造 ReadView 视图，从版本链中获取数据。

生成 ReadView 视图时会包含以下内容：
- m_ids：生成 ReadView 视图时活跃的事务 ID 列表。
- creator_trx_id：生成 ReadView 视图的事务 ID，即当前事务 ID。
- max_trx_id：生成 ReadView 视图时应该分配给下一个事务的 ID。
- min_trx_id：生成 ReadView 视图时活跃事务列表中最小的事务 ID。

- MVCC 的规则如下：
1. 若当前版本链上数据的事务 ID 等于 creator_trx_id，表示数据由当前事务产生，可读。
2. 若当前版本链上数据的事务 ID 大于 max_trx_id，表示数据是视图创建之后产生的，不可读。往版本链往前找。
3. 若当前版本链上数据的事务 ID 小于 min_trx_id，表示数据是视图创建之前产生的，可读。
4. 若当前版本链上数据的事务 ID 在 m_ids 列表中
	- 事务未提交：不可读。
	- 事务已提交
		- RC 级别下，数据可读。
		- RR 级别下，需要保持可重复读的特性，因此不可读。有一种特殊情况，若当前事务先对其进行更新操作，**更新会触发当前读**获取到最新数据更新。更新完之后该数据事务 ID 会变成当前事务 ID，当前事务就可读到了。

# 6. Mysql 的锁

## 6.1. 锁分类

- 按范围分类
	- 数据库锁：对数据库加锁。
		- `flush tables with read lock (FTWRL)`，使数据库处于只读状态
		- 如果只是备份的话可以使用 `mysqldump–single-transaction` 来保证隔离型的读。注意使用这个语句需要所有数据表都是 InnoDB 引擎的。
		- 使用 `set global readonly=true` 的方式。这种方式有两个问题，其一是这个值通常用来处理一些其他情况，如是主库还是从库。另一个是修改 global 影响大，FTWRL 中断后自动释放锁，而 readonly 设置确不会。
	- 表锁
		- `lock tables ... read/write`，主动开启与释放锁。线程 A 中执行 `lock tables t1 read, t2 write;` 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。
		- MDL (metadata lock)，是 Mysql5.5 版本增加的。会在操作一个表的时候自动加读/写锁。需要注意的是，在修改表结构的时候，**若前面有事务没释放锁，则修改表结构操作会阻塞。表结构操作阻塞后后续所有的请求都会阻塞。**
	- 行锁
	- 共享锁
	- 排他锁
- 按锁机制分类
	- 悲观锁
	- 乐观锁
- 按锁实现分类
	- S 锁
	- X 锁
	- IS 锁：意向共享锁。与表共享锁兼容，与表的其他锁互斥。意向锁仅用于表锁，不和行锁冲突。
	- IX 锁：意向排他锁。与表的所有锁互斥。
	- Gap 锁
	- Next-key 锁
- 锁升级
	- 当行锁无法匹配数据时，会升级到表锁
	- 当索引记录超过整表 1/2 时，会走到全表查询。行锁变表锁。

## 6.2. 死锁避免

- 设定超时时间。
- 设定资源访问顺序。
- 一次性申请全部资源。
- 银行家算法进行死锁避免。
- 避免事务交叉。
- 使用低隔离级别。
- 主动死锁检测，在尝试获取锁的时候进行死锁检测。当发现自己的操作可能发生阻塞时，就主动回滚事务让其他事务执行。`innodb_deadlock_detect` 默认就是开启的。这里检测的时候不会扫描所有事务，只会扫描和当前线程操作资源相关的事务。可以采用资源位图法进行死锁检测。

## 6.3. 死锁解除

当线程持有锁时间超过 `innodb_lock_wait_timeout` 时，就主动放弃锁回滚事务。这个值默认是 50s。

## 6.4. 两段锁协议

- 在 InnoDB 事务中，行锁是需要的时候加上去的，但并不是不需要了就立刻释放，而是等到事务结束才释放。这就是两阶段锁协议。
- 如果你的事务需要锁多个行，那么尽可能把造成锁冲突的，影响并发的语句往后放。

## 6.5. 加锁过程

### 6.5.1. RU/RC 级别

- 主键索引
	- 等值查询
		加 X/S 锁，若是更新操作，会为涉及数据字段的二级索引加锁。若是删除操作，会对涉及数据的所有二级索引加锁。
	- 范围查询
		从满足条件的数据开始加锁，加锁规则与等值查询相同。当下一条数据不满足条件时，会先加锁再释放锁 (5.7 版本实验结果)。所以要注意锁争用问题。
- 普通索引
	- 等值查询
		加 X/S 锁，若是不满足索引下推条件需要回表，还会对主键索引进行加锁。这里不会出现对下一个不满足条件对数据加锁的情况。
	- 范围查询
		加锁同等值查询。若是查询语句，当下一个数据不满足条件时，会将二级索引加锁，但是不会释放锁。若是更新语句，则会先对二级索引和主键索引加锁，然后发现不满足条件又释放锁。(5.7 版本实验结果)。更新操作无法使用索引下推特性，因此才会对二级索引和主键索引都加锁。
- 无索引
	存储引擎扫描一行就对该行加 S/X 锁，返回 Server 层发现不满足条件后又释放锁。若是更新操作，还会对涉及到对二级索引加锁。
- 半一致性读
	在 RC 级别下，update 语句有个 `semi-consistent` 优化，当 update 语句碰见一个已经被锁住的行，会取出最新数据判断以下是不是满足条件。如果不满足条件就直接跳过，如果满足条件就进入锁等待。

### 6.5.2. RR 级别

- 加锁规则
	- 原则 1：加锁的基本单位是 next-key lock。Next-key lock 是前开后闭区间。Next-key 锁实际上是间隙锁+行锁组成的。
	- 原则 2：查找过程中访问到的对象才会加锁。
	- 优化 1：索引上的等值查询，给主键索引加锁的时候，next-key lock 退化为行锁。
	- 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
	- 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。在 8.0.18 后已修复。
	- 利用索引的有序性，若一个数据的索引不在被加锁的区间内就不会受到影响。
	- 对于唯一索引，insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock (S 锁)。

- 加锁示例
	- 数据准备
		准备表 t (id, c, d)，其中 id 为主键，c 为普通索引，d 无索引。数据准备为 (0, 0)，(5, 5)，(10, 10)，(15, 15)，(20, 20)，(25, 25)

	- `update t set d = d+1 where id = 7;`
		会对主键索引 (5, 10) 区间加间隙锁。
	
	- `select id from t where c = 5 lock in share mode;`
		会对二级索引 c 加 Next-key 锁 (0, 5]与间隙锁 (5, 10)。由于索引覆盖，所以不会对主键索引加锁。Sql 查询字段若是改为 d，则回表会导致主键索引也被加锁。
	
	- `select * from t where id>=10 and id<11 for update;`
		会对主键索引行 10 以及 next-key 锁 (10, 15]进行加锁。其实这里发现 15 是不满足条件的，没必要进行加锁。在版本 8.0.19 上已经退化成间隙锁 (10, 15) 了。
	
	- `select * from t where c>=10 and id<11 for update;`
		这里 c 是普通索引，会对二级索引 c 加 next-key 锁 (5, 10]及 next-key 锁 (10, 15]进行加锁。同时对主键索引 10 加行锁。同 8.0.19 上后一个 next-key 锁会退化成间隙锁 (10, 15)。
		如果 c 是 uniqu 唯一索引的话，也还是 next-key 锁 (5, 10]及 next-key 锁 (10, 15]，前一个锁不会退化成行锁，只有主键索引会。测试版本为 8.0.20。
	
	- `select * from t where id>10 and id<=15 for update;`
		会对主键索引加 next-key 锁 (10, 15]及 (15, 20]进行加锁。8.0.18 后已优化唯一索引范围查询的加锁方式，只会有 (10, 15]的 next-key 锁。
	
	- 多增加一条数据 `insert into t values(30,10,30);`
		- `delete from t where c = 10;`
			此时存在两条 c=10 的数据，会对二级索引 c 加 (5: 5, 10: 10]，(10: 10, 10: 30]，(10: 30, 15:15)，同时对主键索引  10，30 加行锁。
		- `delete from t where c = 10 limit 2;`
			由于多了 limit 条件，因此扫描到两行后就会结束。此时加锁情况为对二级索引 c 加 (5: 5, 10: 10]，(10: 10, 10: 30]，对主键索引 10，30 加行锁。所以删除时如果行数确定的话尽量加上 limit 条件，这样可以减少锁的范围。
		- `select * from t where c >= 15 and c <= 20 order by c desc for update;`
			会对二级索引 c 加 (20, 25]，(15, 20]，(10, 15]，(5, 10]next-key 锁，同时对主键索引 10, 15,20, 25 加行锁。在 8.20 版本二级索引 c (20, 25]已优化为 (20, 25)，且主键索引无 25 的行锁。
			原因是因为这是倒序排序，所以索引会从后往前扫。扫描数据 15 时会发现仍满足条件，因此继续往前扫描一条数据，所以就对 10 也加上了锁。

	- 事务 A 执行 `select c from t where c > 5 for update;`，而后事务 B 先执行 `update t set c = 1 where c = 5`，之后再执行 `update t set c = 5 where c = 1;`
		首先 A 执行时会对二级索引 c 加 (5, 10], (10, 15], (15, 20], (20, 25], (25, supermum) 锁。事务 B 执行第一条语句时，c=5 列无锁，因此可以执行。但是执行后事务 A 的锁范围蔓延了，会变成 (1, 10)。之后事务 B 再次执行时，将 c=1 改为 c=5，更新操作其实是一个先增后删的操作，因此增加 c=5 这一列时就会被阻塞。

	- 死锁的例子
		![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220513130251.png)
		事务 A 加了 (5, 10]和 (10, 15) 的锁，事务 B 加 (5, 10]的锁时失败阻塞，事务 A 再次插入时进入死锁状态。原因是因为 next-key 锁实际上是由间隙锁+行锁组成的。所以 B 加锁时其实是先加 (5, 10) 的间隙锁，成功，后加行锁是阻塞的。而事务 A 再次插入时被事务 B 的间隙锁锁住，因此阻塞进入死锁。

# 7. Mysql 的高可用

## 7.1. 主备模式

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514143924.png)

在状态 1 中，虽然节点 B 没有被直接访问，但是依然建议把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：
- 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
- 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
- 可以用 readonly 状态，来判断节点的角色。

备库设置成只读了，还怎么跟主库保持同步更新呢？这个问题，不用担心。因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

主备的流程：

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514144050.png)

主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。

一个事务日志同步的完整过程是这样的：
- 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
- 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。
- Io_thread 负责与主库建立连接。主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
- 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
- Sql_thread 读取中转日志，解析出日志里的命令，并执行。这里需要说明，后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程。
- 对于后续主库产生的新日志，就推送给备库执行。
基于 binlog 进行数据备份。Binlog 有三种格式：
- statement：基于 SQL 语句级。
- row：基于 SQL 改变数据级。
- mixed：根据 SQL 情况，看是使用 Statement 级别还是 Row 级别。

## 7.2. 主备延迟

对于主库上发生的更改，延迟了一段时间才到达从库。从库在执行当前事务时，可以在事务的 binlog 日志中看到该事务在主库中执行的时间。通过这个时间与系统时间的插值，就可以得到主备之间的延迟时间，称之为 `seconds_behind_master`。

主备延迟产生的情况可能如下：
- 从库配置低于主库，导致执行慢。
- 从库压力大，在从库上可能有许多其它的操作。如数据分析查询之类，影响同步速度。针对这种，可以进行一主多从的配置来分摊从库压力，或者将部分逻辑迁移到其它组件中，例如使用 Hadoop 来进行数据统计。
- 大事务，当有大事务时，事务提交才会同步给从库。因此事务执行时间长的话也会导致从库同步慢。
- 大表 DDL，影响类似于大事务。对于计划内的 DDL，推荐使用 gh-ost 方案。
- 备库的并行复制能力。
- 若需要迫切的提升从库的读写能力，可以进行以下策略的优化：
	- 从库开启 writeset
	- 将 `sync_binlog` 改为 0，`innodb_flush_log_at_trx_commit` 改为 2 提升写数据能力。

## 7.3. 主备切换策略

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514154847.png)

### 7.3.1. 可靠性优先策略

- 判断当前从库的 `seconds_behind_master` 是否小于某个值，不小于就一直重试，小于开始进行主备切换。
- 将主库改为只读状态。
- 判断从库的 `seconds_behind_master` 是否为 0，不为 0 等待直到变为 0。
- 将从库状态改为读写。
- 请求切换到从库。

在从库提升为读写这段期间服务不可用，这是为了保证可靠性做出的妥协。主库异常时，若从库存在未同步完的数据，此时从库也无法切换。

### 7.3.2. 可用性优先策略

- 不等到从库同步完主库的数据就直接将从库改为主库，接受读写请求。
- 这种可能会导致数据不一致的情况，因为从原来主库同步的数据可能与新写入的数据发生冲突。
- 如果使用该模式，binlog 建议使用 row 格式的。这样可以尽可能减少数据冲突的情况，也能尽可能早的发现数据错误的情况。

## 7.4. 备库日志重放

### 7.4.1. 日志重放职责划分

当备库接收到主库的 binlog 日志后，需要进行重放操作。Mysql 最开始的版本提供的是单线程的重放模式，当主库日志非常多或者主库大事务阻塞之后提交给从库，那么这时候就会造成主从之间的数据延迟增大。为了改善这一情况引入了并行复制的能力。

并行复制采用了以下的规划：
- Coordinator 事务协调者，负责读取日志与将日志转发给后续的日志处理线程。协调者在分发日志时，需要注意以下要求：
	- 不能造成数据破坏，同一行的数据更改操作必须分发给同一个 worker。
	- 不能造成事务破坏，同一个事务操作必须分发给同一个 worker。
- Worker 日志重做者，负责对接受到的日志进行重放操作。

### 7.4.2. 事务分发协调算法

#### 7.4.2.1. 按库按表分发

- 对于同一个库/表操作的分发给同一个 worker，这样就避免了改动同一个库表。但是如果存在热点库/表，极端情况只有一个库/表的情况下，那么会退化成单线程模式。
	- 按表分发时，可进行以下规则判断：
		- 若当前事务涉及表没有其它 worker 在操作，可直接分发给一个空闲的 worker。
		- 若当前事务涉及表有一个 worker 在操作，直接分发给这个 worker。
		- 若当前事务涉及表有多个 work，等待。

#### 7.4.2.2. 按行分发策略

- 针对事务影响的行进行分发，需要注意不仅仅从主键维度考虑，还需要从其它索引的维度考虑，一条数据可能会有多个索引。
- 以行为维度 binlog 日志解析时会占用更多的计算资源。

#### 7.4.2.3. 按组提交时 CommitId 分发策略

- 对于同一组提交的事务，其数据操作一定不会出现冲突。若冲突，则必然会等到前一个操作提交后后一个事务才可继续操作。
- 基于这一个策略，所以可以对同一组内提交的事务分发给不同的 worker，当然还是得注意同一个事务的是不能分开的。
- 对于 Mysql 来说，其实不一定需要等到 Commit 标记才认为事务没有冲突，在 redolog 的 prepare 阶段就可以确认了。当到达 prepare 阶段，就代表已经通过了锁的检测，所以可以分开进行操作了。因此可以考虑优化 `binlog_group_commit_sync_delay` 与 `binlog_group_commit_sync_no_delay_count` 这两个参数的配置来控制主从之间同步的效率。

#### 7.4.2.4. 按 WRITESET 分发策略

在 Mysql5.7.22 的版本增加了一个新的策略，该策略有以下几种选择：
- COMMIT_ORDER：基于 prepare 和 commit 来判断是否可以并行。
- WRITESET：对事务涉及的每一行，计算这一行的 hash，组成集合 writeset。若两个事务没有操作同一行，则认为可以并行。
- WRITESET_SESSION：在 WRITESET 的基础上增加了一个限制，主库上存在先后关系的事务从库上也要保证这个顺序。

为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。Writeset 是在主库生成后直接写入 binlog 中的，因此不会额外占用从库的计算资源，这占用的是主库的计算资源。

**对于数据上没有主键或存在外键约束的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型**。

可以通过数据库的配置 `binlog-transaction-dependency-tracking` 来决定是否开启 WRITESET 策略。

## 7.5. 从库拉取主库数据

现在的数据库架构大多都是一主多从架构，那么这些从库如何拉取主库的数据呢？在主库发生切换的时候，从库基于什么规则拉取才能做到数据一致呢？
![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514175012.png)
![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514175033.png)

### 7.5.1. 基于 binlog 的 position 拉取

1. 等待新主库 A’把中转日志（relay log）全部同步完成。
2. 在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position。
3. 取原主库 A 故障的时刻 T。
4. 用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。

这样得到的位点并不一定准确，时刻 T 时若主库 A 产生了 binlog 发给从库，后续从库会接受到这个日志。而时刻 T 从 A‘上读取位点的时候还不包含这个日志，因此这个日志就可能被重复执行。

对于插入操作，就会抛出主键重复错误，因此主备切换时通常要跳过这些错误。跳过作物的常用方法有：
- 主动跳过一个事务：`set global sql_slave_skip_counter=1;`
- 跳过一些指定类型错误：`slave_skip_errors`，如 1062 是唯一键冲突错误，1032 是删除时找不到行错误。这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。等主备同步完需要切换回去。

### 7.5.2. GTID 算法

由上可以看到，通过位点的方式同步数据并不准确，而且还要处理同步过程中的错误。在 Mysql5.6 版本引入了 GTID，Global Transaction Identifier，全局事务 ID。GTID 由两部分组成：server_uuid: gno，server_uuid 在 mysql 启动时生成，geo 在事务提交时自增。

在 GTID 模式下，每个事务都会与一个 GTID 对应。这个 GTID 有两种生成方式，取决于 session 中 gtid_next 的值：
- `gtid_next=automatic`
	使用默认自增值，在事务提交时 Mysql 会自动自增生成一个 GTID 并分配给该事务。同步将生成的 GTID 写入到 Mysql 的 GTID 集合与该事务的 binlog 中。
- Session 指定值
	- 若指定值已存在 Mysql 实例的 GTID 集合，则该事务被忽略。
	- 不存在，将 GTID 分配给该事务并执行。一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 GTID 或者 automatic。

有了 GTID 算法，在进行主备切换时就无需指定位点了。同步时从库将自己的 GTID 集合传递给主库，主库与自己的 GTID 集合做差集。对于差集结果有以下处理：
- 差集中包含不在主库中的 GTID，代表主库已经将该 binlog 给删除了，返回错误。
- 若全部包含，就将需要的 binlog 发送给从库。
- 这个逻辑里面包含了一个设计思想：在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例 B 需要的日志已经不存在，A’就拒绝把日志发给 B。这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。
- 对于有问题的事务日志，就可以通过 `set gtid_next='id';` 将其排除，不影响主备流程。

## 7.6. 读写分离保证读数据准确性

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514205909.png)

### 7.6.1. 读写分离的方案

- 客户端主动做负载均衡：这种情况下将数据库连接放在客户端，由客户端选择从哪个数据库查询。这种模式需要客户端管理配置，并且对数据库配置信息改动时需要增加处理机制。
- 中间层代理：客户端与中间代理层交互，代理层分发请求到不同数据库。这种模式会略微损失一些行能，但客户端侧就无需关注过多关于数据库的细节。

### 7.6.2. 读写分离延迟问题

读写分离，写操作发生在主库，读操作发生在从库。当主库的变更日志未到达从库之前，从库读到的都不是最新的数据。解决这一问题有以下几种办法：

#### 7.6.2.1. 强制走主库读

对于必须拿到最新数据的请求，从主库查。可以读到旧数据的请求，从从库查。这个方案的问题是当所有请求都无法接受读到旧数据时，所有请求都会落到主库中。

#### 7.6.2.2. Sleep 方案

针对主从之间的延迟，估算一个时间，然后读请求产生的时候先 sleep 一下，以此来保证主从同步。这个方案的问题是时间估算并不一定准确。或者另一个思路是将这个延迟坐在用户端，让前端先直接将数据展示到页面而不是从数据库查，下次刷新时再从数据库查。

#### 7.6.2.3. 判断主备无延迟方案

在查询从库时，判断当前主从是否有延迟。若当前主从无延迟，就可以从从库读。判断延迟有以下几种方案：
- 利用 `show slave status;` 返回的 `seconds_behind_master` 查看，若这个值不为 0，则需要等待。
- 对比点位判断延迟
	Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。
- 对比 GTID 集合判断延迟
	Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。如果这两个集合相同，也表示备库接收到的日志都已经同步完成。
		
需要注意的一点是 `show slave status;` 这只能表示当前从库收到的日志的处理情况，对于那些**主库还未同步到从库的日志，这段延时从库是判断不出来的**。`seconds_behind_master` 是计算收到的日志与当前时间的差值，这个日志并不一定是主库最新的日志。同理位点和 GTID 集合也不一定是主库最新的数据。
**同时还有另一点是若主库源源不断的有日志过来，那么这个延迟就一直不为 0**。

#### 7.6.2.4. semi-sync 半同步方案

半同步方案设计如下：
1. 事务提交的时候，主库把 binlog 发给从库。
2. 从库收到 binlog 以后，发回给主库一个 ack，表示收到了。
3. 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。

采用半同步方案，就能确保至少有一个从库是最新的数据。如果是一主一从，那么读延迟就可以解决了，如果一主多从的话，那么其它从库还是不能保证读取到最新数据。

#### 7.6.2.5. 等主库位点方案

`select master_pos_wait(file, pos[, timeout]);` 可以从主库查询位点信息，各参数作用如下：
- File，pos：主库文件名和位置。
- Timeout：从主库执行该命令的超时时间。

返回结果可能有以下几种：
- NULL：发生异常
- -1：timeout 时间
- 0：该 pos 位置的事务已在从库执行
- 大于 0 的整数 M：从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。

基于这个命令，可以进行如下操作：
1. 执行完更新语句后从主库获取当前的 File 和 position。
2. 选定一个从库执行上面的查询语句。
3. 如果返回值>=0，就在从库上执行该查询。
4. 否则到主库查询。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514211034.png)

#### 7.6.2.6. 等主库 GTID 方案

如果开启了 GTID 模式，则 GTID 也有类似的查询。`select wait_for_executed_gtid_set(gtid_set, 1);` 用于实现 GTID 的等待查询。

对于 GTID 的获取，可以主动查询，也可以在执行完请求后让数据库直接返回。具体做法如下：
1. 将参数 `session_track_gtids` 设置为 `OWN_GTID`。
2. 通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值。
3. 或者在客户端代码调用 `mysql_session_track_get_first;` 函数。

## 7.7. 可用性监控

### 7.7.1. 外部监控

需要注意的是外部监控有随机性，监控的时刻正常并不一定代表过去一直正常。

#### 7.7.1.1. `select 1;` 判断

通过 select 1 可以判断是否可以连接上数据库，但是无法判断当前数据库能否执行请求。比如当前数据库并发查询连接数已到了最大值 `innodb_thread_concurrency`，后续的请求都会阻塞，但是 select 1 仍会正常返回。
并发连接与并发查询不一样，并发连接可以很大，如上千个查询同时进入数据库。但是并发查询不同，并发查询是数据库真正在执行查询的请求，其它未执行的会等待。比如线程锁等待后，并发查询数减一，但并发连接不变。

#### 7.7.1.2. 查表判断

可以建立一个系统表，然后查询该系统表数据，看是否能正常返回。使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。但是无法检查空间占用达到 100%而无法写入的场景。

#### 7.7.1.3. 更新判断

通过更新系统表，来判断更新请求能否正常执行。对于一主一丛或一主多从，可以直接更新系统表就行了。但是如果是一主多从的话，需要注意主与主之间 binlog 会互传，所以会出现更新失败的情况。因此两主之间的数据 id 需要做到差异，如主键 ID 设置为 `@@server_id`。

### 7.7.2. 内部监控

MySQL 5.6 版本以后提供的 `performance_schema` 库，就在 `file_summary_by_event_name` 表里统计了每次 IO 请求的时间。开启这个功能数据库行能会下降 10%左右。`update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';`，可以通过这个命令开启监控功能。

## 7.8. 内存管理策略

Mysql 使用 LRU 算法进行内存缓冲区的管理，淘汰最近最少使用的数据。传统的 LRU 算法是当要添加一个不在缓冲区的数据时，就清除缓冲区的一个数据。当要往缓冲区写的数据都是新数据时，这时缓冲区的数据势必会被全部置换。

这是非常危险的，试想一下如果时一个冷 SQL 执行，导致将缓存中的数据全部清空，那么接下来的查询全部都会走到磁盘上去。这是非常危险的！

因此 Mysql 针对 LRU 算法做了一些特殊的处理：

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220515160901.png)

在 InnoDB 实现上，按照 5: 3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。

- 图中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。
- 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 px，是放在 lru\_old 处。
	- 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部。
	- 如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。
	- 1 秒这个时间，是由参数 `innodb_old_blocks_time` 控制的。其默认值是 1000，单位毫秒。

采用缓存区间拆分的策略，可以避免偶然读请求覆盖调所有的缓存数据。

# 8. 数据备份与恢复

## 8.1. 误删数据恢复

- 误删行数据，可以利用 binlog 反向操作还原数据。对于此类情况，考虑使用稳定的工具进行日志回放，回放过程优先找个临时库测试与验证。
- 误删库/表
	- 取出数据库的备份记录，然后取出日志备份，将备份记录之后的日志进行回放操作。
	- 取出备份记录，将其恢复出一个临时实例。然后将这个实例作为从库去同步数据。
- 预防措施
	- 延迟复制从库，可以保留一个从库采取延迟复制策略，通过 `CHANGE MASTER TO MASTER_DELAY = N` 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。
	- 完善的权限管理机制，SQL 执行规范，Review 流程等。

## 8.2. 数据导出

- 逻辑导出
```sql

# 使用 mysqldump 命令导出一组 insert 语句
mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql

# 执行导出的sql
mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"

# 导出CSV文件
select * from db1.t where a>900 into outfile '/server_tmp/t.csv';

# 加载导出的文件
load data infile '/server_tmp/t.csv' into table db2.t;

```
- 物理拷贝

# 9. 性能优化

## 9.1. 一条 SQL 执行慢的原因

### 9.1.1. 偶尔慢

- 数据库在刷新脏页
	- redo 日志满了
	- 内存满了
	- MySql 正常刷新脏页
	- 正在关机
	- 脏页刷新的快慢和 Myql 的 iops 变量设置与当前脏页比例有关。
- 获取不到锁
	- 可以通过 `show processlist` 来查看是否有阻塞表锁的线程。
	- 可以通过`select * from t sys. Innodb_lock_waits where locked_table=\`'test'.'t\'\`\G\`来查看锁阻塞情况。
- 查询是快照读，有事务进行了大量更新操作没提交，产生大量 undo 日志。快照读需要解析这些 undo 日志因此耗时长。
- 机器性能消耗
	比如突然 QPS 暴涨，导致 Mysql 压力过大

### 9.1.2. 一直慢

- 没正确使用索引
	- 联合索引使用了范围语句导致没用上
	- 使用了函数计算导致没用上。如 month () 这类。当两个表连接时，字段类型不同。如 `t1.a = t2.b`，, t1. A 的编码是 utf-8，, t2. B 的编码是 utf8mb4，此时 t1. A 会发生隐式函数计算 `CONVERT(t1.a USING utf8mb4) = t2.b;` 而导致无法使用索引。
	- 隐式类型转换导致没用上，比如 `.. where c = 1`，若 c 是字符串类型，相当于隐式执行了 `CAST(c AS signed int)` 这个转换。而如果索引是数值类型条件是字符串则不会有这个情况。
- 索引没建
- 由于数据库原因导致索引失效。如是否使用临时表，是否排序，估算的索引扫描行数等。

## 9.2. SQL 优化的途径

- 不要使用 select *
- 减少子查询，用关联查询代替。子查询会生成临时表，关联查询不会。
- 部分场景使用 exists 替换 in 查询。当子查询表大时，用 exists。子查询表小时，用 in。另无论哪个表大，not in 会扫全表，not exists 可以使用到索引。
- or 的查询看情况是否可以使用 union 或 union all 代替。
- 减少 != 条件的使用，否则会全表扫描。
- 避免在 where 条件中进行 null 值判断，否则可能会全表扫描。
- 避免在 where 条件中对字段进行函数计算。
- 如果 binlog 是 row 格式，可以将 `innodb_autoinc_lock_mode` 设置为 2，使主键分配结束就释放自增锁。
- 增大 `net_buffer` 的值，避免数据发送给客户端时阻塞。

## 9.3. 大表优化的思路

- 限定查询范围
- 读写分离
- 垂直分区，拆列
- 水平分区，拆行
- 分库分表

## 9.4. 数据库性能瓶颈优化

- 设置 `binlog_group_commit_sync_delay` 和 `binlog_group_commit_sync_no_delay_count` 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
- 将 `sync_binlog` 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
- 将 `innodb_flush_log_at_trx_commit` 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

# 10. 分布式数据库

## 10.1. 数据库分片两种常见方案

- 客户端代理，如 Sharding-Jdbc。封装在 jar 包中，通过修改或封装 jdbc 实现。
- Mycat，中间件代理。处于应用和数据层之间。

## 10.2. 分库分表后 id 解决方案

- UUID
- 数据库自增 ID。设置不同步长与 ID 生成策略。
- 利用 Redis 中间件生成。
- SnowFlake 算法。
- 其他分布式 ID 生成系统，如美团的 Leaf。