
# 1. 系统设计原则

## 1.1. 系统通用设计方法

在应对高并发大流量时会采用类似水库抵御洪水的方案，归纳起来共有三种方法：
- Scale-up（纵向扩展）与 Scale-out（横向扩展）
    纵向扩展旨在增加机器配置达到应对请求流量的目的，然而随着硬件发展，摩尔定律已经失效，所以纵向扩展前期能收获一定成果，但有一定上限。

    横向扩展，分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。
    
    Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？其中每一个问题都涉及很多方面，因此需要仔细考虑。
- 缓存
    使用缓存来提高系统的性能，就好比用“蓄水池”的方式抵抗高并发大流量的冲击。
- 异步
    在某些场景下，未处理完成之前我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。

这些技术不一定要全部用上，系统的演进过程应当遵循以下思路：
- 最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。
- 随着流量的增加和业务的变化，修正架构中存在的问题
    如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。
- 对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。

## 1.2. 系统的分层架构

分层的好处：
- 分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。
- 分层之后可以做到很高的复用。
- 分层架构可以让我们更容易做横向扩展。

任何的方案架构都是有优势有缺陷的，它最主要的一个缺陷就是增加了代码的复杂度，也可能会有性能的损耗，但是相比于它能带给我们的好处来说，这些都是可以接受的，或者可以通过其它的方案解决的。我们在做决策的时候切不可以偏概全，因噎废食。

## 1.3. 高并发系统设计思路

1. 高性能
    - 性能的度量指标：平均值、最大值、最小值、分位值等。
    - 性能的优化方式
        - 提升处理核心数
            例如提升进程数量，但需要注意测试进程数量与性能的关系，找到拐点。
        - 提升单次任务响应时间
2. 高可用
    高可用要求提升系统的可用性，也就是我们常说的几个 9。
    系统设计方面：可以从故障恢复、超时控制、降级、限流几方面进行。
    系统运维方面：可以从灰度发布，故障演练两方面进行。
3. 高扩展
    - 存储层的扩展：数据库拆分。
    - 业务层的扩展：按业务维度、重要维度、请求来源等进行拆分。

# 2. 系统设计方法

## 2.1. 数据库篇

### 2.1.1. 池化技术

我们所管理的某些对象，无论是连接还是线程，它们的创建过程都比较耗时，也比较消耗系统资源。所以，我们把它们放在一个池子里统一管理起来，以达到提升性能和资源复用的目的。

这是一种常见的软件设计思想，叫做**池化技术，它的核心思想是空间换时间，期望使用预先创建好的对象来减少频繁创建对象的性能开销**，同时还可以对对象进行统一的管理，降低了对象的使用的成本，总之是好处多多。

不过，池化技术也存在一些缺陷，比方说存储池子中的对象肯定需要消耗多余的内存，如果对象没有被频繁使用，就会造成内存上的浪费。再比方说，池子中的对象需要在系统启动的时候就预先创建完成，这在一定程度上增加了系统启动时间。可这些缺陷相比池化技术的优势来说就比较微不足道了，只要我们确认要使用的对象在创建时确实比较耗时或者消耗资源，并且这些对象也确实会被频繁地创建和销毁，我们就可以使用池化技术来优化。

使用池化技术时，需要注意以下几点：
- 池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。
- 池子中的对象需要在使用之前预先初始化完成，这叫做池子的预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。
- 池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。

### 2.1.2. 数据复制与分区

对数据进行[[数据密集型系统设计2：复制与分区|复制与分区]]，保证数据的可用性及性能，对于数据库可以采用主从部署来实现数据复制，使用分库分表来实现分区的效果。

#### 2.1.2.1. 复制之主从分离

对于大部分系统的访问模型其实都是读多写少，所以一种自然的处理就是将读请求与写请求分发到不同的服务上，即主从读写分离。

对于主从分离，主要有三个问题需要思考：
1. 主从间数据如何同步？
    这其实是一个[[数据密集型系统设计2：复制与分区#1. 数据复制|数据复制]]问题，常见的有同步复制，异步复制，链式复制。采取不同的复制方式会对主服务器的性能以及主从之间的延迟产生影响。从服务器越多，主服务器的压力自然越大，而异步复制的形式往往又带来延迟问题。因此需要根据实际情况来作出决定。
2. 主从间的延迟如何解决？
    如果采取的不是同步复制的形式，那么主从之间会存在延迟问题，这也就意味着从服务器读到的并不一定是最新的数据。如果对于数据一致性非常敏感的系统，那么同步复制的方式是应该优先考虑的。
    
    对于异步复制的系统，虽然无法完全避免延迟问题，但是仍然有一些方式来减少这种影响：
    - 数据冗余
        对于使用从服务器的系统，如果有其它信息渠道可以得到完整的数据，那么就可以避免这种影响。例如消息队列发送消息时带上完整的数据内容，而不仅仅只是数据 ID。
    - 缓存
        与数据冗余类似，如果可以从缓存中获取到数据的话，那么也可以避免从从库查询。但是缓存的数据如果也有延迟的话，这就避免不了了。
    - 主库查询
        无奈之举就只能从主服务器查询。
3. 客户端如何处理主从服务？
    当进行主从分离以后，客户端如何处理主从服务器呢？常见的有两种方式：
    1. 客户端代理
        客户端基于一些组件，实现主服务器与从服务器的请求转发。
    2. 代理层中转
        基于专门的主从代理服务器来实现请求转发，例如 Mycat 服务。

#### 2.1.2.2. 分区之分库分表

随着应用的数据量越来越大，应用的性能开始受到影响：数据量太多磁盘空间不足；索引深度变深查询变慢；所有数据在同一个库上，牵一发而动全身。这些问题可以归纳为数据库的写入请求量大造成的性能和可用性方面的问题，而常见的一种处理方式就是分库分表。

分库分表有两种方式：
1. 垂直拆分
    垂直拆分即将将数据库的表拆分到多个不同的数据库中，拆分的原则一般是按照业务类型来拆分。
2. 水平拆分
    垂直拆分可以在一定程度上减少数据量，但是无法避免单表数据量过大的问题，因此最后需要对数据进行水平拆分，即将将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点。
    
    拆分可以按关键字分区或者按关键字的哈希值分区。

数据库在分库分表之后，数据的访问方式也有了极大的改变，原先只需要根据查询条件到从库中查询数据即可，现在则需要先确认数据在哪一个库表中，再到那个库表中查询数据。

分库分表带来的另一个问题就是原本的一次数据查询可能需要改造，比如多表的 join 在单库时是可以通过一个 SQL 语句完成的，但是拆分到多个数据库之后就无法跨库执行 SQL 了。

### 2.1.3. Nosql 与关系型数据库的互补

Nosql 在一些方面可与关系型数据库形成互补：
1. 在性能方面，NoSQL 数据库使用一些算法（例如 LSM 结构）将对磁盘的随机写转换成顺序写，提升了写的性能；
2. 在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持；
3. 在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。

## 2.2. 缓存

### 2.2.1. 动态数据缓存

缓存是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构。许多地方会用到缓存机制，用于提升数据的访问速度。在我们日常开发中，常见的缓存主要就是静态缓存、分布式缓存和热点本地缓存这三种。

然而缓存也并非是一颗银弹，它同样[[Redis大纲#2.8. 缓存问题|有一些局限性]]：
1. 缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。
2. 缓存会给整体系统带来复杂度，并且会有数据不一致的风险，因此需要选择合适的[[Redis大纲#2.8.4. 缓存更新|缓存更新策略]]。
3. 缓存通常使用内存作为存储介质，但是内存并不是无限的。因此，我们在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案。同时，缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。

在分布式缓存中，缓存节点有多个，那么如何决定将数据存储到哪一个节点呢？通常有两种方式：
1. Hash 分片算法
    Hash 分片的算法就是对缓存的 Key 做哈希计算，然后对总的缓存节点个数取余。
    
    这个算法最大的优点就是简单易理解，缺点是当增加或者减少缓存节点时，缓存总的节点个数变化造成计算出来的节点发生变化，从而造成缓存失效不可用。
2. 一致性 Hash 分片算法
    一致性 Hash 分片算法中，我们将整个 Hash 值空间组织成一个虚拟的圆环，然后将缓存节点的 IP 地址或者主机名做 Hash 取值后，放置在这个圆环上。当我们需要确定某一个 Key 需要存取到哪个节点上的时候，先对这个 Key 做同样的 Hash 取值，确定在环上的位置，然后按照顺时针方向在环上“行走”，遇到的第一个缓存节点就是要访问的节点。
    
    ![image.png](https://r2.129870.xyz/img/202310102219052.png)
    
    在增加和删除节点时，只有少量的 Key 会“漂移”到其它节点上，而大部分的 Key 命中的节点还是会保持不变，从而可以保证命中率不会大幅下降。
    
    不过，事物总有两面性。虽然这个算法对命中率的影响比较小，但它还是存在问题：
    1. 节点崩溃问题
        缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大；当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成压力。
        
        可以在一致性 Hash 算法中引入**虚拟节点：将一个缓存节点计算多个 Hash 值分散到圆环的不同位置**，这样既实现了数据的平均，而且当某一个节点故障或者退出的时候，它原先承担的 Key 将以更加平均的方式分配到其他节点上，从而避免雪崩的发生。
    2. 脏数据问题
        比方说，在集群中有两个节点 A 和 B，客户端初始写入一个 Key 为 k，值为 3 的缓存数据到 Cache A 中。这时如果要更新 k 的值为 4，但是缓存 A 恰好和客户端连接出现了问题，那这次写入请求会写入到 Cache B 中。接下来缓存 A 和客户端的连接恢复，当客户端要获取 k 的值时，就会获取到存在 Cache A 中的脏数据 3，而不是 Cache B 中的 4。
        
        所以，在使用一致性 Hash 算法时一定要设置缓存的过期时间，这样当发生漂移时，之前存储的脏数据可能已经过期，就可以减少存在脏数据的几率。

### 2.2.2. 静态数据缓存

CDN (Content Delivery Network/Content Distribution Network，内容分发网络) 是用于对静态资源进行加速的原理和使用的核心技术:
1. DNS 技术是 CDN 实现中使用的核心技术，可以将用户的请求映射到 CDN 节点上；
2. DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间；
3. GSLB (Global Server Load Balance，全局负载均衡) 可以给用户返回一个离着他更近的节点，加快静态资源的访问速度。

## 2.3. 消息队列

消息队列在高并发系统设计中起到一定的作用:
1. 削峰填谷是消息队列最主要的作用，但是会造成请求处理的延迟。
2. 异步处理是提升系统性能的神器，但是你需要分清同步流程和异步流程的边界，同时消息存在着丢失的风险，我们需要考虑如何确保消息一定到达。
3. 解耦合可以提升你的整体系统的鲁棒性。

当然，在使用消息队列之后虽然可以解决现有的问题，但是系统的复杂度也会上升。比如上面提到的业务流程中，同步流程和异步流程的边界在哪里？消息是否会丢失，是否会重复？请求的延迟如何能够减少？ 消息接收的顺序是否会影响到业务流程的正常执行？如果消息处理流程失败了之后是否需要补发？ 这些问题都是我们需要考虑的。

## 2.4. 系统架构

### 2.4.1. RPC 性能考量

为了优化 RPC 框架的性能，可以从网络 I/O 模型和序列化方式入手:
1. 选择高性能的 I/O 模型，如同步多路 I/O 复用模型；
2. 调试网络参数，这里面有一些经验值的推荐；
    比如将 tcp_nodelay 设置为 true，也有一些参数需要在运行中来调试，比如接受缓冲区和发送缓冲区的大小，客户端连接请求缓冲队列的大小 (back log)等等。
3. 序列化协议依据具体业务来选择。如果对性能要求不高，可以选择 JSON，否则可以从 Thrift 和 Protobuf 中选择其一。

### 2.4.2. 注册中心

在服务拆分之后，便需要维护更多的细粒度的服务，而需要面对的第一个问题就是，如何让 RPC 客户端知道服务端部署的地址？使用类似于 Nginx 的反向代理软件可以进行流量透传，但是它的配置又不方便维护。注册中心是一个刚好的选择。

注册中心的基本功能有两点:
1. 其一是提供了服务地址的存储；
2.  其二是当存储内容发生变化时，可以将变更的内容推送给客户端。

使用注册中心需要注意以下几点：
1. 注册中心可以让我们动态地变更 RPC 服务的节点信息，对于动态扩缩容，故障快速恢复以及服务的优雅关闭都有重要的意义；
    优雅关闭是在系统研发过程中必须要考虑的问题。因为如果暴力地停止服务，那么已经发送给服务端的请求来不及处理服务就被杀掉了，就会造成这部分请求失败，服务就会有波动。所以，服务在退出的时候都需要先停掉流量，再停止服务，这样服务的关闭才会更平滑。
2. 心跳机制是一种常见的探测服务状态的方式，在实际的项目中可以考虑使用；
3. 我们需要对注册中心中管理的节点提供一些保护策略，避免注册中心节点或者服务过多导致通知风暴，同时也应避免节点被过度摘除导致的服务不可用。

### 2.4.3. 分布式 Trace

在一体化架构和服务化架构中，要如何排查单次慢请求中，究竟哪一个步骤是瓶颈，这需要用到分布式链路追踪技术。

服务的追踪的需求主要有两点：
1. 对代码要无侵入，可以使用切面编程的方式来解决；
2. 性能上要低损耗，所以建议采用静态代理和日志采样的方式，来尽量减少追踪日志对于系统性能的影响。

无论是单体系统还是服务化架构，无论是服务追踪还是业务问题排查，都需要在日志中增加 requestId，这样可以将日志串起来，呈现一个完整的问题场景。如果 requestId 可以在客户端上生成，在请求业务接口的时候传递给服务端，那么就可以把客户端的日志体系也整合进来，对于问题的排查帮助更大。

### 2.4.4. 负载均衡

负载均衡的作用是采取一些[[分布式大纲#1.3. 负载均衡算法|均衡算法]]将负载 (访问的请求)“均衡”地分配到多个处理节点上。这样可以减少单个处理节点的请求量，提升整体系统的性能。同时，负载均衡服务器作为流量入口，可以对请求方屏蔽服务节点的部署细节，实现对于业务方无感知的扩容。

负载均衡服务大体上可以分为两大类: 一类是代理类的负载均衡服务；另一类是客户端负载均衡服务。
1. 代理类负载均衡
    代理类服务需要承担全量的请求，所以对于性能的要求极高。代理类的负载均衡服务有很多开源实现，比较著名的有 LVS，Nginx 等等。LVS 在 OSI 网络模型中的第四层，传输层工作，所以 LVS 又可以称为四层负载；而 Nginx 运行在 OSI 网络模型中的第七层，应用层，所以又可以称它为七层负载。
    
    这种区别主要和 LVS 和 Nginx 的特点有关，LVS 是在网络栈的四层做请求包的转发，请求包转发之后，由客户端和后端服务直接建立连接，后续的响应包不会再经过 LVS 服务器，所以相比 Nginx，性能会更高，也能够承担更高的并发。
    
    LVS 缺陷是工作在四层，而请求的 URL 是七层的概念，不能针对 URL 做更细致地请求分发，而且 LVS 也没有提供探测后端服务是否存活的机制；而 Nginx 虽然比 LVS 的性能差很多，但也可以承担每秒几万次的请求，并且它在配置上更加灵活，还可以感知后端服务是否出现问题。因此，LVS 适合在入口处，承担大流量的请求分发，而 Nginx 要部署在业务服务器之前做更细维度的请求分发。
    
    ![image.png](https://r2.129870.xyz/img/202310112313967.png)
2. 客户端负载均衡
    在微服务架构中，服务节点存储在注册中心里，使用 LVS 就很难和注册中心交互，获取全量的服务节点列表。另外，一般微服务架构中，使用的是 RPC 协议而不是 HTTP 协议，所以 Nginx 也不能满足要求。所以，我们会使用另一类的负载均衡服务，客户端负载均衡服务，也就是把负载均衡的服务内嵌在 RPC 客户端中。
    
    它一般和客户端应用部署在一个进程中，提供多种选择节点的策略，最终为客户端应用提供一个最佳的，可用的服务端节点。这类服务一般会结合注册中心来使用，注册中心提供服务节点的完整列表，客户端拿到列表之后使用负载均衡服务的策略选取一个合适的节点，然后将请求发到这个节点上。
    
    ![image.png](https://r2.129870.xyz/img/202310112313623.png)

负载均衡服务有以下几个要点：
1. 网站负载均衡服务的部署，是以 LVS 承接入口流量，在应用服务器之前，部署 Nginx 做细化的流量分发和故障节点检测。当然如果你的网站的并发不高，也可以考虑不引入 LVS。
2. 负载均衡的策略可以优先选择动态策略，保证请求发送到性能最优的节点上；如果没有合适的动态策略，那么可以选择轮询的策略，让请求平均分配到所有的服务节点上。
3. Nginx 可以引入 `nginx_upstream_check_module`，对后端服务做定期的存活检测，后端的服务节点在重启时，也要秉承着“先切流量后重启”的原则，尽量减少节点重启对于整体系统的影响。

### 2.4.5. API 网关

1. API 网关分为入口网关和出口网关两类，入口网关作用很多，可以隔离客户端和微服务，从中提供协议转换、安全策略、认证、限流、熔断等功能。出口网关主要是为调用第三方服务提供统一的出口，在其中可以对调用外部的 API 做统一的认证、授权，审计以及访问控制；
2. API 网关的实现重点在于性能和扩展性，可以使用多路 I/O 复用模型和线程池并发处理，来提升网关性能，使用责任链模式来提升网关的扩展性；
3. API 网关中的线程池，可以针对不同的接口或者服务做隔离和保护，这样可以提升网关的可用性；
4. API 网关可以替代原本系统中的 Web 层，将 Web 层中的协议转换、认证、限流等功能挪入到 API 网关中，将服务聚合的逻辑下沉到服务层。

### 2.4.6. 多机房部署

1. 同城双活
    同城双活的核心思想是尽量避免跨机房的调用。数据库的主库可以部署在一个机房中，然后在 A、B 两个机房中各部署一个从库，通过主从复制的方式，从主库中同步数据，这样双机房的查询请求可以查询本机房的从库。一旦 A 机房发生故障，可以通过主从切换的方式，将 B 机房的从库提升为主库，达到容灾的目的。
    
    ![image.png](https://r2.129870.xyz/img/202310112341897.png)
    
2. 异地多活
    在考虑异地多活方案时，你首先要考虑异地机房的部署位置。它部署的不能太近，否则发生自然灾害时，很可能会波及。
    
    在数据写入时，你要保证只写本机房的数据存储服务，再采取数据同步的方案，将数据同步到异地机房中。一般来说，数据同步的方案有两种：
    1. 基于存储系统的主从复制，比如 MySQL 和 Redis。即在一个机房部署主库，在异地机房部署从库，两者同步主从复制, 实现数据的同步。
    2. 基于消息队列的方式。一个机房产生写入请求后，写一条消息到消息队列，另一个机房的应用消费这条消息后，再执行业务处理逻辑，写入到存储服务中。
       
       ![image.png](https://r2.129870.xyz/img/202310112346748.png)

无论是采取哪种方案，数据从一个机房传输到另一个机房都会有延迟，所以需要尽量保证用户在读取自己的数据时，读取数据主库所在的机房。为了达到这一点，需要对用户做分片，让一个用户每次的读写都尽量在同一个机房中。同时在数据读取和服务调用时，也要尽量调用本机房的服务。

### 2.4.7. ServiceMesh

![image.png](https://r2.129870.xyz/img/202310112356440.png)

1. Service Mesh 分为数据平面和控制平面。数据平面主要负责数据的传输；控制平面用来控制服务治理策略的植入。出于性能的考虑，一般会把服务治理策略植入到数据平面中，控制平面负责服务治理策略数据的下发。
2. Sidecar 的植入方式目前主要有两种实现方式，一种是使用 iptables 实现流量的劫持；另一种是通过轻量级客户端来实现流量转发。

### 2.4.8. 服务监控

1. 耗时、请求量和错误数是三种最通用的监控指标，不同的组件还有一些特殊的监控指标，你在搭建自己的监控系统的时候可以直接使用；
2. Agent、埋点和日志是三种最常见的数据采集方式；
3. 访问趋势报表用来展示服务的整体运行情况，性能报表用来分析资源或者依赖的服务是否出现问题，资源报表用来追查资源问题的根本原因。这三个报表共同构成了你的服务端监控体系。

### 2.4.9. 压力测试

![image.png](https://r2.129870.xyz/img/202310120057030.png)

1. 压力测试是一种发现系统性能隐患的重要手段，所以应该尽量使用正式的环境和数据；对于压测流量最好可以使用线上拷贝的流量。
2. 对压测的流量需要增加标记，这样就可以通过 Mock 第三方依赖服务和影子库的方式来实现压测数据和正式数据的隔离；
3. 压测时，应该实时地对系统性能指标做监控和告警，及时地对出现瓶颈的资源或者服务扩容，避免对正式环境产生影响。

### 2.4.10. 配置中心

配置中心有多种存储方式，比如 Mysql，Redis，ZooKeeper 等，无论使用哪一种存储组件，所要做的就是规范配置项在其中的存储结构。比如一种示例存储结构如下：支持存储全局配置、机房配置和节点配置，其中，节点配置优先级高于机房配置，机房配置优先级高于全局配置。也就是说，我们会优先读取节点的配置，如果节点配置不存在，再读取机房配置，最后读取全局配置。

配置变更有两种方式：
1. 轮询
    配置中心的客户端，定期地 (比如 1 分钟)查询所需要的配置是否有变化，如果有变化则通知触发监听器，让应用程序得到变更通知。
    
    这里有一个需要注意的点，如果有很多应用服务器都去轮询拉取配置，由于返回的配置项可能会很大，那么配置中心服务的带宽就会成为瓶颈。为了解决这个问题，我们会给配置中心的每一个配置项，多存储一个根据配置项计算出来的 MD5 值。
    
    配置项一旦变化，这个 MD5 值也会随之改变。配置中心客户端在获取到配置的同时，也会获取到配置的 MD5 值，并且存储起来。那么在轮询查询的时候，需要先确认存储的 MD5 值，和配置中心的 MD5 是不是一致的。如果不一致，这就说明配置中心中，存储的配置项有变化，然后才会从配置中心拉取最新的配置。
    
    ![image.png](https://r2.129870.xyz/img/202310130125151.png)
    
2. 长连接
    配置中心服务端保存每个连接关注的配置项列表。这样，当配置中心感知到配置变化后，就可以通过这个连接，把变更的配置推送给客户端。

**对于配置中心来说，它的可用性的重要程度要远远大于性能**。这是因为我们一般会在服务器启动时，从配置中心中获取配置，如果配置获取的性能不高，那么外在的表现也只是应用启动时间慢了，对于业务的影响不大；但是，如果获取不到配置，很可能会导致启动失败。

因此，我们的诉求是让配置中心“旁路化”。也就是说，即使配置中心宕机，或者配置中心依赖的存储宕机，我们仍然能够保证应用程序是可以启动的。那么这是如何实现的呢?

我们一般会在配置中心的客户端上，增加两级缓存: 第一级缓存是内存的缓存；另外一级缓存是文件的缓存。因此，我们的诉求是让配置中心“旁路化”。也就是说，即使配置中心宕机，或者配置中心依赖的存储宕机，我们仍然能够保证应用程序是可以启动的。那么这是如何实现的呢?

我们一般会在配置中心的客户端上，增加两级缓存：
1. 第一级缓存是内存的缓存；
2. 第二级缓存是文件的缓存。

配置中心客户端在获取到配置信息后，会同时把配置信息同步地写入到内存缓存，并且异步地写入到文件缓存中。内存缓存的作用是降低客户端和配置中心的交互频率，提升配置获取的性能；而文件的缓存的作用就是灾备，当应用程序重启时，一旦配置中心发生故障，那么应用程序就会优先使用文件中的配置，这样虽然无法得到配置的变更消息 (因为配置中心已经宕机了)，但是应用程序还是可以启动起来的，算是一种降级的方案。

### 2.4.11. 降级熔断与限流

当系统一些关联资源不可用时，可能会出现雪崩效应：
1. 依赖的资源或者服务不可用，最终导致整体服务宕机。
2. 超过系统承载能力的流量。

系统雪崩是如何发生的呢？系统在运行的时候是需要消耗一些资源的，包括 CPU、内存等系统资源，也包括执行业务逻辑的时候，需要的线程资源。当下游系统出现无法承担大流量而导致请求处理缓慢，会让上游调用的系统的请求被阻塞，从而导致上游系统被占用的线程资源就不能释放，最终更进一步导致系统雪崩的发生。

![image.png](https://r2.129870.xyz/img/202310132353379.png)

一种熔断机制的实现方式如下：
1. 当调用失败的次数累积到一定的阈值时，熔断状态从关闭态切换到打开态。一般在实现时，如果调用成功一次，就会重置调用失败次数。
2. 当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时后，状态切换到半打开态。你也可以通过设置一个定时器，定期地探测服务是否恢复。
3. 在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定的成功次数后，状态切换到关闭态； 如果出现调用失败的情况，则切换到打开态。

![image.png](https://r2.129870.xyz/img/202310132355230.png)

**降级机制**：相比熔断来说，降级是一个更大的概念。因为它是站在整体系统负载的角度上，放弃部分非核心功能或者服务，保证整体的可用性的方法，是一种有损的系统容错方式。这样看来，熔断也是降级的一种，除此之外还有限流降级、开关降级等等。

例如开关降级指的是在代码中预先埋设一些“开关”，用来控制服务调用的返回值。比方说，开关关闭的时候正常调用远程服务，开关打开时则执行降级的策略。这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要通过配置中心动态更改开关的值，就可以实现不重启服务快速地降级远程服务了。

一些降级策略如下：
1. 针对读取数据的场景，我们一般采用的策略是直接返回降级数据。
    比如，如果数据库的压力比较大，我们在降级的时候，可以考虑只读取缓存的数据，而不再读取数据库中的数据； 如果非核心接口出现问题，可以直接返回服务繁忙或者返回固定的降级数据。
2. 对于一些轮询查询数据的场景，比如每隔 30 秒轮询获取未读数，可以降低获取数据的频率 (将获取频率下降到 10 分钟一次)。
3. 对于写数据的场景，一般会考虑把同步写转换成异步写，这样可以牺牲一些数据一致性和实效性来保证系统的可用性。

只有经过演练的开关才是有用的开关，有些同学在给系统加了开关之后并不测试，结果出了问题真要使用的时候，却发现开关并不生效。因此，你在为系统增加降级开关时，一定要在流量低峰期的时候做验证演练，也可以在不定期的压力测试过程中演练，保证开关的可用性。

限流策略是微服务治理中的标配策略，只是你很难在实际中确认限流的阈值是多少，设置的小了容易误伤正常的请求，设置的大了则达不到限流的目的。所以，一般在实际项目中，我们会把阈值放置在配置中心中方便动态调整； 同时，我们可以通过定期地压力测试得到整体系统以及每个微服务的实际承载能力，然后再依据这个压测出来的值设置合适的阈值。

1. 限流是一种常见的服务保护策略，你可以在整体服务、单个服务、单个接口、单个 IP 或者单个用户等多个维度进行流量的控制；
2. 基于时间窗口维度的算法有固定窗口算法和滑动窗口算法，两者虽然能一定程度上实现限流的目的，但是都无法让流量变得更平滑；
3. 令牌桶算法和漏桶算法则能够塑形流量，让流量更加平滑，但是令牌桶算法能够应对一定的突发流量，所以在实际项目中应用更多。


# 3. 高并发系统设计实战

1. 数据量小的时候可以用数据库存储；
2. 数据量超过一定程度增加缓存机制：例如 Redis；
3. 写入直接写入 Redis，使用缓存来抗并发；
4. 在缓存基础上增加异步机制：使用消息队列来异步更新数据；
5. 以上机制都不够的情况下，如果有能力可以尝试改造中间件，来提升性能。

## 3.1. 未读数系统设计
### 3.1.1. 系统通知未读数设计

系统通知实际上是存储在一个大的列表中的，这个列表对所有用户共享，也就是所有人看到的都是同一份系统通知的数据。不过不同的人最近看到的消息不同，所以每个人会有不同的未读数。因此，可以记录一下在这个列表中每个人看过最后一条消息的 ID，然后统计这个 ID 之后有多少条消息，这就是未读数了。

![image.png](https://r2.129870.xyz/img/202310140028755.png)

这个方案在实现时有这样几个关键点:  
1. 用户访问系统通知页面需要设置未读数为 0，我们需要将用户最近看过的通知 ID 设置为最新的一条系统通知 ID；  
2. 如果最近看过的通知 ID 为空，则认为是一个新的用户，返回未读数为 0；
3. 对于非活跃用户，比如最近一个月都没有登录和使用过系统的用户，可以把用户最近看过的通知 ID 清空，节省内存空间。

这是一种比较通用的方案，即节省内存，又能尽量减少获取未读数的延迟。这个方案适用的另一个业务场景是全量用户打点的场景，比如像微博截图中的红点，这个红点和系统通知类似，也是一种通知全量用户的手段，如果逐个通知用户，延迟也是无法接受的。因此你可以采用和系统通知类似的方案。

首先，我们为每一个用户存储一个时间戳，代表最近点过这个红点的时间，用户点了红点，就把这个时间戳设置为当前时间； 然后，我们也记录一个全局的时间戳，这个时间戳标识最新的一次打点时间，如果你在后台操作给全体用户打点，就更新这个时间戳为当前时间。而我们在判断是否需要展示红点时，只需要判断用户的时间戳和全局时间戳的大小，如果用户时间戳小于全局时间戳，代表在用户最后一次点击红点之后又有新的红点推送，那么就要展示红点，反之，就不展示红点了。

![image.png](https://r2.129870.xyz/img/202310140030690.png)

**这两个场景的共性是全部用户共享一份有限的存储数据，每个人只记录自己在这份存储中的偏移量，就可以得到未读数了**。

### 3.1.2. 信息流未读数设计

在现在的社交系统中，关注关系已经成为标配的功能，而基于关注关系的信息流也是一种非常重要的信息聚合方式，因此，如何设计信息流的未读数系统就成了你必须面对的一个问题。

信息流的未读数之所以复杂主要有这样几点原因：
1. 微博的信息流是基于关注关系的，未读数也是基于关注关系的；
    关注的人发布了新的微博，那么作为粉丝未读数就要增加 1。对于一些动辄几千万甚至上亿粉丝的微博大 V ，如果采取遍历所有粉丝然后增加未读数，增加未读数可能需要几个小时。
2. 信息流未读数请求量极大；
3. 信息流列表不同用户不同。
    因为每个人关注的人不同，信息流的列表也就不同，所以也就没办法采用系统通知未读数的方案。

一个信息流未读数的系统设计如下：
1. 在通用计数器中记录每一个用户发布的博文数；
2. 在 Redis 或者 Memcached 中记录一个人所有关注人的博文数快照，当用户点击未读消息重置未读数为 0 时，将他关注所有人的博文数刷新到快照中；
3. 关注所有人的博文总数减去快照中的博文总数就是信息流未读数。

![image.png](https://r2.129870.xyz/img/202310140042337.png)

这个方案也有一些缺陷：
1. 快照中需要存储关注关系，如果关注关系变更的时候更新不及时，那么就会造成未读数不准确； 
2. 快照采用的是全缓存存储，如果缓存满了就会剔除一些数据，那么被剔除用户的未读数就变为 0 了。

但是好在用户对于未读数的准确度要求不高 (未读 10 条还是 11 条，其实用户有时候看不出来)，因此，这些缺陷也是可以接受的。

通过分享未读数系统设计这个案例，我想给你一些建议:
1. 缓存是提升系统性能和抵抗大并发量的神器；
2. 要围绕系统设计的关键困难点想解决办法，就像我们解决系统通知未读数的延迟问题一样；
3. 合理分析业务场景，明确哪些是可以权衡的，哪些是不行的，会对你的系统设计增益良多，比如对于长久不登录用户，我们就会记录未读数为 0，通过这样的权衡，可以极大地减少内存的占用，减少成本。

## 3.2. 信息流系统设计

最早的信息流系统起源于微博，我们知道，微博是基于关注关系来实现内容分发的，也就是说，如果用户 A 关注了用户 B，那么用户 A 就需要在自己的信息流中，实时地看到用户 B 发布的最新内容，这是微博系统的基本逻辑，也是它能够让信息快速流通、快速传播的关键。由于微博的信息流一般是按照时间倒序排列的，所以我们通常把信息流系统称为 TimeLine (时间线)。

信息流系统的难点如下：
1. 关注的人发了信息之后，信息需要在短时间之内出现在信息流中。
2. 信息流拉取性能直接影响用户的使用体验。
    微博信息流系统中需要聚合的数据非常多，你打开客户端看一看，想一想其中需要聚合哪些数据? 主要是微博的数据，用户的数据，除此之外，还需要查询微博是否被赞、评论点赞转发的计数、是否被关注拉黑等等。聚合这么多的数据就需要查询多次缓存、数据库、计数器，而在每秒几十万次的请求下，如何保证在 100ms 之内完成这些查询操作，展示微博的信息流呢? 这是微博信息流系统最复杂之处，也是技术上最大的挑战。

### 3.2.1. 信息流系统的推模式

推模式是指用户发送一条微博后，主动将这条微博推送给他的粉丝，从而实现微博的分发，也能以此实现微博信息流的聚合。

假设微博系统是一个邮箱系统，那么用户发送的微博可以认为是进入到一个发件箱，用户的信息流可以认为是这个人的收件箱。推模式的做法是在用户发布一条微博时，除了往自己的发件箱里写入一条微博，同时也会给他的粉丝收件箱里写入一条微博。

如果想要提升读取信息流的性能，可以把收件箱的数据存储在缓存里面，每次获取信息流的时候直接从缓存中读取就好了。

推模式存在的问题如下：
1. 消息延迟
    对明星来说，他们的粉丝数庞大，如果在发微博的同时还要将微博写入到上千万人的收件箱中，那么发微博的响应时间会非常慢，用户根本没办法接受。因此，我们一般会使用消息队列来消除写入的峰值，但即使这样，由于写入收件箱的消息实在太多，你还是有可能在几个小时之后才能够看到明星发布的内容，这会非常影响用户的使用体验。
    
    在推模式下，你需要关注的是微博的写入性能，因为用户每发一条微博，都会产生多次的数据库写入。为了尽量减少微博写入的延迟，我们可以从两方面来保障。
    1. 在消息处理上，可以启动多个线程并行地处理微博写入的消息。
    2. 由于消息流在展示时可以使用缓存来提升读取性能，所以我们应该尽量保证数据写入数据库的性能，必要时可以采用写入性能更好的数据库存储引擎。
2. 存储成本
    由于推模式需要给每一个用户都维护一份收件箱的数据，所以数据的存储量极大。
3. 扩展性问题
    比如对关注功能增加分组功能后，会对推模式有什么样的影响呢? 首先是一个用户不止有一个收件箱，比如我有一个全局收件箱，还会针对每一个分组再分别创建一个收件箱，而一条微博在发布之后也需要被复制到更多的收件箱中了。因此这个推模式的扩展性就会很差。
4. 取消关注和删除微博的逻辑时会更加复杂
    删除信息或者取消关注后，未读消息也需要做相应处理，因此复杂度会提升。可以采用的策略是: 在读取自己信息流的时候，判断每一条微博是否被删除以及你是否还关注这条微博的作者，如果没有的话，就不展示这条微博的内容了。使用了这个策略之后，就可以尽量减少对于数据库多余的写操作了。

因此推模式适合粉丝数比较有限的场景，比如说微信朋友圈，你可以理解为我在微信中增加一个好友是关注了他也被他关注，所以好友的上限也就是粉丝的上限 (朋友圈应该是 5000)。有限的粉丝数可以保证消息能够尽量快地被推送给所有的粉丝，增加的存储成本也比较有限。如果你的业务中粉丝数是有限制的，那么在实现以关注关系为基础的信息流时，也可以采用推模式来实现。

### 3.2.2. 信息流系统的拉模式

拉模式，就是指用户主动拉取他关注的所有人的微博，将这些微博按照发布时间的倒序进行排序和聚合之后，生成信息流数据的方法。

拉模式的实现思想并不复杂，并且相比推模式来说，它有几点明显的优势：
1. 推送延迟的问题
    发微博的时候不再需要推送到粉丝的收件箱，延迟大大减少。
2. 存储成本大大降低
3. 功能扩展性更好

拉模式主要存在的问题是聚合成本可能会很高：在拉模式下，我们需要对多个发件箱的数据做聚合，这个查询和聚合的成本比较高。微博的关注上限是 2000，假如你关注了 2000 人，就要查询这 2000 人发布的微博信息，然后再对查询出来的信息做聚合。

那么，如何保证在毫秒级别完成这些信息的查询和聚合呢? 答案还是缓存。我们可以把用户发布的微博 ID 放在缓存中，不过如果把全部用户的所有微博都缓存起来，消耗的硬件成本也是很高的。所以我们需要关注用户浏览信息流的特点，看看是否可能对缓存的存储成本做一些优化，比如只缓存最近五天的微博之类的。

