
# 1. 系统设计原则

## 1.1. 系统通用设计方法

在应对高并发大流量时会采用类似水库抵御洪水的方案，归纳起来共有三种方法：
- Scale-up（纵向扩展）与 Scale-out（横向扩展）
    纵向扩展旨在增加机器配置达到应对请求流量的目的，然而随着硬件发展，摩尔定律已经失效，所以纵向扩展前期能收获一定成果，但有一定上限。

    横向扩展，分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。
    
    Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？其中每一个问题都涉及很多方面，因此需要仔细考虑。
- 缓存
    使用缓存来提高系统的性能，就好比用“蓄水池”的方式抵抗高并发大流量的冲击。
- 异步
    在某些场景下，未处理完成之前我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。

这些技术不一定要全部用上，系统的演进过程应当遵循以下思路：
- 最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。
- 随着流量的增加和业务的变化，修正架构中存在的问题
    如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。
- 对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。

## 1.2. 系统的分层架构

分层的好处：
- 分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。
- 分层之后可以做到很高的复用。
- 分层架构可以让我们更容易做横向扩展。

任何的方案架构都是有优势有缺陷的，它最主要的一个缺陷就是增加了代码的复杂度，也可能会有性能的损耗，但是相比于它能带给我们的好处来说，这些都是可以接受的，或者可以通过其它的方案解决的。我们在做决策的时候切不可以偏概全，因噎废食。

## 1.3. 高并发系统设计思路

1. 高性能
    - 性能的度量指标：平均值、最大值、最小值、分位值等。
    - 性能的优化方式
        - 提升处理核心数
            例如提升进程数量，但需要注意测试进程数量与性能的关系，找到拐点。
        - 提升单次任务响应时间
2. 高可用
    高可用要求提升系统的可用性，也就是我们常说的几个 9。
    系统设计方面：可以从故障恢复、超时控制、降级、限流几方面进行。
    系统运维方面：可以从灰度发布，故障演练两方面进行。
3. 高扩展
    - 存储层的扩展：数据库拆分。
    - 业务层的扩展：按业务维度、重要维度、请求来源等进行拆分。

# 2. 系统设计方法

## 2.1. 数据库篇

### 2.1.1. 池化技术

我们所管理的某些对象，无论是连接还是线程，它们的创建过程都比较耗时，也比较消耗系统资源。所以，我们把它们放在一个池子里统一管理起来，以达到提升性能和资源复用的目的。

这是一种常见的软件设计思想，叫做**池化技术，它的核心思想是空间换时间，期望使用预先创建好的对象来减少频繁创建对象的性能开销**，同时还可以对对象进行统一的管理，降低了对象的使用的成本，总之是好处多多。

不过，池化技术也存在一些缺陷，比方说存储池子中的对象肯定需要消耗多余的内存，如果对象没有被频繁使用，就会造成内存上的浪费。再比方说，池子中的对象需要在系统启动的时候就预先创建完成，这在一定程度上增加了系统启动时间。可这些缺陷相比池化技术的优势来说就比较微不足道了，只要我们确认要使用的对象在创建时确实比较耗时或者消耗资源，并且这些对象也确实会被频繁地创建和销毁，我们就可以使用池化技术来优化。

使用池化技术时，需要注意以下几点：
- 池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。
- 池子中的对象需要在使用之前预先初始化完成，这叫做池子的预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。
- 池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。

### 2.1.2. 数据复制与分区

对数据进行[[数据密集型系统设计2：复制与分区|复制与分区]]，保证数据的可用性及性能，对于数据库可以采用主从部署来实现数据复制，使用分库分表来实现分区的效果。

#### 2.1.2.1. 复制之主从分离

对于大部分系统的访问模型其实都是读多写少，所以一种自然的处理就是将读请求与写请求分发到不同的服务上，即主从读写分离。

对于主从分离，主要有三个问题需要思考：
1. 主从间数据如何同步？
    这其实是一个[[数据密集型系统设计2：复制与分区#1. 数据复制|数据复制]]问题，常见的有同步复制，异步复制，链式复制。采取不同的复制方式会对主服务器的性能以及主从之间的延迟产生影响。从服务器越多，主服务器的压力自然越大，而异步复制的形式往往又带来延迟问题。因此需要根据实际情况来作出决定。
2. 主从间的延迟如何解决？
    如果采取的不是同步复制的形式，那么主从之间会存在延迟问题，这也就意味着从服务器读到的并不一定是最新的数据。如果对于数据一致性非常敏感的系统，那么同步复制的方式是应该优先考虑的。
    
    对于异步复制的系统，虽然无法完全避免延迟问题，但是仍然有一些方式来减少这种影响：
    - 数据冗余
        对于使用从服务器的系统，如果有其它信息渠道可以得到完整的数据，那么就可以避免这种影响。例如消息队列发送消息时带上完整的数据内容，而不仅仅只是数据 ID。
    - 缓存
        与数据冗余类似，如果可以从缓存中获取到数据的话，那么也可以避免从从库查询。但是缓存的数据如果也有延迟的话，这就避免不了了。
    - 主库查询
        无奈之举就只能从主服务器查询。
3. 客户端如何处理主从服务？
    当进行主从分离以后，客户端如何处理主从服务器呢？常见的有两种方式：
    1. 客户端代理
        客户端基于一些组件，实现主服务器与从服务器的请求转发。
    2. 代理层中转
        基于专门的主从代理服务器来实现请求转发，例如 Mycat 服务。

#### 2.1.2.2. 分区之分库分表

随着应用的数据量越来越大，应用的性能开始受到影响：数据量太多磁盘空间不足；索引深度变深查询变慢；所有数据在同一个库上，牵一发而动全身。这些问题可以归纳为数据库的写入请求量大造成的性能和可用性方面的问题，而常见的一种处理方式就是分库分表。

分库分表有两种方式：
1. 垂直拆分
    垂直拆分即将将数据库的表拆分到多个不同的数据库中，拆分的原则一般是按照业务类型来拆分。
2. 水平拆分
    垂直拆分可以在一定程度上减少数据量，但是无法避免单表数据量过大的问题，因此最后需要对数据进行水平拆分，即将将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点。
    
    拆分可以按关键字分区或者按关键字的哈希值分区。

数据库在分库分表之后，数据的访问方式也有了极大的改变，原先只需要根据查询条件到从库中查询数据即可，现在则需要先确认数据在哪一个库表中，再到那个库表中查询数据。

分库分表带来的另一个问题就是原本的一次数据查询可能需要改造，比如多表的 join 在单库时是可以通过一个 SQL 语句完成的，但是拆分到多个数据库之后就无法跨库执行 SQL 了。

### 2.1.3. Nosql 与关系型数据库的互补

Nosql 在一些方面可与关系型数据库形成互补：
1. 在性能方面，NoSQL 数据库使用一些算法（例如 LSM 结构）将对磁盘的随机写转换成顺序写，提升了写的性能；
2. 在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持；
3. 在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。在性能方面，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；

## 2.2. 缓存

### 2.2.1. 动态数据缓存

缓存是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构。许多地方会用到缓存机制，用于提升数据的访问速度。在我们日常开发中，常见的缓存主要就是静态缓存、分布式缓存和热点本地缓存这三种。

然而缓存也并非是一颗银弹，它同样[[Redis大纲#2.8. 缓存问题|有一些局限性]]：
1. 缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。
2. 缓存会给整体系统带来复杂度，并且会有数据不一致的风险，因此需要选择合适的[[Redis大纲#2.8.4. 缓存更新|缓存更新策略]]。
3. 缓存通常使用内存作为存储介质，但是内存并不是无限的。因此，我们在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案。同时，缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。

在分布式缓存中，缓存节点有多个，那么如何决定将数据存储到哪一个节点呢？通常有两种方式：
1. Hash 分片算法
    Hash 分片的算法就是对缓存的 Key 做哈希计算，然后对总的缓存节点个数取余。
    
    这个算法最大的优点就是简单易理解，缺点是当增加或者减少缓存节点时，缓存总的节点个数变化造成计算出来的节点发生变化，从而造成缓存失效不可用。
2. 一致性 Hash 分片算法
    一致性 Hash 分片算法中，我们将整个 Hash 值空间组织成一个虚拟的圆环，然后将缓存节点的 IP 地址或者主机名做 Hash 取值后，放置在这个圆环上。当我们需要确定某一个 Key 需要存取到哪个节点上的时候，先对这个 Key 做同样的 Hash 取值，确定在环上的位置，然后按照顺时针方向在环上“行走”，遇到的第一个缓存节点就是要访问的节点。
    
    ![image.png](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202310102219052.png)
    
    在增加和删除节点时，只有少量的 Key 会“漂移”到其它节点上，而大部分的 Key 命中的节点还是会保持不变，从而可以保证命中率不会大幅下降。
    
    不过，事物总有两面性。虽然这个算法对命中率的影响比较小，但它还是存在问题：
    1. 节点崩溃问题
        缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大; 当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成压力。
        
        可以在一致性 Hash 算法中引入虚拟节点的概念。它将一个缓存节点计算多个 Hash 值分散到圆环的不同位置，这样既实现了数据的平均，而且当某一个节点故障或者退出的时候，它原先承担的 Key 将以更加平均的方式分配到其他节点上，从而避免雪崩的发生。
    2. 脏数据问题
        比方说，在集群中有两个节点 A 和 B，客户端初始写入一个 Key 为 k，值为 3 的缓存数据到 Cache A 中。这时如果要更新 k 的值为 4，但是缓存 A 恰好和客户端连接出现了问题，那这次写入请求会写入到 Cache B 中。接下来缓存 A 和客户端的连接恢复，当客户端要获取 k 的值时，就会获取到存在 Cache A 中的脏数据 3，而不是 Cache B 中的 4。
        
        所以，在使用一致性 Hash 算法时一定要设置缓存的过期时间，这样当发生漂移时，之前存储的脏数据可能已经过期，就可以减少存在脏数据的几率。

### 2.2.2. 静态数据缓存

CDN (Content Delivery Network/Content Distribution Network，内容分发网络) 是用于对静态资源进行加速的原理和使用的核心技术:
1. DNS 技术是 CDN 实现中使用的核心技术，可以将用户的请求映射到 CDN 节点上；
2. DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间；
3. GSLB (Global Server Load Balance，全局负载均衡) 可以给用户返回一个离着他更近的节点，加快静态资源的访问速度。 CDN 对静态资源进行加速的原理和使用的核心技术，这里你需要了解的重点有以下几点。

## 2.3. 消息队列

消息队列在高并发系统设计中起到一定的作用:
1. 削峰填谷是消息队列最主要的作用，但是会造成请求处理的延迟。
2. 异步处理是提升系统性能的神器，但是你需要分清同步流程和异步流程的边界，同时消息存在着丢失的风险，我们需要考虑如何确保消息一定到达。
3. 解耦合可以提升你的整体系统的鲁棒性。

当然，在使用消息队列之后虽然可以解决现有的问题，但是系统的复杂度也会上升。比如上面提到的业务流程中，同步流程和异步流程的边界在哪里？消息是否会丢失，是否会重复？请求的延迟如何能够减少？ 消息接收的顺序是否会影响到业务流程的正常执行?？如果消息处理流程失败了之后是否需要补发？ 这些问题都是我们需要考虑的。

## 2.4. 系统架构

### 2.4.1. RPC 性能考量

为了优化 RPC 框架的性能，可以从网络 I/O 模型和序列化方式入手:
1. 选择高性能的 I/O 模型，如同步多路 I/O 复用模型；
2. 调试网络参数，这里面有一些经验值的推荐；
    比如将 tcp_nodelay 设置为 true，也有一些参数需要在运行中来调试，比如接受缓冲区和发送缓冲区的大小，客户端连接请求缓冲队列的大小 (back log)等等。
3. 序列化协议依据具体业务来选择。如果对性能要求不高，可以选择 JSON，否则可以从 Thrift 和 Protobuf 中选择其一。

### 2.4.2. 注册中心

在服务拆分之后，便需要维护更多的细粒度的服务，而需要面对的第一个问题就是，如何让 RPC 客户端知道服务端部署的地址？使用类似于 Nginx 的反向代理软件可以进行流量透传，但是它的配置又不方便维护。注册中心是一个刚好的选择。

注册中心的基本功能有两点:
1. 其一是提供了服务地址的存储；
2.  其二是当存储内容发生变化时，可以将变更的内容推送给客户端。

使用注册中心需要注意以下几点：
1. 注册中心可以让我们动态地，变更 RPC 服务的节点信息，对于动态扩缩容，故障快速恢复，以及服务的优雅关闭都有重要的意义；
    优雅关闭是在系统研发过程中，必须要考虑的问题。因为如果暴力地停止服务，那么已经发送给服务端的请求，来不及处理服务就被杀掉了，就会造成这部分请求失败，服务就会有波动。所以，服务在退出的时候，都需要先停掉流量，再停止服务，这样服务的关闭才会更平滑。
2. 心跳机制是一种常见的探测服务状态的方式，在实际的项目中可以考虑使用；
3. 我们需要对注册中心中管理的节点提供一些保护策略，避免注册中心节点或者服务过多导致通知风暴，同时也应避免节点被过度摘除导致的服务不可用。
