## 1. 系统架构演进史

架构并不是被发明出来的，而是持续演进的结果，本章我们暂且放下代码与技术，借讨论历史之名，来梳理软件架构发展历程中出现过的名词术语，以全局的视角，从这些概念的起源去分析它们是什么、它们取代了什么，以及它们为什么能够在竞争中取得成功，为什么变得不可或缺，又或者它们为什么会失败，在斗争中被淘汰，逐渐湮灭于历史的烟尘当中。

### 1.1. 原始分布式时代

> [!abstract] UNIX 的分布式设计哲学
> 
> Simplicity of both the interface and the implementation are more important than any other attributes of the system — including correctness, consistency, and completeness
> 
> 保持接口与实现的简单性，比系统的任何其他属性，包括准确性、一致性和完整性，都来得更加重要。

在 20 世纪 70 年代末期到 80 年代初，计算机科学刚经历了从以大型机为主向以微型机为主的蜕变，但当时计算机硬件局促的运算处理能力，已直接妨碍到了在单台计算机上信息系统软件能够达到的最大规模。为突破硬件算力的限制，各个高校、研究机构、软硬件厂商开始分头探索，寻找使用多台计算机共同协作来支撑同一套软件系统运行的可行方案。这一阶段是对分布式架构最原始的探索，从结果来看，历史局限决定了它不可能一蹴而就地解决分布式的难题，但仅从过程来看，这个阶段的探索称得上成绩斐然。研究过程的很多中间成果都对今天计算机科学的诸多领域产生了深远的影响，直接牵引了后续软件架构的演化进程。

为了避免[UNIX 系统的版本战争](https://en.wikipedia.org/wiki/Unix_wars)在分布式领域中重演，负责制定 UNIX 系统技术标准的“[开放软件基金会](https://zh.wikipedia.org/wiki/%E9%96%8B%E6%94%BE%E8%BB%9F%E9%AB%94%E5%9F%BA%E9%87%91%E6%9C%83)”（Open Software Foundation，OSF，也即后来的“国际开放标准组织”）邀请了当时业界主流的计算机厂商一起参与，共同制订了名为“[分布式运算环境](https://en.wikipedia.org/wiki/Distributed_Computing_Environment)”（Distributed Computing Environment，DCE）的分布式技术体系。DCE 包含一套相对完整的分布式服务组件规范与参考实现，譬如源自 NCA 的远程服务调用规范（Remote Procedure Call，RPC），当时被称为[DCE/RPC](https://zh.wikipedia.org/wiki/DCE/RPC)，它与后来 Sun 公司向互联网工程任务组（Internet Engineering Task Force，IETF）提交的基于通用 TCP/IP 协议的远程服务标准[ONC RPC](https://zh.wikipedia.org/wiki/%E9%96%8B%E6%94%BE%E7%B6%B2%E8%B7%AF%E9%81%8B%E7%AE%97%E9%81%A0%E7%AB%AF%E7%A8%8B%E5%BA%8F%E5%91%BC%E5%8F%AB)被认为是现代 RPC 的共同鼻祖；源自 AFS 的分布式文件系统（Distributed File System，DFS）规范，当时被称为[DCE/DFS](https://en.wikipedia.org/wiki/DCE_Distributed_File_System)；源自 Kerberos 的服务认证规范；还有时间服务、命名与目录服务，就连现在程序中很常用的通用唯一识别符 UUID 也是在 DCE 中发明出来的。

由于 OSF 本身的 UNIX 背景，当时研究这些技术都带着浓厚的 UNIX 设计风格，有一个预设的重要原则是**使分布式环境中的服务调用、资源访问、数据存储等操作尽可能透明化、简单化，使开发人员不必过于关注他们访问的方法或其他资源是位于本地还是远程**。这样的主旨非常符合一贯的[UNIX 设计哲学](https://en.wikipedia.org/wiki/Unix_philosophy#cite_note-0)，然而这个过于理想化的目标背后其实蕴含着彼时根本不可能完美解决的技术困难。

“调用远程方法”与“调用本地方法”尽管只是两字之差，但若要同时兼顾简单、透明、性能、正确、鲁棒、一致等特点的话，两者的复杂度就完全不可同日而语了。且不说远程方法不能再依靠本地方法那些以内联为代表的传统编译优化来提升速度，光是“远程”二字带来的网络环境下的新问题，譬如，远程的服务在哪里（服务发现），有多少个（负载均衡），网络出现分区、超时或者服务出错了怎么办（熔断、隔离、降级），方法的参数与返回结果如何表示（序列化协议），信息如何传输（传输协议），服务权限如何管理（认证、授权），如何保证通信安全（网络安全层），如何令调用不同机器的服务返回相同的结果（分布式数据一致性）等一系列问题，全部都需要设计者耗费大量心思。

面对重重困难与压力，DCE 不仅从零开始、从无到有地回答了其中大部分问题，构建出大量的分布式基础组件与协议，而且真的尽力做到了相对“透明”。但无论是 DCE 还是稍后出现的 COBRA，从结果来看，都不能称取得了成功，将一个系统拆分到不同的机器中运行，这样做带来的服务发现、跟踪、通信、容错、隔离、配置、传输、数据一致性和编码复杂度等方面的问题，所付出的代价远远超过了分布式所取得的收益。

### 1.2. 单体系统时代

> [!abstract] Monolithic Application
> 
> Monolith means composed all in one piece. The Monolithic application describes a single-tiered software application in which different components combined into a single program from a single platform.
> 
> 单体意味着自包含。单体应用描述了一种由同一技术平台的不同组件构成的单层软件。

剖析单体架构之前，我们有必要先厘清一个概念误区，许多微服务的资料里，单体系统往往是以“反派角色”的身份登场的，譬如著名的微服务入门书《[微服务架构设计模式](https://book.douban.com/subject/33425123/)》，第一章的名字就是“逃离单体的地狱”。这些材料所讲的单体系统，其实都是有一个没有明说的隐含定语：“**大型的单体系统**”。对于小型系统——即由单台机器就足以支撑其良好运行的系统，单体不仅易于开发、易于测试、易于部署，且由于系统中各个功能、模块、方法的调用过程都是进程内调用，不会发生[进程间通信](https://zh.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B%E9%96%93%E9%80%9A%E8%A8%8A)（Inter-Process Communication，IPC。），因此也是运行效率最高的一种架构风格，完全不应该被贴上“反派角色”的标签，反倒是那些爱赶技术潮流却不顾需求现状的微服务吹捧者更像是个反派。单体系统的不足，必须基于软件的性能需求超过了单机，软件的开发人员规模明显超过了“[2 Pizza Team](https://wiki.mbalib.com/wiki/%E4%B8%A4%E4%B8%AA%E6%8A%AB%E8%90%A8%E5%8E%9F%E5%88%99)”范畴的前提下才有讨论的价值。

#### 1.2.1. 单体架构是否难以拆分？

相信肯定有一部分人说起单体架构、巨石系统的缺点时，在脑海中闪过的第一个特点就是它的“不可拆分”，难以扩展，因此才不能支撑越来越大的软件规模。这种想法看似合理，其实是有失偏颇的，至少不完整。

**从纵向角度来看，分层架构（Layered Architecture）已是现在几乎所有信息系统建设中都普遍认可、采用的软件设计方法**，无论是单体还是微服务，抑或是其他架构风格，都会对代码进行纵向层次划分，收到的外部请求在各层之间以不同形式的数据结构进行流转传递，触及最末端的数据库后按相反的顺序回馈响应，如图所示。对于这个意义上的“可拆分”，单体架构完全不会展露出丝毫的弱势，反而可能会因更容易开发、部署、测试而获得一些便捷性上的好处。

![](https://r2.129870.xyz/img/202212152028428.png)

**从横向角度来看，单体架构也可以支持按照技术、功能、职责等维度，将软件拆分为各种模块，以便重用和管理代码**。单体系统并不意味着只能有一个整体的程序封装形式，如果需要，它完全可以由多个 JAR、WAR、DLL、Assembly 或者其他模块格式来构成。即使是以横向扩展（Scale Horizontally）的角度来衡量，在负载均衡器之后同时部署若干个相同的单体系统副本，以达到分摊流量压力的效果，也是非常常见的需求。

#### 1.2.2. 单体架构的困境：隔离与自治

在“拆分”这方面，**单体系统的真正缺陷不在如何拆分，而在拆分之后的隔离与自治能力上的欠缺**。由于所有代码都运行在同一个进程空间之内，所有模块、方法的调用都无须考虑网络分区、对象复制这些麻烦的事和性能损失。**获得了进程内调用的简单、高效等好处的同时，也意味着如果任何一部分代码出现了缺陷，过度消耗了进程空间内的资源，所造成的影响也是全局性的、难以隔离的**。譬如内存泄漏、线程爆炸、阻塞、死循环等问题，都将会影响整个程序，而不仅仅是影响某一个功能、模块本身的正常运作。如果消耗的是某些更高层次的公共资源，譬如端口号或者数据库连接池泄漏，影响还将会波及整台机器，甚至是集群中其他单体副本的正常工作。

同样，由于所有代码都共享着同一个进程空间，不能隔离，也就无法（其实还是有办法的，譬如使用 OSGi 这种运行时模块化框架，但是很别扭、很复杂）做到单独停止、更新、升级某一部分代码，因为不可能有“停掉半个进程，重启 1/4 个程序”这样不合逻辑的操作，所以从可维护性来说，单体系统也是不占优势的。程序升级、修改缺陷往往需要制定专门的停机更新计划，做灰度发布、A/B 测试也相对更复杂。

如果说共享同一进程获得简单、高效的代价是同时损失了各个功能模块的自治、隔离能力，那这两者孰轻孰重呢？这个问题的潜台词似乎是在比较微服务、单体架构哪种更好用、更优秀？当然，“好用和优秀”不会是放之四海皆准的。

由于隔离能力的缺失，单体除了难以阻断错误传播、不便于动态更新程序以外，还面临难以技术异构的困难，每个模块的代码都通常需要使用一样的程序语言，乃至一样的编程框架去开发。单体系统的技术栈异构并非一定做不到，譬如 JNI 就可以让 Java 混用 C 或 C++，但这通常是迫不得已的，并不是优雅的选择。

不过，以上列举的这些问题都还不是今天以微服务取代单体系统成为潮流趋势的根本原因，笔者认为最重要的理由是：单体系统很难兼容“[Phoenix](https://icyfenix.cn/introduction/about-the-fenix-project.html#%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B)”的特性。这种架构风格潜在的观念是**希望系统的每一个部件，每一处代码都尽量可靠，靠不出或少出缺陷来构建可靠系统**。然而战术层面再优秀，也很难弥补战略层面的不足，单体靠高质量来保证高可靠性的思路，在小规模软件上还能运作良好，但系统规模越大，交付一个可靠的单体系统就变得越来越具有挑战性。如本书的前言开篇《[什么是"凤凰架构"](https://icyfenix.cn/introduction/about-the-fenix-project.html)》所说，正是随着软件架构演进，构筑可靠系统从“追求尽量不出错”，到正视“出错是必然”的观念转变，才是微服务架构得以挑战并逐步开始取代运作了数十年的单体架构的底气所在。

为了允许程序出错，为了获得隔离、自治的能力，为了可以技术异构等目标，是继为了性能与算力之后，让程序再次选择分布式的理由。然而，开发分布式程序也并不意味着一定要依靠今天的微服务架构才能实现。在新旧世纪之交，人们曾经探索过几种服务拆分方法，将一个大的单体系统拆分为若干个更小的、不运行在同一个进程的独立服务，这些服务拆分方法后来导致了[面向服务架构](https://en.wikipedia.org/wiki/Service-oriented_architecture)（Service-Oriented Architecture）的一段兴盛期，我们称其为“[SOA 时代](https://icyfenix.cn/architecture/architect-history/soa.html)”。

### 1.3. SOA 时代

> [!abstract] SOA 架构（Service-Oriented Architecture）
> 
> 面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。

为了对大型的单体系统进行拆分，让每一个子系统都能独立地部署、运行、更新，开发者们曾经尝试过多种方案，这里列举以下三种较有代表性的架构模式，具体如下：

- [烟囱式架构](https://en.wikipedia.org/wiki/Information_silo)（Information Silo Architecture）
	信息烟囱又名信息孤岛（Information Island），它指的是一种完全不与其他相关信息系统进行互操作或者协调工作的设计模式。这样的系统其实并没有什么“架构设计”可言，而唯一的问题，也是致命的问题是，企业中真的存在完全不发生交互的部门吗？对于两个信息系统来说，哪怕真的毫无业务往来关系，但系统的人员、组织、权限等主数据，会是完全独立、没有任何重叠的吗？这样“独立拆分”“老死不相往来”的系统，显然不可能是企业所希望见到的。
- [微内核架构](https://en.wikipedia.org/wiki/Microkernel)（Microkernel Architecture）
	微内核架构也被称为插件式架构（Plug-in Architecture）。既然在烟囱式架构中，没有业务往来关系的系统也可能需要共享人员、组织、权限等一些的公共的主数据，那不妨就将这些主数据，连同其他可能被各子系统使用到的公共服务、数据、资源集中到一块，成为一个被所有业务系统共同依赖的核心（Kernel，也称为 Core System），具体的业务系统以插件模块（Plug-in Modules）的形式存在，这样也可提供可扩展的、灵活的、天然隔离的功能特性，即微内核架构。  

	![](https://r2.129870.xyz/img/202212152042496.png)

	这种模式很适合桌面应用程序，也经常在 Web 应用程序中使用。任何计算机系统都是由各种软件互相配合工作来实现具体功能的。对于平台型应用来说，如果我们希望将新特性或者新功能及时加入系统，微内核架构会是一种不错的方案。微内核架构也可以嵌入到其他的架构模式之中，通过插件的方式来提供新功能的定制开发能力，如果你准备实现一个能够支持二次开发的软件系统，微内核也会是一种良好的选择。

	不过，**微内核架构也有它的局限和使用前提，它假设系统中各个插件模块之间是互不认识，不可预知系统将安装哪些模块，因此这些插件可以访问内核中一些公共的资源，但不会直接交互**。可是，无论是企业信息系统还是互联网应用，这一前提假设在许多场景中都并不成立，我们必须找到办法，既能拆分出独立的系统，也能让拆分后的子系统之间顺畅地互相调用通信。

- [事件驱动架构](https://en.wikipedia.org/wiki/Event-driven_architecture)（Event-Driven Architecture）
	为了能让子系统互相通信，一种可行的方案是在子系统之间建立一套事件队列管道（Event Queues），来自系统外部的消息将以事件的形式发送至管道中，各个子系统从管道里获取自己感兴趣、能够处理的事件消息，也可以为事件新增或者修改其中的附加信息，甚至可以自己发布一些新的事件到管道队列中去，如此，每一个消息的处理者都是独立的，高度解耦的，但又能与其他处理者（如果存在该消息处理者的话）通过事件管道进行互动。

	![](https://r2.129870.xyz/img/202212152044980.png)

当系统演化至事件驱动架构时，与[原始分布式时代](https://icyfenix.cn/architecture/architect-history/primitive-distribution.html)并行发展的远程服务调用也迎来了 SOAP 协议的诞生（详见[远程服务调用](https://icyfenix.cn/architect-perspective/general-architecture/api-style/rpc.html)一文），此时“面向服务的架构”（Service Oriented Architecture，SOA）已经有了它登上软件架构舞台所需要的全部前置条件。

软件架构来到 SOA 时代，许多概念、思想都已经能在今天微服务中找到对应的身影了，譬如服务之间的松散耦合、注册、发现、治理，隔离、编排，等等。这些在今天微服务中耳熟能详的名词概念，大多数也是在分布式服务刚被提出时就已经可以预见的困难点。SOA 针对这些问题，甚至是针对“软件开发”这件事情本身，都进行了更加系统性、更加具体的探索。

- “更具体”体现在尽管 SOA 本身还是属抽象概念，而不是特指某一种具体的技术。但它比单体架构和前面所列举的三种架构模式的操作性要更强，已经不能简单视其为一种架构风格，而是可以称为一套软件设计的基础平台了。
    - 它拥有领导制定技术标准的组织 Open CSA；
    - 有清晰软件设计的指导原则，譬如服务的封装性、自治、松耦合、可重用、可组合、无状态，等等；
    - 明确了采用 SOAP 作为远程调用的协议，依靠 SOAP 协议族（WSDL、UDDI 和一大票 WS-\*协议）来完成服务的发布、发现和治理；
    - 利用一个被称为[企业服务总线](https://zh.wikipedia.org/zh-hans/%E4%BC%81%E4%B8%9A%E6%9C%8D%E5%8A%A1%E6%80%BB%E7%BA%BF)（Enterprise Service Bus，ESB）的消息管道来实现各个子系统之间的通信交互，令各服务间在 ESB 调度下无须相互依赖却能相互通信，既带来了服务松耦合的好处，也为以后可以进一步实施[业务流程编排](https://zh.wikipedia.org/wiki/%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%AE%A1%E7%90%86)（Business Process Management，BPM）提供了基础；
    - 使用[服务数据对象](https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1)（Service Data Object，SDO）来访问和表示数据，使用[服务组件架构](https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E7%BB%84%E4%BB%B6%E6%9E%B6%E6%9E%84)（Service Component Architecture，SCA）来定义服务封装的形式和服务运行的容器。

    在这一整套成体系可以互相精密协作的技术组件支持下，若仅从技术可行性这一个角度来评判的话，SOA 可以算是成功地解决了分布式环境下出现的主要技术问题。

- “更系统”指的是 SOA 的宏大理想，它的终极目标是希望总结出一套自上而下的软件研发方法论，希望做到企业只需要跟着 SOA 的思路，就能够一揽子解决掉软件开发过程中的全部问题。
    譬如该如何挖掘需求、如何将需求分解为业务能力、如何编排已有服务、如何开发测试部署新的功能，等等。这里面技术问题确实是重点和难点，但也仅仅是其中的一个方面，SOA 不仅关注技术，还关注研发过程中涉及到的需求、管理、流程和组织。如果这个目标真的能够达成，软件开发就有可能从此迈进工业化大生产的阶段，试想如果有一天写出符合客户需求的软件会像写八股文一样有迹可循、有法可依，那对软件开发者来说也许是无趣的，但整个社会实施信息化的效率肯定会有大幅的提升。

过于严格的规范定义带来过度的复杂性。而构建在 SOAP 基础之上的 ESB、BPM、SCA、SDO 等诸多上层建筑，进一步加剧了这种复杂性。开发信息系统毕竟不是作八股文章，过于精密的流程和理论也需要懂得复杂概念的专业人员才能够驾驭。SOA 诞生的那一天起，就已经注定了它只能是少数系统阳春白雪式的精致奢侈品，它可以实现多个异构大型系统之间的复杂集成交互，却很难作为一种具有广泛普适性的软件架构风格来推广。SOA 最终没有获得成功的致命伤与当年的[EJB](https://zh.wikipedia.org/wiki/EJB)如出一辙，尽管有 Sun Microsystems 和 IBM 等一众巨头在背后力挺，EJB 仍然败于以 Spring、Hibernate 为代表的“草根框架”，可见一旦脱离人民群众，终究会淹没在群众的海洋之中，连信息技术也不曾例外过。

读到这里，你不妨回想下“**如何使用多个独立的分布式服务共同构建一个更大型系统**”这个问题，再回想下“原始分布式时代”一节中 Unix DCE 提出的分布式服务的设计主旨：“**让开发人员不必关心服务是远程还是本地，都能够透明地调用服务或者访问资源**”。经过了三十年的技术进步，**信息系统经历了巨石、烟囱、插件、事件、SOA 等的架构模式，应用受架构复杂度的牵绊却是越来越大，已经距离“透明”二字越来越远了**，这是否算不自觉间忘记掉了当年的初心？接下来我们所谈论的微服务时代，似乎正是带着这样的自省式的问句而开启的。

### 1.4. 微服务时代

> [!abstract] 微服务架构（Microservices）
> 
> 微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维。

现代微服务的概念：“**微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维**。”此外，文中列举了微服务的九个核心的业务与技术特征，下面将其一一列出并解读。

- **围绕业务能力构建**（Organized around Business Capability）。
	这里再次强调了康威定律的重要性，有怎样结构、规模、能力的团队，就会产生出对应结构、规模、能力的产品。这个结论不是某个团队、某个公司遇到的巧合，而是必然的演化结果。如果本应该归属同一个产品内的功能被划分在不同团队中，必然会产生大量的跨团队沟通协作，跨越团队边界无论在管理、沟通、工作安排上都有更高昂的成本，高效的团队自然会针对其进行改进，当团队、产品磨合调节稳定之后，团队与产品就会拥有一致的结构。
	
	> [!info] 康威定律
	> 
	> 康威定律（Conway's Law）是由计算机科学家梅尔文·康威（Melvin Conway）在 1967 年提出的一条经验法则。该定律表述为：
	> 
	> "组织设计出来的系统，在其设计中所体现的组织沟通结构，最终会成为这个系统的实际结构。"
	> 
	> 简而言之，康威定律强调了组织内部的沟通方式和架构设计之间存在密切的联系。如果一个团队的组织架构复杂，那么他们开发的系统也有可能因为各个部分之间的沟通和协调问题而变得复杂。相反，如果组织架构简单、清晰，那么他们开发的系统也有可能更加简洁、易于理解和管理。
 
- **分散治理**（Decentralized Governance）。
	服务对应的开发团队有直接对服务运行质量负责的责任，也应该有着不受外界干预地掌控服务各个方面的权力，譬如选择与其他服务异构的技术来实现自己的服务。这一点在真正实践时多少存有宽松的处理余地，大多数公司通常会有统一的主流语言，乃至统一的技术栈或专有的技术平台。微服务不提倡也并不反对这种“统一”，微服务更加强调的是确实有必要技术异构时，应能够有选择“不统一”的权利。
- **通过服务来实现独立自治的组件**（Componentization via Services）。
	之所以强调通过“服务”（Service）而不是“类库”（Library）来构建组件，是因为类库在编译期静态链接到程序中，通过本地调用来提供功能，而服务是进程外组件，通过远程调用来提供功能。前面的文章里我们已经分析过，尽管远程服务有更高昂的调用成本，但这是为组件带来隔离与自治能力的必要代价。
- **产品化思维**（Products not Projects）。
	避免把软件研发视作要去完成某种功能，而是视作一种持续改进、提升的过程。譬如，不应该把运维只看作运维团队的事，把开发只看作开发团队的事，团队应该为软件产品的整个生命周期负责，开发者不仅应该知道软件如何开发，还应该知道它如何运作，用户如何反馈，乃至售后支持工作是怎样进行的。注意，这里服务的用户不一定是最终用户，也可能是消费这个服务的另外一个服务。

	以前在单体架构下，程序的规模决定了无法让全部人员都关注完整的产品，组织中会有开发、运维、支持等细致的分工的成员，各人只关注于自己的一块工作，但在微服务下，要求开发团队中每个人都具有产品化思维，关心整个产品的全部方面是具有可行性的。

- **数据去中心化**（Decentralized Data Management）。
	**微服务明确地提倡数据应该按领域分散管理、更新、维护、存储**，在单体服务中，一个系统的各个功能模块通常会使用同一个数据库，诚然中心化的存储天生就更容易避免一致性问题，但是，同一个数据实体在不同服务的视角里，它的抽象形态往往也是不同的。譬如，Bookstore 应用中的书本，在销售领域中关注的是价格，在仓储领域中关注的库存数量，在商品展示领域中关注的是书籍的介绍信息，如果作为中心化的存储，所有领域都必须修改和映射到同一个实体之中，这便使得不同的服务很可能会互相产生影响而丧失掉独立性。**尽管在分布式中要处理好一致性的问题也相当困难，很多时候都没法使用传统的事务处理来保证，但是两害相权取其轻，有一些必要的代价仍是值得付出的**。
- **强终端弱管道**（Smart Endpoint and Dumb Pipe）。
	弱管道（Dumb Pipe）几乎算是直接指名道姓地反对 SOAP 和 ESB 的那一堆复杂的通信机制。ESB 可以处理消息的编码加工、业务规则转换等；BPM 可以集中编排企业业务服务；SOAP 有几十个 WS-\*协议族在处理事务、一致性、认证授权等一系列工作，这些构筑在通信管道上的功能也许对某个系统中的某一部分服务是有必要的，但对于另外更多的服务则是强加进来的负担。如果服务需要上面的额外通信能力，就应该在服务自己的 Endpoint 上解决，而不是在通信管道上一揽子处理。微服务提倡类似于经典 UNIX 过滤器那样简单直接的通信方式，RESTful 风格的通信在微服务中会是更加合适的选择。
- **容错性设计**（Design for Failure）。
	不再虚幻地追求服务永远稳定，而是接受服务总会出错的现实，要求在微服务的设计中，有**自动的机制对其依赖的服务能够进行快速故障检测，在持续出错的时候进行隔离，在服务恢复的时候重新联通**。所以“断路器”这类设施，对实际生产环境的微服务来说并不是可选的外围组件，而是一个必须的支撑点，如果没有容错性的设计，系统很容易就会被因为一两个服务的崩溃所带来的雪崩效应淹没。可靠系统完全可能由会出错的服务组成，这是微服务最大的价值所在。
- **演进式设计**（Evolutionary Design）。
	容错性设计承认服务会出错，演进式设计则是承认服务会被报废淘汰。一个设计良好的服务，应该是能够报废的，而不是期望得到长存永生。假如系统中出现不可更改、无可替代的服务，这并不能说明这个服务是多么的优秀、多么的重要，反而是一种系统设计上脆弱的表现，微服务所追求的独立、自治，也是反对这种脆弱性的表现。
- **基础设施自动化**（Infrastructure Automation）。
	基础设施自动化，如 CI/CD 的长足发展，显著减少了构建、发布、运维工作的复杂性。由于微服务下运维的对象比起单体架构要有数量级的增长，使用微服务的团队更加依赖于基础设施的自动化，人工是很难支撑成百上千乃至成千上万级别的服务的。

从以上微服务的定义和特征中，你应该可以明显地感觉到微服务追求的是更加自由的架构风格，摒弃了几乎所有 SOA 里可以抛弃的约束和规定，提倡以“实践标准”代替“规范标准”。可是，如果没有了统一的规范和约束，以前 SOA 所解决的那些分布式服务的问题，不也就一下子都重新出现了吗？的确如此，服务的注册发现、跟踪治理、负载均衡、故障隔离、认证授权、伸缩扩展、传输通信、事务处理，等等，这些问题，在微服务中不再会有统一的解决方案。

微服务所带来的自由是一把双刃开锋的宝剑，当软件架构者拿起这把宝剑，一刃指向 SOA 定下的复杂技术标准，将选择的权力夺回的同一时刻，另外一刃也正朝向着自己映出冷冷的寒光。微服务时代中，软件研发本身的复杂度应该说是有所降低。一个简单服务，并不见得就会同时面临分布式中所有的问题，也就没有必要背上 SOA 那百宝袋般沉重的技术包袱。需要解决什么问题，就引入什么工具；团队熟悉什么技术，就使用什么框架。

### 1.5. 后微服务时代

上节提到的分布式架构中出现的问题，如注册发现、跟踪治理、负载均衡、传输通信等，其实在 SOA 时代甚至可以说从原始分布式时代起就已经存在了，只要是分布式架构的系统，就无法完全避免，但我们不妨换个思路来想一下，这些问题一定要由软件系统自己来解决吗？

如果不局限于采用软件的方式，这些问题几乎都有对应的硬件解决方案。譬如，某个系统需要伸缩扩容，通常会购买新的服务器，部署若干副本实例来分担压力；如果某个系统需要解决负载均衡问题，通常会布置负载均衡器，选择恰当的均衡算法来分流；如果需要解决传输安全问题，通常会布置 TLS 传输链路，配置好 CA 证书以保证通信不被窃听篡改；如果需要解决服务发现问题，通常会设置 DNS 服务器，让服务访问依赖稳定的记录名而不是易变的 IP 地址，等等。经过计算机科学多年的发展，这些问题大多有了专职化的基础设施去解决，而**之所以微服务时代，人们选择在软件的代码层面而不是硬件的基础设施层面去解决这些分布式问题，很大程度上是因为由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性的无奈之举**。软件可以只使用键盘命令就能拆分出不同的服务，只通过拷贝、启动就能够伸缩扩容服务，硬件难道就不可以通过敲键盘就变出相应的应用服务器、负载均衡器、DNS 服务器、网络链路这些设施吗？

行文至此，估计大家已经听出下面要说的是[虚拟化](https://en.wikipedia.org/wiki/Virtualization)技术和[容器化](https://en.wikipedia.org/wiki/OS-level_virtualization)技术了。微服务时代所取得的成就，本身就离不开以 Docker 为代表的早期容器化技术的巨大贡献。早期的容器只被简单地视为一种可快速启动的服务运行环境，目的是方便程序的分发部署，这个阶段针对单个应用进行封装的容器并未真正参与到分布式问题的解决之中。但是，被业界广泛认可、普遍采用的通过虚拟化基础设施去解决分布式架构问题的开端，应该要从 2017 年 Kubernetes 赢得容器战争的胜利开始算起。

“前途广阔”不仅仅是一句恭维赞赏的客气话，**当虚拟化的基础设施从单个服务的容器扩展至由多个容器构成的服务集群、通信网络和存储设施时，软件与硬件的界限便已经模糊**。一旦虚拟化的硬件能够跟上软件的灵活性，那些与业务无关的技术性问题便有可能从软件层面剥离，悄无声息地解决于硬件基础设施之内，让软件得以只专注业务，真正“围绕业务能力构建”团队与产品。如此，DCE 中未能实现的“透明的分布式应用”成为可能，Martin Fowler 设想的“[凤凰服务器](https://martinfowler.com/bliki/PhoenixServer.html)“成为可能，Chad Fowler 提出的“[不可变基础设施](http://chadfowler.com/2013/06/23/immutable-deployments.html)”也成为可能，从软件层面独力应对分布式架构所带来的各种问题，发展到应用代码与基础设施软、硬一体，合力应对架构问题的时代，现在常被媒体冠以“云原生”这个颇为抽象的名字加以宣传。云原生时代与此前微服务时代中追求的目标并没有本质改变，在服务架构演进的历史进程中，笔者更愿意称其为“后微服务时代”。

Kubernetes 成为容器战争胜利者标志着后微服务时代的开端，但 Kubernetes 仍然没有能够完美解决全部的分布式问题——“不完美”的意思是，仅从功能上看，单纯的 Kubernetes 反而不如之前的 Spring Cloud 方案。这是因为**有一些问题处于应用系统与基础设施的边缘，使得完全在基础设施层面中确实很难精细化地处理**。举个例子，微服务 A 调用了微服务 B 的两个服务，称为 B1 和 B2，假设 B1 表现正常但 B2 出现了持续的错误，那在达到一定阈值之后就应该对 B2 进行熔断，以避免产生[雪崩效应](https://en.wikipedia.org/wiki/Snowball_effect)。如果仅在基础设施层面来处理，这会遇到一个两难问题，切断 A 到 B 的网络通路则会影响到 B1 的正常调用，不切断的话则持续受 B2 的错误影响。

![](https://r2.129870.xyz/img/202212152113770.png)

以上问题在通过 Spring Cloud 这类应用代码实现的微服务中并不难处理，既然是使用程序代码来解决问题，只要合乎逻辑，想要实现什么功能，只受限于开发人员的想象力与技术能力，但基础设施是针对整个容器来管理的，粒度相对粗旷，只能到容器层面，对单个远程服务就很难有效管控。类似的情况不仅仅在断路器上出现，服务的监控、认证、授权、安全、负载均衡等都有可能面临细化管理的需求，譬如服务调用时的负载均衡，往往需要根据流量特征，调整负载均衡的层次、算法，等等，而 DNS 尽管能实现一定程度的负载均衡，但通常并不能满足这些额外的需求。

为了解决这一类问题，虚拟化的基础设施很快完成了第二次进化，引入了今天被称为“[服务网格](https://en.wikipedia.org/wiki/Service_mesh)”（Service Mesh）的“边车代理模式”（Sidecar Proxy）。所谓的“边车”是一种带垮斗的三轮摩托，这个场景里指的具体含义是由系统自动在服务容器（通常是指 Kubernetes 的 Pod）中注入一个通信代理服务器，相当于那个挎斗，以类似网络安全里中间人攻击的方式进行流量劫持，在应用毫无感知的情况下，悄然接管应用所有对外通信。这个代理除了实现正常的服务间通信外（称为数据平面通信），还接收来自控制器的指令（称为控制平面通信），根据控制平面中的配置，对数据平面通信的内容进行分析处理，以实现熔断、认证、度量、监控、负载均衡等各种附加功能。这样便实现了既不需要在应用层面加入额外的处理代码，也提供了几乎不亚于程序代码的精细管理能力。

![](https://r2.129870.xyz/img/202212152114990.png)

很难从概念上判定清楚一个与应用系统运行于同一资源容器之内的代理服务到底应该算软件还是算基础设施，但它对应用是透明的，不需要改动任何软件代码就可以实现服务治理，这便足够。

### 1.6. 无服务时代

> [!abstract] 无服务架构（Serverless）
>
> 如果说微服务架构是分布式系统这条路的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。

人们研究分布式架构，最初是由于单台机器的性能无法满足系统的运行需要，尽管在后来架构演进过程中，容错能力、技术异构、职责划分等各方面因素都成为架构需要考虑的问题，但其中**获得更好性能的需求在架构设计中依然占很大的比重**。对软件研发而言，不去做分布式无疑才是最简单的，如果单台服务器的性能可以是无限的，那架构演进的结果肯定会与今天有很大的差别，分布式也好，容器化也好，微服务也好，恐怕都未必会如期出现，最起码不必一定是像今天这个样子。

无服务现在还没有一个特别权威的“官方”定义，但它的概念并没有前面各种架构那么复杂，本来无服务也是以“简单”为主要卖点的，它只涉及两块内容：后端设施（Backend）和函数（Function）。

- 后端设施是指数据库、消息队列、日志、存储，等等这一类用于支撑业务逻辑运行，但本身无业务含义的技术组件，这些后端设施都运行在云中，无服务中称其为“后端即服务”（Backend as a Service，BaaS）。
- 函数是指业务逻辑代码，这里函数的概念与粒度，都已经很接近于程序编码角度的函数了，其区别是无服务中的函数运行在云端，不必考虑算力问题，不必考虑容量规划（从技术角度可以不考虑，从计费的角度你的钱包够不够用还是要掂量一下的），无服务中称其为“函数即服务”（Function as a Service，FaaS）。

无服务的愿景是让开发者只需要纯粹地关注业务，不需要考虑技术组件，后端的技术组件是现成的，可以直接取用，没有采购、版权和选型的烦恼；不需要考虑如何部署，部署过程完全是托管到云端的，工作由云端自动完成；不需要考虑算力，有整个数据中心支撑，算力可以认为是无限的；也不需要操心运维，维护系统持续平稳运行是云计算服务商的责任而不再是开发者的责任。在 UC Berkeley 的论文中，把无服务架构下开发者不再关心这些技术层面的细节，类比成当年软件开发从汇编语言踏进高级语言的发展过程，开发者可以不去关注寄存器、信号、中断等与机器底层相关的细节，从而令生产力得到极大地解放。

无服务架构的远期前景看起来是很美好的，但笔者自己对无服务中短期内的发展并没有那么乐观。无服务架构对一些适合的应用确实能够降低开发和运维环节的成本，譬如不需要交互的离线大规模计算，又譬如多数 Web 资讯类网站、小程序、公共 API 服务、移动应用服务端等都契合于无服务架构所擅长的短链接、无状态、适合事件驱动的交互形式；但另一方面，对于那些信息管理系统、网络游戏等应用，又或者说所有具有业务逻辑复杂，依赖服务端状态，响应速度要求较高，需要长链接等这些特征的应用，至少目前是相对并不适合的。这是因为无服务天生“无限算力”的假设决定了它必须要按使用量（函数运算的时间和占用的内存）计费以控制消耗算力的规模，因而函数不会一直以活动状态常驻服务器，请求到了才会开始运行，这导致了函数不便依赖服务端状态，也导致了函数会有冷启动时间，响应的性能不可能太好（目前无服务的冷启动过程大概是在数十到百毫秒级别，对于 Java 这类启动性能差的应用，甚至能到接近秒的级别）。

## 2. 远程服务访问

> [!abstract] 远程服务
> 远程服务将计算机程序的工作范围从单机扩展到网络，从本地延伸至远程，是构建分布式系统的首要基础。而远程服务又不仅仅是为了分布式系统服务的，在网络时代，浏览器、移动设备、桌面应用和服务端的程序，普遍都有跟其他设备交互的需求，所以今天已经很难找到没有开发和使用过远程服务的程序员了，但是没有正确理解远程服务的程序员却仍比比皆是。

### 2.1. 远程服务调用 RPC

#### 2.1.1. 进程间通信

尽管今天的大多数 RPC 技术已经不再追求这个目标了，但无可否认，RPC 出现的最初目的，就是**为了让计算机能够跟调用本地方法一样去调用远程方法**。

当调用本地方法时，通常会进行以下四步操作：

1. 传递方法参数
    将参数压栈。
2. 确定方法版本
    根据方法的签名，确定其执行版本。这其实并不是一个简单的过程，不论是编译时静态解析也好，是运行时动态分派也好，总之必须根据某些语言规范中明确定义原则，找到明确的 `Callee`，“明确”是指唯一的一个 `Callee`，或者有严格优先级的多个 `Callee`，譬如不同的重载版本。
3. 执行被调方法
    从栈中弹出参数，进行方法的调用。
4. 返回执行结果
    将执行的结果压栈，并将程序指令流恢复到 `Call Site` 的下一条指令继续执行。

如果被调用的方法不在当前进程的内存地址空间中，那么会发生什么问题？不难想到，此时至少面临两个直接的障碍：首先，第一步和第四步所做的传递参数、传回结果都依赖于栈内存的帮助，如果 `Caller` 与 `Callee` 分属不同的进程，就不会拥有相同的栈内存，将参数在 `Caller` 进程的内存中压栈，对于 Callee 进程的执行毫无意义。其次，第二步的方法版本选择依赖于语言规则的定义，如果 `Caller` 与 `Callee` 不是同一种语言实现的程序，方法版本选择就将是一项模糊的不可知行为。

为了简化讨论，我们暂时忽略第二个障碍，假设 `Caller` 与 `Callee` 是使用同一种语言实现的，先来解决两个进程之间如何交换数据的问题，这件事情在计算机科学中被称为“[进程间通信](https://en.wikipedia.org/wiki/Inter-process_communication)”（Inter-Process Communication，IPC）。可以考虑的办法有以下几种：

- 管道
    管道类似于两个进程间的桥梁，可通过管道在进程间传递少量的字符流或字节流。典型的管道应用就是命令行中的 `｜` 操作符，譬如：

    ```shell
    ps -ef | grep java
    ```

- 信号
    信号用于通知目标进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程自身。信号的典型应用是 `kill` 命令，譬如：

    ```
    kill -9 pid
    ```

    以上就是由 Shell 进程向指定 PID 的进程发送 SIGKILL 信号。

- 信号量
    信号量用于两个进程之间同步协作手段，它相当于操作系统提供的一个特殊变量，程序可以在上面进行 `wait()` 和 `notify()` 操作。
- 消息队列
    POSIX 标准中定义了消息队列用于进程间数据量较多的通信。进程可以向队列添加消息，被赋予读权限的进程则可以从队列消费消息。消息队列克服了信号承载信息量少，管道只能用于无格式字节流以及缓冲区大小受限等缺点，但实时性相对受限。
- 共享内存
    许多个进程访问同一块公共的内存空间，这是效率最高的进程间通信形式。原本每个进程的内存地址空间都是相互隔离的，但操作系统提供了让进程主动创建、映射、分离、控制某一块内存的程序接口。当一块内存被多进程共享时，各个进程往往会与其它通信机制，譬如信号量结合使用，来达到进程间同步及互斥的协调操作。
- 套接字接口
    消息队列和共享内存只适合单机多进程间的通信，套接字接口是更为普适的进程间通信机制，可用于不同机器之间的进程通信。
    
    > [!tip] 套接字
    > 
    > 套接字（Socket）起初是由 UNIX 系统的 BSD 分支开发出来的，现在已经移植到所有主流的操作系统上。出于效率考虑，当仅限于本机进程间通信时，套接字接口是被优化过的，不会经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等操作，只是简单地将应用层数据从一个进程拷贝到另一个进程，这种进程间通信方式有个专名的名称：UNIX Domain Socket，又叫做 IPC Socket。

#### 2.1.2. 通信的成本

> [!tip] 远程服务调用
> 远程服务调用是指位于互不重合的内存地址空间中的两个程序，在语言层面上，以同步的方式使用带宽有限的信道来传输程序控制信息。
> 
> ![image.png](https://r2.129870.xyz/img/202306142314300.png)

早期科学家们将 RPC 作为 IPC 的一种特例来看待的，但这种透明的调用形式却反而造成了程序员误以为**通信是无成本的假象**，因而被滥用以致于显著降低了分布式系统的性能。因此有人对这种透明的 RPC 范式提出了一系列质问：

- 两个进程通信，谁作为服务端，谁作为客户端？
- 怎样进行异常处理？异常该如何让调用者获知？
- 服务端出现多线程竞争之后怎么办？
- 如何提高网络利用的效率，譬如连接是否可被多个请求复用以减少开销？是否支持多播？
- 参数、返回值如何表示？应该有怎样的字节序？
- 如何保证网络的可靠性？譬如调用期间某个链接忽然断开了怎么办？
- 发送的请求服务端收不到回复该怎么办？

因此将本地调用与远程调用当做一样处理，这是犯了方向性的错误，把系统间的调用做成透明，反而会增加程序员工作的复杂度。

1. The network is reliable —— 网络是可靠的。
2. Latency is zero —— 延迟是不存在的。
3. Bandwidth is infinite —— 带宽是无限的。
4. The network is secure —— 网络是安全的。
5. Topology doesn't change —— 拓扑结构是一成不变的。
6. There is one administrator —— 总会有一个管理员。
7. Transport cost is zero —— 不必考虑传输成本。
8. The network is homogeneous —— 网络是同质化的。

以上这八条反话被认为是程序员在网络编程中经常被忽略的八大问题，潜台词就是如果远程服务调用要弄透明化的话，就必须为这些罪过埋单

#### 2.1.3. 三个基本问题

这几十年来所有流行过的 RPC 协议，都不外乎变着花样使用各种手段来解决以下三个基本问题：

1. 如何表示数据
    这里数据包括了传递给方法的参数，以及方法执行后的返回值。无论是将参数传递给另外一个进程，还是从另外一个进程中取回执行结果，都涉及到它们应该如何表示。

    进程内的方法调用，使用程序语言预置的和程序自定义的数据类型，就很容易解决数据表示问题，远程方法调用则完全可能面临交互双方各自使用不同程序语言的情况；即使只支持一种程序语言的 RPC 协议，在不同硬件指令集、不同操作系统下，同样的数据类型也完全可能有不一样表现细节，譬如数据宽度、字节序的差异等等。

    有效的做法是**将交互双方所涉及的数据转换为某种事先约定好的中立数据流格式来进行传输，将数据流转换回不同语言中对应的数据类型来进行使用**，这个过程就是序列化与反序列化。每种 RPC 协议都应该要有对应的序列化协议：

    - ONC RPC 的[External Data Representation](https://en.wikipedia.org/wiki/External_Data_Representation) （XDR）
    - CORBA 的[Common Data Representation](https://en.wikipedia.org/wiki/Common_Data_Representation)（CDR）
    - Java RMI 的[Java Object Serialization Stream Protocol](https://docs.oracle.com/javase/8/docs/platform/serialization/spec/protocol.html#a10258)
    - gRPC 的[Protocol Buffers](https://developers.google.com/protocol-buffers)
    - Web Service 的[XML Serialization](https://docs.microsoft.com/en-us/dotnet/standard/serialization/xml-serialization-with-xml-web-services)
    - 众多轻量级 RPC 支持的[JSON Serialization](https://tools.ietf.org/html/rfc7159)
2. 如何传递数据
    如何通过网络，在两个服务的 Endpoint 之间相互操作、交换数据。这里“交换数据”通常指的是应用层协议，实际传输一般是基于标准的 TCP、UDP 等标准的传输层协议来完成的。

    两个服务交互不是只扔个序列化数据流来表示参数和结果就行的，许多在此之外信息，譬如异常、超时、安全、认证、授权、事务，等等，都可能产生双方需要交换信息的需求。

    在计算机科学中，专门有一个名称“[Wire Protocol](https://en.wikipedia.org/wiki/Wire_protocol)”来用于表示这种两个 Endpoint 之间交换这类数据的行为，常见的 Wire Protocol 有：

    - Java RMI 的[Java Remote Message Protocol](https://docs.oracle.com/javase/8/docs/platform/rmi/spec/rmi-protocol3.html)（JRMP，也支持[RMI-IIOP](https://zh.wikipedia.org/w/index.php?title=RMI-IIOP&action=edit&redlink=1)）
    - CORBA 的[Internet Inter ORB Protocol](https://en.wikipedia.org/wiki/General_Inter-ORB_Protocol)（IIOP，是 GIOP 协议在 IP 协议上的实现版本）
    - DDS 的[Real Time Publish Subscribe Protocol](https://en.wikipedia.org/wiki/Data_Distribution_Service)（RTPS）
    - Web Service 的[Simple Object Access Protocol](https://en.wikipedia.org/wiki/SOAP)（SOAP）
    - 如果要求足够简单，双方都是 HTTP Endpoint，直接使用 HTTP 协议也是可以的（如 JSON-RPC）
3. 如何确定方法
    “如何找到对应的方法”还是需要设计一个跨语言的统一的标准，如以下用于表示方法的协议：
    
    - Android 的[Android Interface Definition Language](https://developer.android.com/guide/components/aidl)（AIDL）
    - CORBA 的[OMG Interface Definition Language](https://www.omg.org/spec/IDL)（OMG IDL）
    - Web Service 的[Web Service Description Language](https://zh.wikipedia.org/wiki/WSDL)（WSDL）
    - JSON-RPC 的[JSON Web Service Protocol](https://en.wikipedia.org/wiki/JSON-WSP)（JSON-WSP）

#### 2.1.4. 统一的 RPC

1999 年末，SOAP 1.0（Simple Object Access Protocol）规范的发布，它代表着一种被称为“Web Service”的全新的 RPC 协议的诞生。Web Service 协议家族中，除它本身包括的 SOAP、WSDL、UDDI 协议外，还有一堆几乎说不清有多少个、以 WS-\*命名的、用于解决事务、一致性、事件、通知、业务描述、安全、防重放等子功能协议，对开发者造成了非常沉重的学习负担。

当程序员们对 Web Service 的热情迅速兴起，又逐渐冷却之后，自己也不禁开始反思：那些面向透明的、简单的 RPC 协议，如 DCE/RPC、DCOM、Java RMI，要么依赖于操作系统，要么依赖于特定语言，总有一些先天约束；那些面向通用的、普适的 RPC 协议；如 CORBA，就无法逃过使用复杂性的困扰，CORBA 烦琐的 OMG IDL、ORB 都是很好的佐证；而那些意图通过技术手段来屏蔽复杂性的 RPC 协议，如 Web Service，又不免受到性能问题的束缚。简单、普适、高性能这三点，似乎真的难以同时满足。

#### 2.1.5. 分裂的 RPC

由于一直没有一个同时满足以上三点的“完美 RPC 协议”出现，所以远程服务器调用这个领域里出现了各式各样的 RPC 框架，这些 RPC 功能、特点不尽相同，有的是某种语言私有，有的能支持跨越多门语言，有的运行在应用层 HTTP 协议之上，有的能直接运行于传输层 TCP/UDP 协议之上，各个 RPC 框架有自己的针对性特点作为主要的发展方向：

- 朝着面向对象发展
    不满足于 RPC 将面向过程的编码方式带到分布式，希望在分布式系统中也能够进行跨进程的面向对象编程，代表为 RMI、. NET Remoting，之前的 CORBA 和 DCOM 也可以归入这类，这条线有一个别名叫做[分布式对象](https://en.wikipedia.org/wiki/Distributed_object)（Distributed Object）
- 朝着性能发展
    代表为 gRPC 和 Thrift。**决定 RPC 性能的主要就两个因素：序列化效率和信息密度**。序列化效率很好理解，序列化输出结果的容量越小，速度越快，效率自然越高；信息密度则取决于协议中有效荷载（Payload）所占总传输数据的比例大小，使用传输协议的层次越高，信息密度就越低。
- 朝着简化发展
    以 JSON-RPC 为代表，牺牲了功能和效率，换来的是协议的简单轻便，接口与格式都更为通用，尤其适合用于 Web 浏览器这类一般不会有额外协议支持、额外客户端支持的应用场合。

近几年来，RPC 框架有明显的朝着更高层次（不仅仅负责调用远程服务，还管理远程服务）与插件化方向发展的趋势，不再追求独立地解决 RPC 的全部三个问题（表示数据、传递数据、表示方法），而是将一部分功能设计成扩展点，让用户自己去选择。

### 2.2. REST 访问

> [!abstract] REST 设计风格
> REST 与 RPC 在思想上差异的核心是抽象的目标不一样，即面向资源的编程思想与面向过程的编程思想两者之间的区别。
> 
> REST 并不是一种远程服务调用协议，甚至它不是一种协议，REST 只能说是风格而不是规范、协议。

#### 2.2.1. 理解 REST

REST（**Re**presentational **S**tate **T**ransfer）：即表征状态转移。REST 实际上是“HTT”（**H**yper**t**ext **T**ransfer）的进一步抽象，两者就如同接口与实现类的关系一般。

> [!info] REST 与 HTT 
> REST 源于 Roy Thomas Fielding 在 2000 年发表的博士论文：《[Architectural Styles and the Design of Network-based Software Architectures](https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm)》。同时，Fielding 也是 HTTP 1.0 协议（1996 年发布）的专家组成员，后来还晋升为 HTTP 1.1 协议（1999 年发布）的负责人。
> 
> 从时间上看，对 HTTP 1.1 协议的设计工作贯穿了 Fielding 的整个博士研究生涯，当起草 HTTP 1.1 协议的工作完成后，Fielding 回到了加州大学欧文分校继续攻读自己的博士学位。第二年，他更为系统、严谨地阐述了这套理论框架，并且以这套理论框架导出了一种新的编程思想，他为这种程序设计风格取了一个很多人难以理解，但是今天已经广为人知的名字 REST，即“表征状态转移”的缩写。

下面我们尝试从“超文本”或者“超媒体”的含义来理解什么是“表征”以及 REST 中其他关键概念：

- 资源（Resource）
    浏览器向服务器请求的数据被当作资源。
- 表征（Representation）
    **服务端向浏览器返回的资源的表现形式被称之为“表征”**，该资源可能是 HTML 格式，亦或是 PDF、Markdown、RSS 等其他形式的版本，它们也同样是一个资源的多种表征。

    “表征”这个概念是指信息与用户交互时的表示形式，这与我们软件分层架构中常说的“表示层”（Presentation Layer）的语义其实是一致的。

- 状态（State）
    状态控制资源的后续表征结果。当你获取到当前资源并想继续得到后续资源时，需要继续向服务器发起申请。但是“后续资源”是个相对概念，必须依赖“当前你获取到的是哪个资源”才能正确回应，这类在特定语境中才能产生的上下文信息即被称为“状态”。
    
    **我们所说的有状态（Stateful）抑或是无状态（Stateless），都是指相对于服务端来说的**，服务器要完成“取下一份资源”的请求，要么自己记住用户的状态：这个用户现在获取的是哪一份资源，这称为有状态；要么客户端来记住状态，在请求的时候明确告诉服务器：我已获取某某资源，现在要得到它的后续资源，这称为无状态。
    
    > [!example] 示例
    > 以阅读网页文章为例，当你读完了这篇文章，想看后面是什么内容时，你向服务器发出请求“给我下一篇文章”。但是“下一篇”是个相对概念，必须依赖“当前你正在阅读的文章是哪一篇”才能正确回应。

- 转移（Transfer）
    无论状态是由服务端还是客户端来提供的，“取下一份资源”这个行为逻辑必然只能由服务端来提供，因为只有服务端拥有该资源及其表征形式。服务器通过某种方式，把“当前得到的资源”转变成“下一份资源”，这就被称为“表征状态转移”。

在理解 REST 的思想后，以下的相关概念描述了 REST 的一些特性：

- 统一接口（Uniform Interface）
    服务器“通过某种方式”让表征状态发生转移，具体是什么方式？ HTTP 协议中已经提前约定好了一套“统一接口”，它包括：GET、HEAD、POST、PUT、DELETE、TRACE、OPTIONS 七种基本操作，任何一个支持 HTTP 协议的服务器都会遵守这套规定，对特定的 URI 采取这些操作，服务器就会触发相应的表征状态转移。
- 超文本驱动（Hypertext Driven）
    尽管表征状态转移是由浏览器主动向服务器发出请求所引发的，但这是由服务器发出的请求响应信息（超文本）来驱动的。这点与其他带有客户端的软件有十分本质的区别，在那些软件中，业务逻辑往往是预置于程序代码之中的，有专门的页面控制器（无论在服务端还是在客户端中）来驱动页面的状态转移。
- 自描述消息（Self-Descriptive Messages）
    由于资源的表征可能存在多种不同形态，在消息中应当有明确的信息来告知客户端该消息的类型以及应如何处理这条消息。

    一种被广泛采用的自描述方法是在名为“Content-Type”的 HTTP Header 中标识出[互联网媒体类型](https://en.wikipedia.org/wiki/Media_type)（MIME type），譬如“Content-Type : application/json; charset=utf-8”，则说明该资源会以 JSON 的格式来返回，请使用 UTF-8 字符集进行处理。

#### 2.2.2. RESTful 的系统

一套理想的、完全满足 REST 风格的系统应该满足以下六大原则：

1. 服务端与客户端分离（Client-Server）
    将用户界面所关注的逻辑和数据存储所关注的逻辑分离开来，有助于提高用户界面的跨平台的可移植性。
2. 无状态（Stateless）
    **无状态是 REST 的一条核心原则**，REST 希望服务器不要去负责维护状态，每一次从客户端发送的请求中，应包括所有的必要的上下文信息，会话信息也由客户端负责保存维护，服务端依据客户端传递的状态来执行业务处理逻辑，驱动整个应用的状态变迁。

    客户端承担状态维护职责以后，会产生一些新的问题，譬如身份认证、授权等可信问题，它们都应有针对性的解决方案。

    但必须承认的现状是，目前大多数的系统都达不到这个要求，往往越复杂、越大型的系统越是如此。服务端无状态可以在分布式计算中获得非常高价值的好处，但**大型系统的上下文状态数量完全可能膨胀到让客户端在每次请求时提供变得不切实际的程度。在服务端的内存、会话、数据库或者缓存等地方持有一定的状态成为一种是事实上存在，并将长期存在、被广泛使用的主流的方案。**

3. 可缓存（Cacheability）
    无状态服务虽然提升了系统的可见性、可靠性和可伸缩性，但降低了系统的网络性。“降低网络性”的通俗解释是某个功能如果使用有状态的设计只需要一次（或少量）请求就能完成，使用无状态的设计则可能会需要多次请求，或者在请求中带有额外冗余的信息。

    为了缓解这个矛盾，REST 希望软件系统能够如同万维网一样，允许客户端和中间的通讯传递者（譬如代理）将部分服务端的应答缓存起来。当然，为了缓存能够正确地运作，服务端的应答中必须明确地或者间接地表明本身是否可以进行缓存、可以缓存多长时间，以避免客户端在将来进行请求的时候得到过时的数据。运作良好的缓存机制可以减少客户端、服务器之间的交互，甚至有些场景中可以完全避免交互，这就进一步提高了性能。

4. 分层系统（Layered System）
    这里所指的并不是表示层、服务层、持久层这种意义上的分层。而是指客户端一般不需要知道是否直接连接到了最终的服务器，抑或连接到路径上的中间服务器。中间服务器可以通过负载均衡和共享缓存的机制提高系统的可扩展性，这样也便于缓存、伸缩和安全策略的部署。该原则的典型的应用是内容分发网络（Content Distribution Network，CDN）
5. 统一接口（Uniform Interface）
    这是 REST 的另一条核心原则，**REST 希望开发者面向资源编程，希望软件系统设计的重点放在抽象系统该有哪些资源上，而不是抽象系统该有哪些行为（服务）上**。

    面向资源编程的抽象程度通常更高。抽象程度高意味着坏处是往往距离人类的思维方式更远，而好处是往往通用程度会更好。

6. 按需编码（[Code-On-Demand](https://en.wikipedia.org/wiki/Code_on_demand)）
    按需代码被 REST 列为一条可选原则。它是指任何按照客户端（譬如浏览器）的请求，将可执行的软件程序从服务器发送到客户端的技术，按需代码赋予了客户端无需事先知道所有来自服务端的信息应该如何处理、如何运行的宽容度。

REST 提出以资源为主体进行服务设计的风格，能为它带来不少好处，譬如：

- 降低服务接口的学习成本
    统一接口（Uniform Interface）是 REST 的重要标志，将对资源的标准操作都映射到了标准的 HTTP 方法上去，这些方法对于每个资源的用法都是一致的，语义都是类似的，不需要刻意去学习，更不需要有什么 Interface Description Language 之类的协议存在。
- 资源天生具有集合与层次结构
    以方法为中心抽象的接口，由于方法是动词，逻辑上决定了每个接口都是互相独立的；但以资源为中心抽象的接口，由于**资源是名词，天然就可以产生集合与层次结构**。
- REST 绑定于 HTTP 协议
    **面向资源编程不是必须构筑在 HTTP 之上，但 REST 是**。这是缺点，也是优点。因为 HTTP 本来就是面向资源而设计的网络协议，纯粹只用 HTTP（而不是 SOAP over HTTP 那样在再构筑协议）带来的好处是 RPC 中的 Wire Protocol 问题就无需再多考虑了，REST 将复用 HTTP 协议中已经定义的概念和相关基础支持来解决问题。HTTP 协议已经有效运作了三十年，其相关的技术基础设施已是千锤百炼，无比成熟。而坏处自然是，当你想去考虑那些 HTTP 不提供的特性时，便会彻底地束手无策。

当然，REST 也有它不足的地方（好处与不足都是仁者见仁智者见智）：

- 面向资源的编程思想只适合做 CRUD，面向过程、面向对象编程才能处理真正复杂的业务逻辑
    HTTP 的四个最基础的命令 POST、GET、PUT 和 DELETE 很容易让人直接联想到 CRUD 操作，只是这个 CRUD 必须泛化去理解。它们涵盖了信息在客户端与服务端之间如何流动的几种主要方式，所有基于网络的操作逻辑，都可以对应到信息在服务端与客户端之间如何流动来理解，有的场景里比较直观，而另一些场景中可能比较抽象。

    针对那些比较抽象的场景，如果真不好把 HTTP 方法映射为资源的所需操作，REST 也并非刻板的教条，用户是可以使用自定义方法的，按 Google 推荐的 REST API 风格，[自定义方法](https://cloud.google.com/apis/design/custom_methods)应该放在资源路径末尾，嵌入冒号加自定义动词的后缀。

- REST 与 HTTP 完全绑定，不适合应用于要求高性能传输的场景中
    面向资源编程与协议无关，但是 REST 的确依赖着 HTTP 协议的标准方法、状态码、协议头等各个方面。HTTP 并不是传输层协议，它是应用层协议，如果仅将 HTTP 当作传输是不恰当的。

    对于需要直接控制传输，如二进制细节、编码形式、报文格式、连接方式等细节的场景中，REST 确实不合适，这些场景往往存在于服务集群的内部节点之间，这也是之前曾提及的，REST 和 RPC 尽管应用场景的确有所重合，但重合的范围有多大就是见仁见智的事情。

- REST 不利于事务支持
    如果“事务”指的是数据库那种的狭义的刚性 ACID 事务，那除非完全不持有状态，否则分布式系统本身与此就是有矛盾的（CAP 不可兼得），这是分布式的问题而不是 REST 的问题。

    如果“事务”是指通过服务协议或架构，在分布式服务中，获得对多个数据同时提交的统一协调能力（2PC/3PC），譬如[WS-AtomicTransaction](http://docs.oasis-open.org/ws-tx/wstx-wsat-1.1-spec-errata-os/wstx-wsat-1.1-spec-errata-os.html)、[WS-Coordination](http://docs.oasis-open.org/ws-tx/wstx-wscoor-1.1-spec-errata-os/wstx-wscoor-1.1-spec-errata-os.html)这样的功能性协议，这 REST 确实不支持。

    如果“事务”只是指希望保障数据的最终一致性，说明你已经放弃刚性事务了，这才是分布式系统中的正常交互方式，使用 REST 肯定不会有什么阻碍，谈不上“不利于”。

- REST 没有传输可靠性支持
    在 HTTP 中你发送出去一个请求，通常会收到一个与之相对的响应，譬如 HTTP/1.1 200 OK 或者 HTTP/1.1 404 Not Found 诸如此类的。但如果你没有收到任何响应，那就无法确定消息到底是没有发送出去，抑或是没有从服务端返回回来，这其中的关键差别是服务端到底是否被触发了某些处理？应对传输可靠性最简单粗暴的做法是把消息再重发一遍。这种简单处理能够成立的前提是服务应具有[幂等性](https://zh.wikipedia.org/wiki/%E5%86%AA%E7%AD%89)（Idempotency）
- REST 缺乏对资源进行“部分”和“批量”的处理能力
    REST 开创了面向资源的服务风格，却肯定仍并不完美。当我们想仅获取资源的某部分数据或者对资源进行批量操作时，REST 在这方面显得不足。当想获取部分资源时，REST 风格是获取到资源的全部信息并只提取我们关心的属性并抛弃其他的属性。而另外一方面，与此相对的缺陷是对资源的批量操作的支持，有时候我们不得不为此而专门设计一些抽象的资源才能应对。

## 3. 事务处理

内部事务通常用 ACID 来解决，但是外部一致性问题通常很难使用 A、I、D 来解决，因为这样需要付出很大甚至不切实际的代价；但是外部一致性又是分布式系统中必然会遇到且必须要解决的问题，为此我们要转变观念，将一致性从“是或否”的二元属性转变为可以按不同强度分开讨论的多元属性，在确保代价可承受的前提下获得强度尽可能高的一致性保障，也正因如此，事务处理才从一个具体操作上的“编程问题”上升成一个需要全局权衡的“架构问题”。

### 3.1. 本地事务

“本地事务是一种最基础的事务解决方案，只适用于单个服务使用单个数据源的场景。从应用角度看，它是直接依赖于数据源本身提供的事务能力来工作的，在程序代码层面，最多只能对事务接口做一层标准化的包装（如 JDBC 接口），并不能深入参与到事务的运作过程中，事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作

#### 3.1.1. 实现原子性和持久性

实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观存在着“正在写”的中间状态。由于写入中间状态与崩溃都不可能消除，所以如果不做额外保障措施的话，将内存中的数据写入磁盘，并不能保证原子性与持久性。

- 未提交事务，写入后崩溃
    数据库必须要有办法得知崩溃前发生过一次不完整的操作，将已经修改过的数据从磁盘中恢复成没有改过的样子，以保证原子性。
- 已提交事务，写入前崩溃
    程序已经修改完三个数据，但数据库还未将全部三个数据的变动都写入磁盘，若此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次完整的购物操作，将还没来得及写入磁盘的那部分数据重新写入，以保证持久性。

由于写入中间状态与崩溃都是无法避免的，为了保证原子性和持久性，就只能在崩溃后采取恢复的补救措施，这种数据恢复操作被称为“**崩溃恢复**”（Crash Recovery，也有资料称作 Failure Recovery 或 Transaction Recovery）。

为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中的变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即**以仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中**。只有在日志记录全部安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化，这种事务实现方法被称为“提交日志”（Commit Logging）。

> [!info] Shadow Paging
> “通过日志实现事务的原子性和持久性是当今的主流方案，但并不是唯一的选择。除日志外，还有另外一种称为“Shadow Paging”（有中文资料翻译为“影子分页”）的事务实现机制，常用的轻量级数据库 SQLite Version 3 采用的事务机制就是 Shadow Paging。
> 
> Shadow Paging 的大体思路是对数据的变动会写到硬盘的数据中，但不是直接就地修改原先的数据，而是**先复制一份副本，保留原数据，修改副本数据**。在事务处理过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。当事务成功提交，所有数据的修改都成功持久化之后，最后一步是修改数据的引用指针，将引用从原数据改为新复制并修改后的副本，最后的“修改指针”这个操作将被认为是原子操作，现代磁盘的写操作的作用可以认为是保证了在硬件上不会出现“改了半个值”的现象。所以 Shadow Paging 也可以保证原子性和持久性。Shadow Paging 实现事务要比 Commit Logging 更加简单，但涉及隔离性与并发锁时，Shadow Paging 实现的事务并发能力就相对有限，因此在高性能的数据库中应用不多。

Commit Logging 存在一个巨大的先天缺陷：**所有对数据的真实修改都必须发生在事务提交以后，即日志写入了 Commit Record 之后**。在此之前，即使磁盘 I/O 有足够空闲，即使某个事务修改的数据量非常庞大，占用了大量的内存缓冲区，无论何种理由，都决不允许在事务提交之前就修改磁盘上的数据，**这一点是 Commit Logging 成立的前提，却对提升数据库的性能十分不利**。

为此，ARIES 提出了“提前写入日志”（Write-Ahead Logging）的日志改进方案，所谓“提前写入”（Write-Ahead），就是允许在事务提交之前写入变动数据的意思。Write-Ahead Logging 按照事务提交时点，将何时写入变动数据划分为 FORCE 和 STEAL 两类情况。

- FORCE
    当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，因为只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入时立即进行。
- STEAL
    在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。

Write-Ahead Logging 允许 NO-FORCE，也允许 STEAL，它给出的解决办法是**增加了另一种被称为 Undo Log 的日志类型**，当变动数据写入磁盘前，必须先记录 Undo Log，注明修改了哪个位置的数据、从什么值改成什么值等，以便在事务回滚或者崩溃恢复时根据 Undo Log 对提前写入的数据变动进行擦除。Undo Log 现在一般被翻译为“回滚日志”，此前记录的用于崩溃恢复时重演数据变动的日志就相应被命名为 Redo Log，一般翻译为“重做日志”。由于 Undo Log 的加入，Write-Ahead Logging 在崩溃恢复时会经历以下三个阶段。

1. 分析阶段（Analysis）
    该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合，这个集合至少会包括事务表（Transaction Table）和脏页表（Dirty Page Table）两个组成部分。
2. 重做阶段（Redo）
    该阶段依据分析阶段中产生的待恢复的事务集合来重演历史（Repeat History），具体操作是找出所有包含 Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移出待恢复事务集合。
3. 回滚阶段（Undo）
    该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。

![image.png](https://r2.129870.xyz/2024/10/4fea1d3b21376296ed1a90dd98bb9754.png)

#### 3.1.2. 实现隔离性

数据库的隔离型基本都靠加锁来实现。现代数据库基本提供了以下三种锁：

- 写锁
- 读锁
- 范围锁
    范围不能被写入”与“一批数据不能被写入”的差别，即不要把范围锁理解成一组排他锁的集合。加了范围锁后，**不仅不能修改该范围内已有的数据，也不能在该范围内新增或删除任何数据**，后者是一组排他锁的集合无法做到的。

串行化访问提供了最高强度的隔离性，ANSI/ISO SQL-92 中定义的最高等级的隔离级别便是可串行化（Serializable）。可串行化完全符合普通程序员对数据竞争加锁的理解，如果不考虑性能优化的话，对事务所有读、写的数据全都加上读锁、写锁和范围锁即可做到可串行化，“即可”是简化理解，实际还是很复杂的，要分成加锁（Expanding）和解锁（Shrinking）两阶段去处理读锁、写锁与数据间的关系，称为两阶段锁（Two-Phase Lock，2PL）。

除了都以锁来实现外，以上四种隔离级别还有另外一个共同特点，就是幻读、不可重复读、脏读等问题都是由于**一个事务在读数据的过程中，受另外一个写数据的事务影响而破坏了隔离性**。针对这种“一个事务读+另一个事务写”的隔离问题，近年来有一种名为“多版本并发控制”（Multi-Version Concurrency Control，MVCC）的无锁优化方案被主流的商业数据库广泛采用。

MVCC 是一种读取优化策略，它的**“无锁”特指读取时不需要加锁**。MVCC 的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版本与老版本共存，以此达到读取时可以完全不加锁的目的。

MVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，稍微有点讨论余地的是加锁策略是选“乐观加锁”（Optimistic Locking）还是选“悲观加锁”（Pessimistic Locking）。

### 3.2. 全局事务与分布式事务

参见[[分布式/分布式大纲#2. 分布式事务|分布式事务]]

## 4. 透明多级分流系统

在用户使用信息系统的过程中，请求从浏览器出发，在域名服务器的指引下找到系统的入口，经过网关、负载均衡器、缓存、服务集群等一系列设施，最后触及末端存储于数据库服务器中的信息，然后逐级返回到用户的浏览器之中。这其中要经过很多技术部件。作为系统的设计者，我们应该意识到不同的设施、部件在系统中有各自不同的价值。

对系统进行流量规划时，我们应该充分理解这些部件的价值差异，有两条简单、普适的原则能指导我们进行设计。

- 尽可能的减少单点部件
- 奥卡姆剃刀原则，最简单的系统就是最好的系统

### 4.1. 客户端缓存

#### 4.1.1. 强制缓存

HTTP 的强制缓存对一致性问题的处理策略就如它的名字一样，十分直接：假设在某个时点到来以前，譬如收到响应后的 10 分钟内，资源的内容和状态一定不会被改变，因此客户端可以无须经过任何请求，在该时点前一直持有和使用该资源的本地缓存副本。

根据约定，强制缓存在浏览器的地址输入、页面链接跳转、新开窗口、前进和后退中均可生效，但在用户主动刷新页面时应当自动失效。HTTP 协议中设有以下两类 Header 实现强制缓存：

1. Expires

    ```txt
    HTTP/1.1 200 OK
    Expires: Wed, 8 Apr 2020 07:28:00 GMT”
    ```

    Expires 是 HTTP 协议最初版本中提供的缓存机制，设计非常直观易懂，但考虑得并不周全。主要存在以下问题：

    - 受限于客户端的本地时间
    - 无法处理涉及用户身份的私有资源
    - 无法描述"不缓存"的语义

2. Cache-Control

    ```txt
    HTTP/1.1 200 OK
    Cache-Control: max-age=600
    ```

    如果 Cache-Control 和 Expires 同时存在，并且语义存在冲突（譬如 Expires 与 max-age/s-maxage 冲突）的话，规定必须以 Cache-Control 为准。Cache-Control 在客户端的请求 Header 或服务器的响应 Header 中都可以存在，它定义了一系列参数，且允许自行扩展：

    - max-age 和 s-maxage
        max-age 后面跟随一个以秒为单位的数字，表明相对于请求时间（在 Date Header 中会注明请求时间）多少秒以内缓存是有效的。
    - public 和 private
        指明是否涉及用户身份的私有资源，如果是 public，则可以被代理、CDN 等缓存；如果是 private，则只能由用户的客户端进行私有缓存。
    - no-cache
        浏览器和中间代理可以存储该资源，但是在使用缓存资源之前，必须向服务器发送请求进行验证（通常通过 `ETag` 或者 `Last-Modified` 进行验证）。如果服务器认为缓存资源是最新的，可以返回 304 Not Modified 响应，这样客户端就可以继续使用缓存副本而不必下载完整资源。
    - no-store
        既不允许浏览器缓存该资源，也不允许任何中间代理（例如 CDN）缓存该资源。这意味着每次用户请求该资源时，必须从服务器直接获取最新的数据，浏览器和中间代理都不能以任何形式保存这个资源的副本。
    - no-transform
        禁止以任何形式修改资源。譬如，某些 CDN、透明代理支持自动 GZip 压缩图片或文本，以提升网络性能，而 no-transform 禁止了这样的行为，它不允许 Content-Encoding、Content-Range、Content-Type 进行任何形式的修改。

#### 4.1.2. 协商缓存

强制缓存是基于时效性的，但无论是人还是服务器，其实多数情况下并没有什么把握去承诺某项资源多久不会发生变化。另外一种基于变化检测的缓存机制，在一致性上会有比强制缓存更好的表现，但需要一次变化检测的交互开销，性能上就会略差一些，这种基于检测的缓存机制，通常被称为“协商缓存”。

- Last-Modified 和 If-Modified-Since
    根据资源的修改时间来判断是否需要重新获取，如果此时服务端发现资源在该时间后没有被修改过，就返回一个 304/Not Modified 的响应，无须附带消息体，即可达到节省流量的目的。
- ETag 和 If-None-Match
    ETag 是服务端的响应 Header，用于告诉客户端这个资源的唯一标识。HTTP 服务端可以根据自己的意愿来选择如何生成这个标识。ETag 是 HTTP 中一致性最强的缓存机制，譬如，Last-Modified 标注的最后修改只能精确到秒级。

到这里为止，HTTP 的协商缓存机制已经能很好地适用于通过 URL 获取单个资源的场景，为什么要强调单个资源”呢？在 HTTP 协议的设计中，**一个 URL 地址是有可能提供多份不同版本的资源的**，譬如，一段文字的不同语言版本，一个文件的不同编码格式版本，一份数据的不同压缩方式版本，等等。因此针对请求的缓存机制，也必须能够提供对应的支持。为此，HTTP 协议设计了以 Accept*（Accept、Accept-Language、Accept-Charset、Accept-Encoding）开头的一套请求 Header 和对应的以 Content-\*（Content-Language、Content-Type、Content-Encoding）开头的响应 Header，这些 Header 被称为 HTTP 的内容协商机制。与之对应的，对于一个 URL 能够获取多个资源的场景，缓存也同样需要有明确的标识来获知根据什么内容返回给用户正确的资源。此时就要用到 Vary Header，Vary 后面应该跟随一组其他 Header 的名字。

```txt
HTTP/1.1 200 OK
Vary: Accept, User-Agent
```

以上响应的含义是应该根据 MIME 类型和浏览器类型来缓存资源，获取资源时也需要根据请求 Header 中对应的字段来筛选出适合的资源版本。

### 4.2. 域名解析

DNS 域名的流程如下：

1. 检查本地 DNS 缓存
2. 查询本地 DNS 服务器
    本地 DNS 解析服务器可以由用户设置，也可以由 DHCP 分配。
    本地 DNS 服务器的解析流程如下：

    ![image.png](https://r2.129870.xyz/img/2025/10d5e6262232fa8925b9d4593e05081f.png)

    1. 本地 DNS 收到查询请求后，会按照“是否有 www.icyfenix.com.cn 的权威服务器 ”→“是否有 icyfenix.com.cn 的权威服务器”→“是否有 com.cn 的权威服务器”→“是否有 cn 的权威服务器”的顺序，依次查询自己的地址记录，如果都没有查询到，就会一直找到最后点号代表的根域名服务器为止。
       这个步骤里涉及两个重要名词：
       - 权威域名服务器
           负责翻译特定域名的 DNS 服务器，“权威”意味着域名应该翻译出怎样的结果是由这个服务器决定的。
       - 根域名服务器
           固定的、无须查询的顶级域名（Top-Level Domain）服务器，可以默认它们已内置在操作系统代码之中。全世界一共有 13 组根域名服务器（注意并不是 13 台），每一组根域名都通过任播的方式建立了一大群镜像。
3. 本地 DNS 全新的情况下，会一直查到根域名服务器，之后它将会得到“cn 的权威服务器”的地址记录，然后通过“cn 的权威服务器”，得到“com.cn 的权威服务器”的地址记录，以此类推，最后找到能够解释“ www.icyfenix.com.cn ”的权威服务器地址
4. 通过“ www.icyfenix.com.cn 的权威服务器 ”，查询 www.icyfenix.com.cn 的地址记录
   地址记录并不一定就是指 IP 地址，在 RFC 规范中有定义的地址记录类型已经多达数十种，譬如 IPv4 下的 IP 地址为 A 记录，IPv6 下的 AAAA 记录、主机别名 CNAME 记录，等等。

   每种记录类型中还可以包括多条记录，以一个域名下配置多条不同的 A 记录为例，此时权威服务器可以根据自己的策略来进行选择，典型的应用是智能线路：根据访问者所处的不同地区（譬如华北、华南、东北）、不同服务商（譬如电信、联通、移动）等因素来确定返回最合适的 A 记录，将访问者路由到最合适的数据中心，达到智能加速的目的。

DNS 系统多级分流的设计使得 DNS 系统能够经受住全球网络流量不间断的冲击，但在极端情况下，即各级服务器均无缓存时，域名解析可能导致每个域名都必须递归多次才能查询到结果，明显影响传输的响应速度。

而另一种可能更严重的缺陷是 DNS 的分级查询意味着每一级都有可能受到中间人攻击的威胁，产生被劫持的风险。要攻陷位于递归链条顶层的服务器（譬如根域名服务器、cn 权威服务器）和链路是非常困难的，它们都有很专业的安全防护措施。但很多位于递归链底层或者来自本地运营商的本地 DNS 服务器的安全防护则相对松懈，甚至不少地区的运营商自己就会主动劫持，专门返回一个错的 IP，通过在这个 IP 上代理用户请求，给特定类型的资源（主要是 HTML）注入广告，以此牟利。

为此，最近几年出现了另一种新的 DNS 工作模式：HTTPDNS（也称为 DNS over HTTPS，DoH）。它将原本的 DNS 解析服务开放为一个基于 HTTPS 协议的查询服务，替代基于 UDP 传输协议的 DNS 域名解析，通过程序代替操作系统直接从权威 DNS 或者可靠的本地 DNS 获取解析数据，从而绕过传统本地 DNS。

### 4.3. 传输链路

#### 4.3.1. 连接数优化

**HTTP 传输对象的主要特征是数量多、时间短、资源小、切换快**。另一方面，TCP 协议要求必须在三次握手完成之后才能开始数据传输，这是一个可能以高达“百毫秒”为计时尺度的事件；另外，TCP 还有慢启动的特性，使得刚刚建立连接时的传输速度是最低的，后面再逐步加速直至稳定。由于 **TCP 协议本身是面向长时间、大数据传输来设计的，在长时间尺度下，它建立连接的高昂成本才不至于成为瓶颈**，它的稳定性和可靠性的优势才能展现出来。因此，可以说 HTTP over TCP 这种搭配在目标特征上确实是有矛盾的，以至于 **HTTP/1.x 时代，大量短而小的 TCP 连接导致了网络性能的瓶颈**。

连接复用技术，也称为连接 Keep-Alive 机制。持久连接的原理是让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接。典型做法是在客户端维护一个 FIFO 队列，在每次取完数据之后一段时间内先不自动断开连接，以便在获取下一个资源时直接复用，避免创建 TCP 连接的成本。

但是，**连接复用技术依然是不完美的，最明显的副作用是“队首阻塞”（Head-of-Line Blocking）问题**。队首的资源如果发生阻塞的话会影响队列中其它资源的处理速度，即使他们能被很快的计算。服务端不能因为哪个请求先完成就返回哪个，更不可能将所有要返回的资源混杂到一起交叉传输，原因是**只使用一个 TCP 连接来传输多个资源的话，如果顺序乱了，客户端就很难区分哪个数据包归属哪个资源了**。

第二代 HTTP 协议解决了队首阻塞问题，在 HTTP/2 中，**帧（Frame）才是最小粒度的信息单位**，它可以用来描述各种数据，譬如请求的 Headers、Body，或者用来做控制标识，譬如打开流、关闭流。这里说的流（Stream）是一个逻辑上的数据通道概念，每个帧都附带一个流 ID 以标识这个帧属于哪个流。这样，在同一个 TCP 连接中传输的多个数据帧就可以根据流 ID 轻易区分开来，在客户端毫不费力地将不同流中的数据重组出不同 HTTP 请求和响应报文来。这项设计是 HTTP/2 的最重要的技术特征一，被称为 HTTP/2 多路复用（HTTP/2 Multiplexing）技术，

![image.png](https://r2.129870.xyz/img/2024/2b28ef785376f1694fb66f7a0ebe53b3.png)

有了多路复用的支持，HTTP/2 就可以对每个域名只维持一个 TCP 连接（One Connection Per Origin）并以任意顺序传输任意数量的资源了，这样既减轻了服务器的连接压力，也不需要开发者去考虑域名分片这种事情来突破浏览器对每个域名最多 6 个的连接数限制。

#### 4.3.2. 传输优化

HTTP 除了静态压缩外还存在动态压缩。静态压缩指服务器预先将压缩成不同版本，而现代服务器大多采用的动态压缩（On-The-Fly Compression），在请求阶段才将资源压缩成客户端需求的格式。

采用动态压缩后服务器再也没有办法给出 Content-Length 这个响应 Header 了，因为输出 Header 时服务器还不知道压缩后资源的确切大小。与此同时带来的一个问题是连接复用的情况下无法判断资源请求的结束时机了。

持久连接机制不再依靠 TCP 连接是否关闭来判断资源请求是否结束，而是需要其它机制来判断。这个机制最初（在 HTTP/1.0 时）就只有 Content-Length，即依靠请求 Header 中明确给出资源的长度判断，传输到达该长度即宣告一个资源的传输已结束。由于启用即时压缩后就无法给出 Content-Length 了，不仅仅在于即时压缩这一种场景，譬如对于动态内容（Ajax、PHP、JSP 等输出），服务器也同样无法事先得知 Content-Length。

HTTP/1.1 版本中增加了另一种“分块传输编码”（Chunked Transfer Encoding）的资源结束判断机制，彻底解决了 Content-Length 与持久连接的冲突问题。分块编码的原理相当简单：在响应 Header 中加入“Transfer-Encoding:chunked”之后，就代表这个响应报文将采用分块编码。此时，报文中的 Body 需要改为用一系列“分块”来传输。**每个分块包含十六进制的长度值和对应每个分块包含十六进制的长度值和对应长度的数据内容**，长度值独占一行，数据从下一行开始，最后以一个长度值为 0 的分块来表示资源结束

#### 4.3.3. 快速 UDP 连接

HTTP 是应用层协议而不是传输层协议，它的设计原本不应该过多地考虑底层的传输细节，从职责上讲，持久连接、多路复用、分块编码这些能力，已经或多或少超过了应用层的范畴。要从根本上改进 HTTP，必须直接替换掉 HTTP over TCP 的根基，即 TCP 传输协议，这便是最新一代 HTTP/3 协议的设计重点。

2013 年，Google 在它的服务器（如 Google.com、YouTube.com 等）及 Chrome 浏览器上同时启用了名为“快速 UDP 网络连接”（Quick UDP Internet Connection，QUIC）的全新传输协议。

QUIC 会以 UDP 协议为基础，而 UDP 协议没有丢包自动重传的特性，因此 **QUIC 的可靠传输能力并不是由底层协议提供，而是完全由自己实现**。由 QUIC 自己实现的好处是能对每个流做单独的控制，如果在一个流中发生错误，协议栈仍然可以独立地继续为其他流提供服务。这对提高易出错链路的性能非常有用，因为在大多数情况下，TCP 协议接到数据包丢失或损坏通知之前，可能已经收到了大量的正确数据，但是在纠正错误之前，其他的正常请求都会等待甚至被重发，因此**在连接复用的情况下传输大文件可能反而比单独连接处理的更慢**。

QUIC 的另一个设计目标是面向移动设备的专门支持，由于以前 TCP、UDP 传输协议在设计时根本不可能设想到今天移动设备盛行的场景，因此肯定不会有任何专门的支持。QUIC 在移动设备上的优势体现在网络切换时的响应速度上，譬如当移动设备在不同 Wi-Fi 热点之间切换，或者从 Wi-Fi 切换到移动网络时，如果使用 TCP 协议，现存的所有连接都必定会超时、中断，然后根据需要重新创建。这个过程会带来很高的延迟，因为超时和重新握手都需要大量时间。为此，**QUIC 提出了连接标识符的概念，该标识符可以唯一地标识客户端与服务器之间的连接，而无须依靠 IP 地址**。这样，切换网络后，只需向服务端发送一个包含此标识符的数据包即可重用既有的连接，因为即使用户的 IP 地址发生变化，原始连接的连接标识符依然是有效的。

### 4.4. 内容分发网络

内容分发网络（Content Distribution Network，CDN，也有写作 Content Delivery Network）常用于资源的加速访问。在 CDN 存在的情况下，DNS 解析过程如下：

![image.png](https://r2.129870.xyz/img/2025/cebbb8fc1de717c8215635e49326a5b1.png)

CDN 有两种主流分发方式：

- 主动分发（Push）
    分发由源站主动发起，将内容从源站或者其他资源库推送到用户边缘的各个 CDN 缓存节点上。
- 被动回源（Pull）
    被动回源由用户访问所触发全自动、双向透明的资源缓存过程。当某个资源首次被用户请求的时候，CDN 缓存节点发现自己没有该资源，就会实时从源站中获取。

最常见的做法是**超时被动失效与手工主动失效相结合**，超时失效是指给予缓存资源一定的生存期，超过了生存期就在下次请求时重新被动回源一次。而手工失效是指 CDN 服务商一般会提供给程序调用来失效缓存的接口，在网站更新时，由持续集成的流水线自动调用该接口来实现缓存更新。

CDN 的主流应用：

- 加速静态资源
- 安全防御
    CDN 在广义上可以视作网站的堡垒机，源站只对 CDN 提供服务
- 协议升级
    不少 CDN 提供商都同时对接（代售 CA 的）SSL 证书服务，例如将 http 升级为 https，http/1.x 升级为 http/2 或 http/3 等。
- 状态缓存
    例如缓存资源等 301 重定向状态。
- 修改资源
    例如可以对源站未压缩的资源自动压缩并修改 Content-Encoding、启用客户端缓存、修改 CORS 相关 header 等。
- 访问控制
    提供黑白名单等控制。
- 注入功能
    在不修改源站代码的情况下为源站注入功能。

### 4.5. 负载均衡

从形式上来说都可以分为两种：四层负载均衡和七层负载均衡，四层”、七层”，指的是经典的 OSI 七层模型中第四层传输层和第七层应用层。

“四层”的意思是这些工作模式的共同特点是维持着同一个 TCP 连接，而不是说它只工作在第四层。事实上，这些模式主要都是工作在二层（数据链路层，改写 MAC 地址）和三层（网络层，改写 IP 地址）上，单纯只处理第四层（传输层，可以改写 TCP、UDP 等协议的内容和端口）的数据无法做到负载均衡的转发，因为 OSI 的下三层是媒体层（Media Layers），上四层是主机层（Host Layers），既然流量都已经到达目标主机上了，也就谈不上什么流量转发，最多只能做代理了。

#### 4.5.1. 数据链路层负载均衡

数据链路层负载均衡所做的工作，是修改请求的数据帧中的 MAC 目标地址，让用户原本是发送给负载均衡器的请求的数据帧，被二层交换机根据新的 MAC 目标地址转发到服务器集群中对应的服务器（后文称为“真实服务器”，Real Server）的网卡上，这样真实服务器就获得了一个原本目标并不是发送给它的数据帧。

由于二层负载均衡器在转发请求过程中**只修改了帧的 MAC 目标地址**，不涉及更上层协议（没有修改 Payload 的数据），所以在更上层（第三层）看来，所有数据都是未曾被改变过的。由于第三层的数据包，即 IP 数据包中包含了源（客户端）和目标（均衡器）的 IP 地址，只有真实服务器保证自己的 IP 地址与数据包中的目标 IP 地址一致，这个数据包才能被正确处理。因此，使用这种负载均衡模式时，**需要把真实物理服务器集群所有机器的虚拟 IP 地址**（Virtual IP Address，VIP。与之对应的是物理 IP，真实存在的硬件网卡（如 `eth0`, `ens33`），用于连接物理网络（网线/WiFi））配置成与负载均衡器的虚拟 IP 一样，这样经均衡器转发后的数据包就能在真实服务器中顺利地使用。也正是因为实际处理请求的真实物理服务器 IP 和数据请求中的目的 IP 是一致的，所以响应结果就不再需要通过负载均衡服务器进行地址交换，可将响应结果的数据包直接从真实服务器返回给用户的客户端，避免负载均衡器网卡带宽成为瓶颈，因此数据链路层的负载均衡效率是相当高的。

> [!info] 负载均衡器的配置
> 为了能在同一子网内配置多个相同的 VIP，必须对负载均衡服务器和真实服务器做一些特殊配置：
> -  ARP 抑制：禁止真实服务器响应 VIP 的 ARP 请求
> -  VIP 绑定在 Loopback 接口（Non-ARP）
> 
> 工作原理：
> 1. **ARP 层面**：只有负载均衡器响应对 VIP 的 ARP 请求，所以客户端只知道负载均衡器的 MAC 地址
> 2. **转发过程**：负载均衡器修改数据帧的目标 MAC 地址为真实服务器的 MAC，但保持 IP 层不变
> 3. **服务器处理**：真实服务器收到数据包后，发现目标 IP 是 VIP，而自己确实在回环接口上配置了这个 IP，所以能正常处理
> 4. **直接返回**：响应数据包的源 IP 就是 VIP，可以直接返回给客户端，不需要经过负载均衡器

![image.png](https://r2.129870.xyz/img/2025/8dde65d798de2864e9a13b488f140262.png)

上述只有请求经过负载均衡器，而服务的响应无须从负载均衡器原路返回的工作模式，整个请求、转发、响应的链路形成一个“三角关系”，所以这种负载均衡模式也常被很形象地称为“三角传输模式”（Direct Server Return，DSR），也有叫“单臂模式”（Single Legged Mode）或者“直接路由”（Direct Routing）。

二层负载均衡器直接改写目标 MAC 地址的工作原理决定了它与真实的服务器的通信必须是二层可达的，通俗地说就是**必须位于同一个子网当中**，无法跨 VLAN。优势（效率高）和劣势（不能跨子网）共同决定了数据链路层负载均衡最适合用来做数据中心的第一级均衡设备，用来连接其他的下级负载均衡器。

#### 4.5.2. 网络层负载均衡

网络层负载均衡通过改变数据包中的源 IP/目的 IP 地址来实现数据包的转发，有两种方式：

1. IP 隧道
    保持原来的数据包不变，新创建一个数据包，把原来数据包的 Headers 和 Payload 整体作为另一个新的数据包的 Payload，在这个新数据包的 Headers 中写入真实服务器的 IP 作为目标地址，然后把它发送出去。

    经过三层交换机的转发，真实服务器收到数据包后，必须在接收入口处设计一个针对性的拆包机制，把由负载均衡器自动添加的那层 Headers 扔掉，还原出原来的数据包来进行使用。这样，真实服务器就同样拿到了一个原本不是发给它（目标 IP 不是它）的数据包，达到了流量转发的目的。

    由于并没有修改原有数据包中的任何信息，所以 IP 隧道的转发模式仍然具备三角传输的特性，即负载均衡器转发来的请求，可以由真实服务器去直接应答，无须在经过均衡器原路返回。

    该策略有两个限制：

    1. 服务器支持 IP 隧道协议
        实际上几乎现在所有的 linux 服务器都支持 ip 隧道协议。
    2. 需要配置相同的 VIP
        这个 VIP 的配置需要网络管理员手动介入。

    ![image.png](https://r2.129870.xyz/img/2025/f1c8df820f429f2c6ae988bde0419593.png)

2. NAT 模式：改变目标数据包
    直接把数据包 Headers 中的目标地址改掉，修改后原本由用户发给均衡器的数据包，也会被三层交换机转发送到真实服务器的网卡上。同时只能让应答流量继续回到负载均衡，由负载均衡把应答包的源 IP 改回自己的 IP，再发给客户端，这样才能保证客户端与真实服务器之间的正常通信。

    ![image.png](https://r2.129870.xyz/img/2025/9611bb5f6db2cdd430e745a9546a432c.png)

#### 4.5.3. 应用层负载均衡

四层负载均衡工作模式都属于转发，即直接将承载着 TCP 报文的底层数据格式（IP 数据包或以太网帧）转发到真实服务器上，此时客户端到响应请求的真实服务器维持着同一条 TCP 通道。但工作在四层之后的负载均衡模式就无法再进行转发了，只能进行代理，此时真实服务器、负载均衡器、客户端三者之间由两条独立的 TCP 通道来维持通信。

![image.png](https://r2.129870.xyz/img/2025/94cf80f7e1c1291095aef08813a44282.png)

七层负载均衡在性能上不如四层负载均衡，它比四层均衡器至少多一轮 TCP 握手，有着跟 NAT 转发模式一样的带宽问题，而且通常要耗费更多的 CPU。七层均衡器的作用是来源于它工作在应用层，可以感知应用层通信的具体内容，往往能够做出更明智的决策。

七层负载均衡可以实现但不包括以下功能：

- CDN 可以做的缓存方面的工作
- 更智能化的路由：根据 URL 分发、根据用户身份分发、根据 session 分发等
- 抵御安全攻击
- 链路治理策略：降级、熔断等

#### 4.5.4. 均衡策略与实现

- 轮循
- 加权轮循
- 随机轮循
- 一致性哈希
    根据请求中某一些数据（可以是 MAC、IP 地址，也可以是更上层协议中的某些参数信息）作为特征值来计算需要落在的节点上。
- 响应速度均衡
- 最少连接数均衡

从实现角度来看，负载均衡器的实现分为“软件均衡器”和“硬件均衡器”两类。在软件均衡器方面，又分为直接建设在操作系统内核的均衡器和应用程序形式的均衡器两种。前者的代表是 LVS（Linux Virtual Server），后者的代表有 Nginx、HAProxy、KeepAlived 等，前者性能会更好，因为无须在内核空间和应用空间中来回复制数据包；而后者的优势是选择广泛，使用方便，功能不受限于内核版本。

在硬件均衡器方面，往往会直接采用应用专用集成电路（Application Specific Integrated Circuit，ASIC）来实现，有专用处理芯片的支持，避免操作系统层面的损耗，得以达到最高的性能。这类的代表就是著名的 F5 和 A10 公司的负载均衡产品。

### 4.6. 服务端缓存

设计或者选择缓存至少会考虑以下四个维度的属性：

- 吞吐量
    缓存的吞吐量使用 OPS 值（每秒操作数，Operations per Second，ops/s）来衡量，反映了对缓存进行并发读、写操作的效率，即缓存本身的工作效率高低。

    吞吐量受多方面因素的共同影响，譬如，怎样设计数据结构以尽可能避免数据竞争，存在竞争风险时怎样处理同步（主要有使用锁实现的悲观同步和使用 CAS 实现的乐观同步）、如何避免伪共享现象（False Sharing，这也算是典型缓存提升开发复杂度的例子）发生，等等。

    缓存中最主要的数据竞争源于读取数据的同时，也会伴随着对数据状态的写入操作，写入数据的同时，也会伴随着数据状态的读取操作。

    对以上伴随读写操作而来的状态维护，有两种可选择的处理思路，一种是以 Guava Cache 为代表的同步处理机制，即在访问数据时一并完成缓存淘汰、统计、失效等状态变更操作，通过分段加锁等优化手段来尽量减少竞争。另一种是以 Caffeine 为代表的**异步日志提交机制**，这种机制参考了经典的数据库设计理论，将对数据的读、写过程看作是日志（即对数据的操作指令）的提交过程

- 命中率与淘汰策略
    基础的淘汰策略有 FIFO（First In First Out）、LRU（Least Recent Used）、LFU（Least Frequently Used）。

    近年来出现一些性能更好但也更复杂的改进算法，一些改进思路如下：

    - Sketch 统计：以少量样本数据评估全体数据特征
    - 热度衰减：每隔一段时间递减访问计数器
    - 多个淘汰策略合并使用：例如分块缓存，局部使用 LRU，整体使用 LFU 方案
- 扩展功能
    最大容量、失效时间、失效事件、命中率统计、持久化、统计信息，等等。
- 分布式支持
    集中式缓存是目前分布式缓存的主流形式，集中式缓存的读、写都需要网络访问，其好处是不会随着集群节点数量的增加而产生额外的负担，其坏处自然是读、写都不再可能达到进程内缓存那样的高性能。

基于进程缓存和分布式缓存构建的多级缓存：

![image.png](https://r2.129870.xyz/img/2025/1e42fad09c5ac002ce83dbc6c7d02323.png)

## 5. 架构安全性

- **认证（Authentication）**：系统如何正确分辨出操作用户的真实身份？
- **授权（ Authorization）**：系统如何控制一个用户该看到哪些数据、能操作哪些功能？
- **凭证（Credential）**：系统如何保证它与用户之间的承诺是双方当时真实意图的体现，是准确、完整且不可抵赖的？
- **保密（Confidentiality）**：系统如何保证敏感数据无法被包括系统管理员在内的内外部人员所窃取、滥用？
- **传输（Transport Security）**：系统如何保证通过网络传输的信息无法被第三方窃听、篡改和冒充？
- **验证（Verification）**：系统如何确保提交到每项服务中的数据是合乎规则的，不会对系统稳定性、数据一致性、正确性产生风险？

### 5.1. 认证

> [!abstract] 认证
> 系统如何正确的分辨出操作用户的真实身份？

- 通信信道上的认证：你和我建立通信连接之前，要先证明你是谁。在网络传输（Network）场景中的典型是基于 SSL/TLS 传输安全层的认证。
- 通信协议上的认证：你请求获取我的资源之前，要先证明你是谁。在互联网（Internet）场景中的典型是基于 HTTP 协议的认证。
- 通信内容上的认证：你使用我提供的服务之前，要先证明你是谁。在万维网（World Wide Web）场景中的典型是基于 Web 内容的认证。

#### 5.1.1. HTTP 认证

HTTP 协议的通用认证框架，要求所有支持 HTTP 协议的服务器，在未授权的用户意图访问服务端保护区域的资源时，应返回 401 Unauthorized 的状态码，同时应在响应报文头里附带以下两个分别代表网页认证和代理认证的 Header 之一，告知客户端应该采取何种方式产生能代表访问者身份的凭证信息：

```txt
WWW-Authenticate: <认证方案> realm=<保护区域的描述信息>
Proxy-Authenticate: <认证方案> realm=<保护区域的描述信息>

示例：

HTTP/1.1 401 Unauthorized
Date: Mon, 24 Feb 2020 16:50:53 GMT
WWW-Authenticate: Basic realm="example from icyfenix.cn
```

接收到该响应后，客户端必须遵循服务端指定的认证方案，在请求资源的报文头中加入身份凭证信息，由服务端核实通过后才会允许该请求正常返回，否则将返回 403 Forbidden 错误。请求头报文应包含以下 Header 项之一：

```
Authorization: <认证方案> <凭证内容>
Proxy-Authorization: <认证方案> <凭证内容>

示例：

GET /admin HTTP/1.1
Authorization: Basic aWN5ZmVuaXg6MTIzNDU2
```

#### 5.1.2. Web 认证

WebAuth 认证示例：

![image.png](https://r2.129870.xyz/img/2025/c3a00cf7d192e999a84bf8b9859542cd.png)

WebAuthn 规范涵盖了“注册”与“认证”两大流程，先来介绍注册流程，它大致可以分为以下步骤：

1. 用户进入系统的注册页面，这个页面的格式、内容和用户注册时需要填写的信息均不包含在 WebAuthn 标准的定义范围内
2. 当用户填写完信息，点击“提交注册信息”的按钮后，服务端先暂存用户提交的数据，生成一个随机字符串（规范中称为 Challenge）和用户的 UserID（在规范中称作凭证 ID），返回给客户端
3. 客户端的 WebAuthn API 接收到 Challenge 和 UserID，把这些信息发送给验证器（Authenticator），验证器可理解为用户设备上 TouchID、FaceID、实体密钥等认证设备的统一接口
4. 验证器提示用户进行验证，如果支持多种认证设备，还会提示用户选择一个想要使用的设备。验证的结果是生成一个密钥对（公钥和私钥），由验证器存储私钥、用户信息以及当前的域名。然后使用私钥对 Challenge 进行签名，并将签名结果、UserID 和公钥一起返回客户端
5. 浏览器将验证器返回的结果转发给服务器
6. 服务器核验信息，检查 UserID 与之前发送的是否一致，并用公钥解密后得到的结果与之前发送的 Challenge 相比较，一致即表明注册通过，由服务端存储该 UserID 对应的公钥

登录流程与注册流程类似，如果你理解了注册流程，就很容易理解登录流程了。登录流程大致可以分为以下步骤：

1. 用户访问登录页面，填入用户名后即可点击登录按钮
2. 服务器返回随机字符串 Challenge、用户 UserID
3. 浏览器将 Challenge 和 UserID 转发给验证器
4. 验证器提示用户进行认证操作。由于在注册阶段验证器已经存储了该域名的私钥和用户信息，所以如果域名和用户都相同的话，就不需要生成密钥对了，直接以存储的私钥加密 Challenge，然后返回给浏览器
5. 服务端接收到浏览器转发来的被私钥加密的 Challenge，以此前注册时存储的公钥进行解密，如果解密成功则宣告登录成功

### 5.2. 授权

授权主要涉及两个问题：

- 确保授权的过程可靠
    对于单一系统来说，授权的过程是比较容易做到可控的。对于多方系统，如何既让第三方系统能够访问到所需的资源，又能保证其不泄露用户的敏感数据呢？常用的多方授权协议主要有 OAuth2 和 SAML 2.0。
- 确保授权的结果可控
    授权的结果用于对程序功能或者资源的访问控制（Access Control），成理论体系的权限控制模型有很多，譬如自主访问控制（Discretionary Access Control，DAC）、强制访问控制（Mandatory Access Control，MAC）、基于属性的访问控制（Attribute-Based Access Control，ABAC），还有最为常用的基于角色的访问控制（Role-Based Access Control，RBAC）。

    ![image.png](https://r2.129870.xyz/img/2025/2d88c4e7d88cbdc4b72f151ab2026b94.png)

#### 5.2.1. Oauth2

OAuth2 是面向于解决**第三方应用（Third-Party Application）的认证授权协议**。如何让第三方系统得到授权呢？简单的授权账号密码存在以下问题：

- 密码泄漏
    如果第三方数据发生泄漏将会发生同步泄漏的风险。
- 访问范围
    无法精准的控制访问权限。
- 授权回收
    只有修改密码才能回收权限，而该密码可能被同时授权到多个不同的第三方平台。

Oauth2 以**令牌（Token）代替用户密码作为授权的凭证**。有了令牌之后，哪怕令牌被泄漏，也不会导致密码的泄漏；令牌上可以设定访问资源的范围以及时效性；每个应用都持有独立的令牌，哪个失效都不会波及其他。

![image.png](https://r2.129870.xyz/img/2025/6fb25c779eec31fe5ea03bae36aa0529.png)

##### 5.2.1.1. 授权码模式

授权码模式是最为严格的授权模式。

![image.png](https://r2.129870.xyz/img/2025/c8a6feb73d180cda8e186282ae1a5a2a.png)

开始进行授权过程以前，第三方应用先要到授权服务器上进行注册：**向认证服务器提供一个域名地址，然后从授权服务器中获取 ClientID 和 ClientSecret**，以便能够顺利完成如下授权过程：

1. 第三方应用将资源所有者（用户）导向授权服务器的授权页面，并向授权服务器提供 ClientID 及用户同意授权后的回调 URI，这是一次客户端页面转向
2. 授权服务器根据 ClientID 确认第三方应用的身份，用户在授权服务器中决定是否同意向该身份的应用进行授权，用户认证的过程未定义在此步骤中，在此之前应该已经完成
3. 如果用户同意授权，授权服务器将转向第三方应用在第 1 步调用中提供的回调 URI，并附带上一个授权码和获取令牌的地址作为参数，这是第二次客户端页面转向
4. 第三方应用通过回调地址收到授权码，然后将授权码与自己的 ClientSecret 一起作为参数，通过服务器向授权服务器提供的获取令牌的服务地址发起请求，换取令牌。该服务器的地址应与注册时提供的域名处于同一个域中
5. 授权服务器核对授权码和 ClientSecret，确认无误后，向第三方应用授予令牌。令牌可以是一个或者两个，其中必定要有的是访问令牌（Access Token），可选的是刷新令牌（Refresh Token）。访问令牌用于到资源服务器获取资源，有效期较短，刷新令牌用于在访问令牌失效后重新获取，有效期较长
6. 资源服务器根据访问令牌所允许的权限，向第三方应用提供资源

授权码模式分析：

- 为什么要先发放授权码，再用授权码换令牌？
    这是因为客户端转向（通常就是一次 HTTP 302 重定向）**对于用户是可见的**，换而言之，授权码可能会暴露给用户以及用户机器上的其他程序，但由于用户并没有 ClientSecret，光有授权码也是无法换取到令牌的，所以避免了令牌在传输转向过程中被泄漏的风险。
- 为什么要设计一个时限较长的刷新令牌和时限较短的访问令牌？不能直接把访问令牌的时间调长吗？
    这是为了缓解 OAuth2 在实际应用中的一个主要缺陷，**通常访问令牌一旦发放，除非超过了令牌中的有效期，否则很难（需要付出较大代价）有其他方式让它失效**，所以访问令牌的时效性一般设计的比较短，譬如几个小时，如果还需要继续用，那就定期用刷新令牌去更新，授权服务器就可以在更新过程中决定是否还要继续给予授权。

尽管授权码模式是严谨的，但是它并不够好用，这不仅仅体现在它那繁复的调用过程上，还体现在它对第三方应用提出了一个貌似不难的要求：**第三方应用必须有应用服务器**，因为第 4 步要发起服务端转向，而且要求服务端的地址必须与注册时提供的地址在同一个域内。

##### 5.2.1.2. 隐式授权模式

隐式授权省略掉了通过授权码换取令牌的步骤，整个授权过程都不需要服务端支持。代价是在隐式授权中，**授权服务器不会再去验证第三方应用的身份**，因为已经没有应用服务器了，ClientSecret 没有人保管，就没有存在的意义了。但其实还是会限制第三方应用的回调 URI 地址必须与注册时提供的域名一致，尽管有可能被 DNS 污染之类的攻击所攻破，但仍算是尽可能努力一下。同样的原因，也不能避免令牌暴露给资源所有者，不能避免用户机器上可能意图不轨的其他程序、HTTP 的中间人攻击等风险了。

![image.png](https://r2.129870.xyz/img/2025/a76523979dce2abeaaafe13124c1ca40.png)

##### 5.2.1.3. 密码模式

密码模式原本的设计意图是仅限于用户对第三方应用是高度可信任的场景中使用，因为用户需要把密码明文提供给第三方应用，第三方以此向授权服务器获取令牌。

![image.png](https://r2.129870.xyz/img/2025/1bb77d3d5273d86e513d737aafddb373.png)

##### 5.2.1.4. 客户端模式

客户端模式是指第三方应用以自己的名义，向授权服务器申请资源许可。

![image.png](https://r2.129870.xyz/img/2025/cd80b2cb58c7485facc8a2433d42a890.png)

与之类似的还有一种设备码模式：

![image.png](https://r2.129870.xyz/img/2025/772d9a9dffbeb02b1c49c5586cd1e677.png)

进行验证时，设备需要从授权服务器获取一个 URI 地址和一个用户码，然后需要用户手动或设备自动地到验证 URI 中输入用户码。在这个过程中，设备会一直循环，尝试去获取令牌，直到拿到令牌或者用户码过期为止。

### 5.3. 凭证

> [!abstract] 凭证
> 系统如何保证它与用户之间的承诺是**双方当时真实意图的体现，是准确、完整且不可抵赖的**？

凭证存储方式：

- 存储在服务端的有状态的 cookie-session 方式
    状态信息存储在服务端，只要依靠客户端的同源策略和 HTTPS 的传输层安全，保证 Cookie 中的键值不被窃取而出现被冒认身份的情况，就能完全规避掉上下文信息在传输过程中被泄漏和篡改的风险。Cookie-Session 方案的另一大优点是**服务端有主动的状态管理能力**，可根据自己的意愿随时修改、清除任意上下文信息，譬如很轻易就能实现强制某用户下线的这样功能。

    在单节点的服务环境中 cookie-session 方案是合适的，但是在分布式环境中多节点数据不共享的情况下，该方案受到 CAP 的限制。

- 存储在客户端的无状态的 JWT 方式
    JWT 方案：当服务器存在多个客户端只有一个时，把状态信息存储在客户端，每次随着请求发回服务器。这样做的缺点是无法携带大量信息，而且有泄漏和篡改的安全风险。信息量受限的问题并没有太好的解决办法，但是要**确保信息不被中间人篡改则还是可以实现的**。

    ![image.png](https://r2.129870.xyz/img/2025/5fcabe38c0727657d68f8cd66541b7ef.png)

    JWT 只解决防篡改的问题，并不解决防泄漏的问题，因此令牌默认是不加密的。JWT 令牌是以 JSON 结构（毕竟名字就叫 JSON Web Token）存储的，结构总体上可划分为三个部分，每个部分间用点号.分隔开：

    - 令牌头（header）：描述了令牌的类型以及签名的算法
    - 负载（payload）：真正需要向服务端传递的消息
    - 签名（Signature）：使用在对象头中公开的特定签名算法，通过特定的密钥（Secret，由服务器进行保密，不能公开）对前面两部分内容进行加密计算
        签名的意义在于确保负载中的信息是可信的、没有被篡改的，也没有在传输过程中丢失任何信息。

    JWT 不需要任何一个服务节点保留任何一点状态信息，就能够保障认证服务与用户之间的承诺是双方当时真实意图的体现，是准确、完整、不可篡改、且不可抵赖的。同时，由于 JWT 本身可以携带少量信息，这十分有利于 RESTful API 的设计，能够较容易地做成无状态服务。

    JWT 存在以下缺点：

    - 令牌难以主动实效
        可以使用黑名单的机制来实现额外的逻辑。
    - 相对更容易遭到重放攻击
    - 只能携带有限的数据
        HTTP 协议并没有强制约束 Header 的最大长度，但是，各种服务器、浏览器都会有自己的约束，譬如 Tomcat 就要求 Header 最大不超过 8KB，而在 Nginx 中则默认为 4KB。
    - 必须考虑令牌在客户端如何存储
    - 无状态也限制了可用性
        例如统计在线用户，在无状态的情况下是难以实现的。

### 5.4. 保密

> [!abstract] 保密
保密系统如何保证敏感数据无法被包括系统管理员在内的内外部人员所窃取、滥用？

保密的强度：

- 以摘要代替明文
- 先加盐值再做哈希应对弱密码
- 将盐值变为动态值能有效防止冒认
- 给服务加入动态令牌
    在网关或其他流量公共位置建立校验逻辑，服务端愿意付出在集群中分发令牌信息等代价的前提下，可以做到防止重放攻击，但是依然不能抵御传输过程中被嗅探而泄漏信息的问题。
- 启用 HTTPS 防御链路上的恶意嗅探，也能在通信层面解决了重放攻击的问题
    但是依然有因客户端被攻破产生伪造根证书风险、有因服务端被攻破产生的证书泄漏而被中间人冒认的风险、有因 CRL 更新不及时或者 OCSP Soft-fail 产生吊销证书被冒用的风险、有因 TLS 的版本过低或密码学套件选用不当产生加密强度不足的风险。
- 更进一步的验证
    为了抵御上述风险，保密强度还要进一步提升，譬如银行会使用独立于客户端的存储证书的物理设备（俗称的 U 盾）来避免根证书被客户端中的恶意程序窃取伪造；大型网站涉及到账号、金钱等操作时，会使用双重验证开辟一条独立于网络的信息通道（如手机验证码、电子邮件）来显著提高冒认的难度；甚至一些关键企业（如国家电网）或机构（如军事机构）会专门建设遍布全国各地的与公网物理隔离的专用内部网络来保障通信安全。

为了保证为了保证信息不被黑客窃取而做客户端加密没有太多意义，但是**为了保证密码不在服务端被滥用**，在客户端就开始加密是很有意义的。真正防御性的密码加密存储确实应该在服务端中进行，但这是为了**防御服务端被攻破而批量泄漏密码的风险，并不是为了增加传输过程的安全**。

一种可用的密码存储和验证过程：

1. 客户端注册输入明文密码
2. 客户端对用户密码进行简单哈希摘要

    ```txt
    client_hash = MD5(password) // e10adc3949ba59abbe56e057f20f883e
    ```

3. 客户端加盐
    为了防御彩虹表攻击应加盐处理，客户端加盐只取固定的字符串即可，如实在不安心，最多用伪动态的盐值（“伪动态”是指服务端不需要额外通信可以得到的信息，譬如由日期或用户名等自然变化的内容，加上固定字符串构成）。

    ```txt
    client_hash = MD5(MD5(password) + salt)  // SALT = $2a$10$o5L.dWYEjZjaejOmN3x4Qu
    ```

4. 客户端使用慢哈希函数
    客户端使用固定盐值的情况下容易使用彩虹表的方式暴力破解，为了应对这种暴力破解，并不提倡在盐值上做动态化，更理想的方式是引入慢哈希函数来解决。**通过增大密码被破解的成本，而不是设计一种完全不会被破解的加密体系**。

    慢哈希函数是指这个函数执行时间是可以调节的哈希函数，通常是以控制调用次数来实现的。BCrypt 算法就是一种典型的慢哈希函数，它做哈希计算时接受盐值 Salt 和执行成本 Cost 两个参数。BCrypt 的执行时间大概是 0.1 秒完成一次哈希计算的话，按照 1 秒生成 10 个哈希值的速度，算完所有的 10 位大小写字母和数字组成的弱密码大概需要 P(62,10)/(3600×24×365)/0.1=1,237,204,169 年时间。

3. 防止脱库使用服务端动态盐值
    为每一个密码（指客户端传来的哈希值）产生一个随机的盐值。建议采用“密码学安全伪随机数生成器”（Cryptographically Secure Pseudo-Random Number Generator，CSPRNG）来生成一个长度与哈希值长度相等的随机字符串。

    ```java
    SecureRandom random = new SecureRandom();
    byte server_salt[] = new byte[36];
    random.nextBytes(server_salt);   // tq2pdxrblkbgp8vt8kbdpmzdh1w8bex
    ```

    > [!info] 脱库与彩虹表
    > 这里利用动态盐值的作用在于**即使数据库被脱库了**，攻击者也无法使用预先计算好的彩虹表来**批量**破解密码。
    > 彩虹表的核心是**一张表破解多个使用相同哈希算法和相同盐值的密码**。如果每个用户的密码都使用一个**唯一、随机、足够长**的盐值，那么攻击者即使拿到整个数据库也无法使用**同一张预先计算好的彩虹表**来批量破解所有用户的密码，攻击者必须为**每一个用户**（每一个独特的 `server_salt`）单独计算一张新的彩虹表。计算一张针对特定盐值的彩虹表成本极高（时间、计算资源）。
4. 服务端利用动态盐值再哈希
    将动态盐值混入客户端传来的哈希值再做一次哈希，产生出最终的密文，并和上一步随机生成的盐值一起写入到同一条数据库记录中。

    ```java
    server_hash = SHA256(client_hash + server_salt);  // 55b4b5815c216cf80599990e781cd8974a1e384d49fbde7776d096e1dd436f67
    DB.save(server_hash, server_salt);
    ```

登陆验证过程：

1. 客户端输入明文密码并经过与注册相同的加密过程
2. 服务端取出动态盐值再哈希
    服务端，接受到客户端传输上来的哈希值，从数据库中取出登录用户对应的密文和盐值，采用相同的哈希算法，对客户端传来的哈希值、服务端存储的盐值计算摘要结果。

    ```txt
    result = SHA256(authentication_hash + server_salt);  // 55b4b5815c216cf80599990e781cd8974a1e384d49fbde7776d096e1dd436f67
    ```

3. 与数据库存储的哈希值进行对比
    比较上一步的结果和数据库储存的哈希值是否相同，如果相同那么密码正确，反之密码错误。

    ```txt
    authentication = compare(result, server_hash) // yes
    ```

### 5.5. 传输

> [!abstract] 传输
> 系统如何保证通过网络传输的信息无法被第三方窃听、篡改和冒充。

#### 5.5.1. 摘要、加密与签名

摘要也称之为数字摘要（Digital Digest）或数字指纹（Digital Fingerprint）。如 JWT 令牌中默认的签名信息是对令牌头、负载和密钥三者通过令牌头中指定的哈希算法（HMAC SHA256）计算出来的摘要值。

理想的哈希算法具备两个特性：

- 易变性
    输入端发生了任何一点细微变动，都会引发雪崩效应（Avalanche Effect），使得输出端的结果产生极大的变化
- 不可逆性
    摘要的过程是单向的，不可能从摘要的结果中逆向还原出输入值来。

摘要的意义是**在源信息不泄漏的前提下辨别其真伪**。易变性保证了从公开的特征上可以甄别出是否来自于源信息，不可逆性保证了从公开的特征并不会暴露出源信息。

摘要也会被借用来做加密（如保密中介绍的慢哈希 Bcrypt 算法）和签名（如 JWT 签名中的 HMAC SHA256 算法），加密与摘要的本质区别在于加密是可逆的，逆过程就是解密。

在经典密码学时代，加密的安全主要是依靠机密性来保证的，即**依靠保护加密算法或算法的执行参数不被泄漏来保障信息的安全**。而现代密码学不依靠机密性，加解密算法都是完全公开的，**安全建立在特定问题的计算复杂度之上**，具体是指算法根据输入端计算输出结果耗费的算力资源很小，但根据输出端的结果反过来推算原本的输入，耗费的算力就极其庞大。

根据加密与解密是否采用同一个密钥，现代密码学算法可分为对称加密算法和非对称加密两大类型。**对称加密存在密钥管理复杂和不安全传输的问题**。为保证两两通信都采用独立的密钥，密钥数量就与成员数量的平方成正比，当通信双方原本就不存在安全的信道时，如何才能将一个只能让通信双方才能知道的密钥传输给对方？

非对称加密算法将密钥分为公钥和私钥，公钥公开私钥保密。

- 公钥加密，私钥解密
    这种就是加密，用于向私钥所有者发送信息，这个信息可能被他人篡改，但是无法被他人得知。

    如果甲想给乙发一个安全保密的数据，那么应该甲乙各自有一个私钥，甲先用乙的公钥加密这段数据，再用自己的私钥加密这段加密后的数据。最后再发给乙，这样确保了内容即不会被读取，也不能被篡改。

    > [!question] 为什么甲也需要使用自己的私钥加密？
    > 这是为了确认数据真的是甲发送的，避免中间人攻击。试想以下场景：
    > 1. 黑客丙截获了甲发给乙的加密数据
    > 2. 丙删除原数据，用乙的公钥加密一个恶意消息发给乙
    > 3. 乙收到后能正常解密，但以为是甲发送的

- 私钥加密，公钥解密
    这种就是签名，用于让所有公钥所有者验证私钥所有者的身份，并且用来防止私钥所有者发布的内容被篡改。但是不用来保证内容不被他人获得。

在加密方面，现在一般会结合对称与非对称加密的优点，以混合加密来保护信道安全，具体做法是**用非对称加密来安全地传递少量数据给通信的另一方，然后再以这些数据为密钥，采用对称加密来安全高效地大量加密传输数据**，这种由多种加密算法组合的应用形式被称为“密码学套件”。非对称加密在这个场景中发挥的作用称为“密钥协商”。

#### 5.5.2. 数字证书与传输安全

##### 5.5.2.1. CA 数字证书

公开密钥基础设施（Public Key Infrastructure，PKI）借着数字证书认证中心（Certificate Authority，CA）将用户的个人身份跟公开密钥链接在一起。**CA 作为受信任的第三方，承担公钥体系中公钥的合法性检验的责任**。权威的 CA 中心则应是可数的，“可数”意味着可以不通过网络，而是在浏览器与操作系统出厂时就预置好，或者提前安装好（如银行的证书）。

证书（Certificate），证书是权威 CA 中心对特定公钥信息的一种公证载体，也可以理解为是**权威 CA 对特定公钥未被篡改的签名背书**。使得我们能够在不依靠网络的前提下，使用根证书里面的公钥信息对其所签发的证书中的签名进行确认。

一个数字证书包含以下内容：

- 版本号
- 序列号
    由证书颁发者分配的本证书的唯一标识符.
- 签名算法标识符（Signature Algorithm ID）
    用于签发证书的算法标识，由对象标识符加上相关的参数组成，用于说明本证书所用的数字签名算法。譬如，SHA1 和 RSA 的对象标识符就用来说明该数字签名是利用 RSA 对 SHA1 的摘要结果进行加密。

    ```txt
    Signature Algorithm: sha1WithRSAEncryption
    ```

- 认证机构的数字签名（Certificate Signature）
    这是使用证书发布者私钥生成的签名，以确保这个证书在发放之后没有被篡改过。
- 认证机构（Issuer Name）
- 有效期限（Validity Period）
- 主题信息（Subject）：证书持有人唯一的标识符，通常使用的是网站的域名
- 公钥信息（Public-Key）
    包括证书持有人的公钥、算法(指明密钥属于哪种密码系统)的标识符和其他相关的密钥参数。

##### 5.5.2.2. 证书工作流程

CA 证书涉及三方，各有自己的密钥对（以 google.com 为例）：

1. **CA 机构**（如 DigiCert、Let's Encrypt）
2. **网站**（如 Google）
3. **用户**（你的电脑/浏览器）

密钥对的实际位置：

-  CA 机构的密钥对
    - CA 私钥：在 CA 机构的安全服务器中（严格保护）
    - CA 公钥：内置在操作系统/浏览器中
-  Google 网站的密钥对
    - Google 私钥：在 Google 自己的服务器上
    - Google 公钥：包含在 CA 签发给 Google 的证书中

具体流程解释：

1. 证书申请和签发
    1. Google 生成自己的密钥对
    2. Google 向 CA 机构申请证书，提交自己的公钥
    3. CA 机构验证 Google 确实拥有 google.com 域名
    4. CA 用自己的私钥对 Google 的公钥进行签名，生成证书
    5. CA 把签好名的证书发给 Googlele
2. 网站部署证书
    Google 服务器上存储：
    - Google 自己的私钥（用于解密）
    - CA 签发的证书（包含 Google 的公钥和 CA 的签名）
3. 用户访问验证
    当你访问 https://google.com时 ：
    
    1. Google 服务器发送证书给你的浏览器
    2. 浏览器用内置的 CA 公钥验证证书签名
    3. 验证通过，说明这个证书确实是可信 CA 签发的
    4. 浏览器提取证书中 Google 的公钥
    5. 用 Google 的公钥与 Google 服务器建立加密连接

##### 5.5.2.3. 传输安全层

TLS 1.2 在传输之前的握手过程一共需要进行上下两轮、共计四次通信：

![image.png](https://r2.129870.xyz/img/2025/c80bb4626554a9b821dc93b86a9a7d3e.png)

1. 客户端请求：Client Hello
    客户端向服务器请求进行加密通信，在这个请求里面，它会以明文的形式，向服务端提供以下信息：
    
    - 支持的协议版本
        譬如 TLS 1.2。1.0 至 3.0 分别代表 SSL1.0 至 3.0，TLS1.0 则是 3.1，一直到 TLS1.3 的 3.4
    - 一个客户端生成的 32 Bytes 随机数，这个随机数将稍后用于产生加密的密钥
    - 一个可选的 SessionID，传输安全层的 Session，是为了 TLS 的连接复用而设计的
    - 一系列支持的密码学算法套件
        例如 TLS_RSA_WITH_AES_128_GCM_SHA256，代表着密钥交换算法是 RSA，加密算法是 AES128-GCM，消息认证码算法是 SHA256
    - 一系列支持的数据压缩算法
    - 其他可扩展的信息
        为了保证协议的稳定，后续对协议的功能扩展大多都添加到这个变长结构中。“譬如 TLS 1.0 中由于发送的数据并不包含服务器的域名地址，导致了一台服务器只能安装一张数字证书，这对虚拟主机来说就很不方便，所以 TLS 1.1 起就增加了名为“Server Name”的扩展信息，以便一台服务器给不同的站点安装不同的证书

2. 服务端回应：Server hello
    服务器接收到客户端的通信请求后，如果客户端声明支持的协议版本和加密算法组合与服务端相匹配的话，就向客户端发出回应。如果不匹配，将会返回一个握手失败的警告提示。这次回应同样以明文发送的，包括以下信息：
    
    - 服务端确认使用的 TLS 协议版本
    - 第二个 32 Bytes 的随机数，稍后用于产生加密的密钥
    - 一个 SessionID，以后可通过连接复用减少一轮握手
    - 服务端在列表中选定的密码学算法套件
    - 服务端在列表中选定的数据压缩方法
    - 其他可扩展的信息
    - 如果协商出的加密算法组合是依赖证书认证的，服务端还要发送出自己的 X.509 证书，而证书中的公钥是什么，也必须根据协商的加密算法组合来决定
    - 密钥协商消息
        这部分内容对于不同密码学套件有着不同的价值，譬如对于 ECDH + anon 这样得密钥协商算法组合（基于椭圆曲线的 ECDH 算法可以在双方通信都公开的情况下协商出一组只有通信双方知道的密钥）就不需要依赖证书中的公钥，而是通过 Server Key Exchange 消息协商出密钥。
3. 客户端确认：Client Handshake Finished
    客户端收到服务器应答后，先要验证服务器的证书合法性。如果证书不是可信机构颁布的，或者证书中信息存在问题，譬如域名与实际域名不一致、或者证书已经过期、或通过在线证书状态协议得知证书已被吊销，等等，都会向访问者显示一个“证书不可信任”的警告，由用户自行选择是否还要继续通信。如果证书没有问题，客户端就会从证书中取出服务器的公钥，并向服务器发送以下信息：
    
    - 客户端证书（可选）
        部分服务端并不是面向全公众，只对特定的客户端提供服务，此时客户端需要发送它自身的证书来证明身份。如果不发送，或者验证不通过，服务端可自行决定是否要继续握手，或者返回一个握手失败的信息。客户端需要证书的 TLS 通信也称为**“双向 TLS”**（Mutual TLS，常简写为 mTLS），这是云原生基础设施的主要认证方法，也是基于信道认证的最主流形式。
    - 第三个 32 Bytes 的随机数
        这个随机数不再是明文发送，而是以服务端传过来的公钥加密的，它被称为 PreMasterSecret，将与前两次发送的随机数一起，根据特定算法计算出 48Bytes 的 MasterSecret ，这个 MasterSecret 即为**后续内容传输时的对称加密算法所采用的私钥**。
    - 编码改变通知
        表示随后的信息都将用双方商定的加密方法和密钥发送。
    - 客户端握手结束通知
        表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的哈希值，以供服务器校验
4. 服务端确认：Server Handshake Finished
    服务端向客户端回应最后的确认通知，包括以下信息：
    
    - 编码改变通知
        表示随后的信息都将用双方商定的加密方法和密钥发送。
    - 服务器握手结束通知
        表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的哈希值，以供客户端校验。

HTTPS 并非不是只有“启用了 HTTPS”和“未启用 HTTPS”的差别，采用不同的协议版本、不同的密码学套件、证书是否有效、服务端/客户端对面对无效证书时的处理策略如何都导致了不同 HTTPS 站点的安全强度的不同，因此并不能说只要启用了 HTTPS 就必定能够安枕无忧。

## 6. 分布式的基石

### 6.1. 分布式共识算法

#### 6.1.1. Paxos

##### 6.1.1.1. 算法过程

Paxos 算法将分布式系统中的节点分为三类：

- 提案节点：Proposer
    提出对某个值进行设置操作的节点，设置值这个行为就被称之为提案（Proposal），值一旦设置成功，就是不会丢失也不可变的。请注意，Paxos 是典型的基于操作转移模型而非状态转移模型来设计的算法。
- 决策节点：Acceptor
    应答提案的节点，决定该提案是否可被投票、是否可被接受。提案一旦得到过半数决策节点的接受，即称该提案被批准（Accept），提案被批准即意味着该值不能再被更改，也不会丢失，且最终所有节点都会接受该它。
- 记录节点：Learner
    不参与提案，也不参与决策，只是单纯地从提案、决策节点中学习已经达成共识的提案，譬如少数派节点从网络分区中恢复时，将会进入这种状态。

使用 Paxos 算法的分布式系统里的，所有的节点都是平等的，它们都可以承担以上某一种或者多种的角色，不过为了便于确保有明确的多数派，决策节点的数量应该被设定为奇数个，且在系统初始化时，网络中每个节点都知道整个网络所有决策节点的数量、地址等信息。

共识算法“就某个值达成一致”的复杂度主要源于以下两个方面：

- 系统内部各个节点通信是不可靠的
- 系统外部各个用户的访问是可并发的
    并发问题可用加锁解决，但分布式算法中的加锁就不完全等同于并发控制中以互斥量来实现的加锁，还必须提供一个其他节点能抢占锁的机制，以避免因通信问题而出现死锁。

Paxos 算法包含两个阶段：

1. 准备（Prepare）阶段

    相当于抢占锁的过程，如果某个提案节点准备发起提案，必须先向所有的决策节点广播一个许可申请（称为 Prepare 请求）。提案节点的 Prepare 请求中会附带一个全局唯一的数字 n 作为提案 ID，决策节点收到后，将会给予提案节点两个承诺与一个应答。

    两个承诺：

    1. 承诺不会再接受提案 ID 小于或等于 n 的 Prepare 请求
    2. 承诺不会再接受提案 ID 小于 n 的 Accept 请求

    一个应答：不违背以前作出的承诺的前提下，回复已经批准过的提案中 ID 最大的那个提案所设定的值和提案 ID，如果该值从来没有被任何提案设定过，则返回空值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Prepare 请求不予理会。

2. 批准（Accept）阶段

    当提案节点收到了多数派决策节点的应答（称为 Promise 应答）后，可以开始第二阶段“批准”（Accept）过程，这时有如下两种可能的结果：

    - 所有响应的决策节点都没有批准过该值
        这说明它是第一个设置值的节点，可以随意地决定要设定的值，将自己选定的值与提案 ID，构成一个二元组(id, value)，再次广播给全部的决策节点（称为 Accept 请求）。
    - 至少有一个决策节点响应中包含有值了
        此时不能够随意取值了，必须无条件地从应答中找出提案 ID 最大的那个值并接受，构成一个二元组(id, maxAcceptValue)，再次广播给全部的决策节点（称为 Accept 请求）。

当每一个决策节点收到 Accept 请求时，都会在不违背以前作出的承诺的前提下，接收并持久化对当前提案 ID 和提案附带的值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Accept 请求不予理会。

当提案节点收到了多数派决策节点的应答（称为 Accepted 应答）后，协商结束，共识决议形成，将形成的决议发送给所有记录节点进行学习。

![image.png](https://r2.129870.xyz/img/2025/a308bb8f70a6acb9d8039985944fbc83.png)

##### 6.1.1.2. 工作示例

假设一个分布式系统有五个节点，分别命名为 $S_1$、$S_2$ 、$S_3$、$S_4$、$S_5$，这个例子中只讨论正常通信的场景，不涉及网络分区。全部节点都同时扮演着提案节点和决策节点的身份。此时，有两个并发的请求分别希望将同一个值分别设定为 X（由 $S_1$ 作为提案节点提出）和 Y（由 $S_5$ 作为提案节点提出），以 P 代表准备阶段，以 A 代表批准阶段，这时候可能发生以下情况：

- 情况一
    $S_1$ 选定的提案 ID 是 3.1（全局唯一 ID 加上节点编号），先取得了多数派决策节点的 Promise 和 Accepted 应答，此时 $S_5$ 选定提案 ID 是 4.5，发起 Prepare 请求，收到的多数派应答中至少会包含 1 个此前应答过 $S_1$ 的决策节点，假设是 $S_3$，那么 $S_3$ 提供的 Promise 中必将包含 $S_1$ 已设定好的值 X，$S_5$ 就必须无条件地用 X 代替 Y 作为自己提案的值，由此整个系统对“取值为 X”这个事实达成一致。

    ![image.png](https://r2.129870.xyz/img/2025/19275acbcb3f1a4a72a09432d820d4f4.png)

- 情况二
    事实上，对于情况一，X 被选定为最终值是必然结果，但从情况一中可以看出，X 被选定为最终值并不是必定需要多数派的共同批准，只取决于 $S_5$ 提案时 **Promise 应答中是否已包含了批准过 X 的决策节点**，$S_5$ 发起提案的 Prepare 请求时，X 并未获得多数派批准，但由于 $S_3$ 已经批准的关系，最终共识的结果仍然是 X。

    ![image.png](https://r2.129870.xyz/img/2025/3067e6cc67cbd2b4734dc22e7f18f6d0.png)

- 情况三
    $S_5$ 提案时 Promise 应答中并未包含批准过 X 的决策节点，譬如应答 $S_5$ 提案时，节点 $S_1$ 已经批准了 X，节点 $S_2$、$S_3$ 未批准但返回了 Promise 应答，此时 $S_5$ 以更大的提案 ID 获得了 $S_3$、$S_4$、$S_5$ 的 Promise，这三个节点均未批准过任何值，那么 $S_3$ 将不会再接收来自 $S_1$ 的 Accept 请求，因为它的提案 ID 已经不是最大的了，这三个节点将批准 Y 的取值，整个系统最终会对“取值为 Y”达成一致。

    ![image.png](https://r2.129870.xyz/img/2025/204ddc3e7bb5b423a3b4e78c6699eb33.png)

- 情况四
    从情况三可以推导出另一种极端的情况，如果两个提案节点交替使用更大的提案 ID 使得准备阶段成功，但是批准阶段失败的话，这个过程理论上可以无限持续下去，形成活锁（Live Lock）。在算法实现中会引入随机超时时间来避免活锁的产生。

    ![image.png](https://r2.129870.xyz/img/2025/2df3cc7d23b5b0ba0a8ad6c7ac117de7.png)

Basic Paxos 的价值在于开拓了分布式共识算法的发展思路，但它因有如下缺陷，一般不会直接用于实践：Basic Paxos 只能对单个值形成决议，并且决议的形成至少需要两次网络请求和应答（准备和批准阶段各一次），高并发情况下将产生较大的网络开销，极端情况下甚至可能形成活锁。

#### 6.1.2. Multi Paxos

活锁问题与许多 Basic Paxos 异常场景中所遭遇的麻烦，都可以看作是源于任何一个提案节点都能够完全平等地、与其他节点并发地提出提案而带来的复杂问题。

Multi Paxos 对 Basic Paxos 的核心改进是**增加了选主”的过程**，提案节点会通过定时轮询（心跳），确定当前网络中的所有节点里是否存在有一个主提案节点，一旦没有发现主节点存在，节点就会在心跳超时后使用 Basic Paxos 中定义的准备、批准的两轮网络交互过程，向所有其他节点广播自己希望竞选主节点的请求，希望整个分布式系统对“由我作为主节点”这件事情协商达成一致共识，如果得到了决策节点中多数派的批准，便宣告竞选成功。

当选主完成之后，除非主节点失联之后发起重新竞选，否则从此往后，就**只有主节点本身才能够提出提案**。此时，**无论哪个提案节点接收到客户端的操作请求，都会将请求转发给主节点来完成提案**，而主节点提案的时候，也就无需再次经过准备过程，因为可以视作是“经过选举时的那一次准备之后，后续的提案都是对相同提案 ID 的一连串的批准过程。也可以通俗理解为选主过后，就不会再有其他节点与它竞争，相当于是处于无并发的环境当中进行的有序操作，所以此时系统中要对某个值达成一致，只需要进行一次批准的交互即可。

![image.png](https://r2.129870.xyz/img/2025/ff701134d51b3e28ffee857b776e8ed0.png)

这时候的二元组(id, value)已经变成了三元组(id, i, value)，这是因为需要**给主节点增加一个“任期编号”，这个编号必须是严格单调递增的**，以应付主节点陷入网络分区后重新恢复，但另外一部分节点仍然有多数派，且已经完成了重新选主的情况，此时必须以任期编号大的主节点为准。当节点有了选主机制的支持，在整体来看，就可以进一步简化节点角色，不去区分提案、决策和记录节点了，统统以“节点”来代替，节点只有主（Leader）和从（Follower）的区别。

![image.png](https://r2.129870.xyz/img/2025/af09bc98c2c754404d99100cbfc6b272.png)

分布式系统中如何对某个值达成一致”这个问题可以划分做三个子问题来考虑，当以下三个问题同时被解决时，即等价于达成共识：

- 如何选主（Leader Election）
    选主问题尽管还涉及许多工程上的细节，譬如心跳、随机超时、并行竞选，等等，但要只论原理的话，Paxos 算法的操作就能对分布式系统“谁来当主节点”这件事情达成共识。
- 如何把数据复制到各个节点上（Entity Replication）
    在正常情况下，当客户端向主节点发起一个操作请求，譬如提出“将某个值设置为 X”，此时主节点将 X 写入自己的变更日志，但先不提交，接着把变更 X 的信息在下一次心跳包中广播给所有的从节点，并要求从节点回复确认收到的消息，从节点收到信息后，将操作写入自己的变更日志，然后给主节点发送确认签收的消息，主节点收到过半数的签收消息后，提交自己的变更、应答客户端并且给从节点广播可以提交的消息，从节点收到提交消息后提交自己的变更，数据在节点间的复制宣告完成。

    在异常情况下，网络出现了分区，部分节点失联，但只要仍能正常工作的节点的数量能够满足多数派（过半数）的要求，分布式系统就仍然可以正常工作，这时数据复制过程如下：

    - 假设有 $S_1$、$S_2$、$S_3$、$S_4$、$S_5$ 五个节点，$S_1$ 是主节点，由于网络故障，导致 $S_1$、$S_2$ 和 $S_3$、$S_4$、$S_5$ 之间彼此无法通信，形成网络分区
    - 一段时间后，$S_3$、$S_4$、$S_5$ 三个节点中的某一个（譬如是 $S_3$）最先达到心跳超时的阈值，获知当前分区中已经不存在主节点了，它向所有节点发出自己要竞选的广播，并收到了 $S_4$、$S_5$ 节点的批准响应，加上自己一共三票，即得到了多数派的批准，竞选成功，此时系统中同时存在 $S_1$ 和 $S_3$ 两个主节点，但由于网络分区，它们不会知道对方的存在。

    此时，客户端发起操作请求：

    - 如果客户端连接到了 $S_1$、$S_2$ 之一，都将由 $S_1$ 处理，但由于操作只能获得最多两个节点的响应，不构成多数派的批准，所以任何变更都无法成功提交
    - 如果客户端连接到了 $S_3$、$S_4$、$S_5$ 之一，都将由 $S_3$ 处理，此时操作可以获得最多三个节点的响应，构成多数派的批准，是有效的，变更可以被提交，即系统可以继续提供服务

    此后故障恢复，分区解除：

    - $S_1$ 和 $S_3$ 都向所有节点发送心跳包，从各自的心跳中可以得知两个主节点里 $S_3$ 的任期编号更大，它是最新的，此时五个节点均只承认 $S_3$ 是唯一的主节点
    - $S_1$、$S_2$ 回滚它们所有未被提交的变更
    - $S_1$、$S_2$ 从主节点发送的心跳包中获得它们失联期间发生的所有变更，将变更提交写入本地磁盘
    - 此时分布式系统各节点的状态达成最终一致
- 如何保证过程是安全的（Safety）
    Safety 保证了选主的结果一定是有且只有唯一的一个主节点，不可能同时出现两个主节点；而 Liveness 则要保证选主过程是一定可以在某个时刻能够结束的。

#### 6.1.3. Gossip 协议

Gossip 的过程：

1. 如果有某一项信息需要在整个网络中所有节点中传播，那从信息源开始，选择一个固定的传播周期（譬如 1 秒），随机选择它相连接的 k 个节点（称为 Fan-Out）来传播消息
2. 每一个节点收到消息后，如果这个消息是它之前没有收到过的，将在下一个周期内，选择除了发送消息给它的那个节点外的其他相邻 k 个节点发送相同的消息，直到最终网络中所有节点都收到了消息，尽管这个过程需要一定时间，但是理论上最终网络的所有节点都会拥有相同的消息

![gossip.0eb19e80.gif](https://r2.129870.xyz/img/2025/0eb19e80fd049add9eec775bfbc87ced.gif)

Gossip 优势：

- 对网络节点的连通性和稳定性几乎没有任何要求，它一开始就将网络某些节点只能与一部分节点部分连通（Partially Connected Network）而不是以全连通网络（Fully Connected Network）作为前提
- 能够容忍网络上节点的随意地增加或者减少，随意地宕机或者重启，新增加或者重启的节点的状态最终会与其他节点同步达成一致
- Gossip 把网络上所有节点都视为平等而普通的一员，没有任何中心化节点或者主节点的概念，

这些特点使得 Gossip 具有极强的鲁棒性，而且非常适合在公众互联网中应用。但同时 Gossip 有很明显的缺点：

- 消息最终是通过多个轮次的散播而到达全网的，因此它必然会存在全网各节点状态不一致的情况
- 随机选取发送消息的节点，所以尽管可以在整体上测算出统计学意义上的传播速率，但对于个体消息来说，无法准确地预计到需要多长时间才能达成全网一致
- 由于随机选取发送消息的节点，也就不可避免的存在消息重复发送给同一节点的情况，增加了网络的传输的压力，也给消息节点带来额外的处理负载

为了改善缺点，Gossip 设计了两种可能的消息传播模式：

- 反熵（Anti-Entropy）
    在反熵模式下，会同步节点的全部数据，以消除各节点之间的差异，目标是整个网络各节点完全的一致。但是，在节点本身就会发生变动的前提下，这个目标将使得整个网络中消息的数量非常庞大，给网络带来巨大的传输开销。
- 传谣（Rumor-Mongering）
    传谣模式是以传播消息为目标，仅仅发送新到达节点的数据，即只对外发送变更信息，这样消息数据量将显著缩减，网络开销也相对较小。

### 6.2. 从类库到服务

微服务架构其中一个重要设计原则是“通过服务来实现独立自治的组件”（Componentization via Services），强调应采用“服务”（Service）而不再是“类库”（Library）来构建组件化的程序。

一套由多个微服务相互调用才能正常运作的分布式系统中，每个节点都互相扮演着服务的生产者与消费者的多重角色，形成了一套复杂的网状调用关系，此时，至少有（但不限于）以下三个问题是必须考虑并得到妥善解决的：

- 服务发现
    对消费者来说，外部服务是谁提供的，具体在网络什么位置。
- 服务的网关路由
    对生产者来说，**内部哪些服务需要暴露？哪些应当隐藏？应当以何种形式暴露服务？以什么规则在集群中分配请求**？
- 服务的负载均衡
    对调用过程来说，如何保证每个远程服务都接收到相对平均的流量，获得尽可能高的服务质量与可靠性？

#### 6.2.1. 服务发现

所有的远程服务调用都是使用全限定名（Fully Qualified Domain Name，FQDN）、端口号与服务标识所构成的三元组来确定一个远程服务的精确坐标的。**服务标识则与具体的应用层协议相关**，不同协议具有不同形式的标识，譬如 REST 的远程服务，标识是 URL 地址；RMI 的远程服务，标识是 Stub 类中的方法；SOAP 的远程服务，标识是 WSDL 中定义方法，等等。

当前主流的服务发现方式是服务坐标退化为更简单的全限定名+端口号这样的形式，原本最初服务发现只依赖 DNS 将一个全限定名翻译为一至多个 IP 地址或者 SRV 等其他类型的记录便可，位于 DNS 之后的负载均衡器也实质上承担了一部分服务发现的职责。但随着微服务的逐渐流行，服务的非正常宕机、重启和正常的上线、下线变得越发频繁，仅靠着 DNS 服务器和负载均衡器等基础设施就显得逐渐疲于应对，无法跟上服务变动的步伐了。

服务发现的具体过程：

- 服务注册
    当服务启动的时候，它应该通过某些形式（如调用 API、产生事件消息、在 ZooKeeper/Etcd 的指定位置记录、存入数据库，等等）**将自己的坐标信息通知到服务注册中心**，这个过程可能由应用程序本身来完成，称为自注册模式，譬如 Spring Cloud 的 `@EnableEurekaClient` 注解；也可能由容器编排框架或第三方注册工具来完成，称为第三方注册模式，譬如 Kubernetes 和 Registrator。
- 服务维护
    尽管服务发现框架通常都有提供下线机制，但并没有什么办法**保证每次服务都能优雅地下线（Graceful Shutdown）而不是由于宕机、断网等原因突然失联**。所以服务发现框架必须要自己去保证所维护的服务列表的正确性，以避免告知消费者服务的坐标后，得到的服务却不能使用的尴尬情况。现在的服务发现框架，往往都能支持多种协议（HTTP、TCP 等）、多种方式（长连接、心跳、探针、进程状态等）去监控服务是否健康存活，将不健康的服务自动从服务注册表中剔除。
- 服务发现
    特指狭义上消费者从服务发现框架中，把一个符号（譬如 Eureka 中的 ServiceID、Nacos 中的服务名、或者通用的 FQDN）转换为服务实际坐标的过程，这个过程现在一般是通过 HTTP API 请求或者通过 DNS Lookup 操作来完成，也还有一些相对少用的方式，譬如 Kubernetes 也支持注入环境变量来做服务发现。

除了以上功能外还会有一些可选的扩展功能，譬如在服务发现时进行的负载均衡、流量管控、键值存储、元数据管理、业务分组，等等。

![image.png](https://r2.129870.xyz/img/2025/ee144720a950231e67040147e3a2f65d.png)

服务发现也面临 CAP 的问题：

- AP 类实现
    Eureka 的选择是优先保证高可用性，相对牺牲系统中服务状态的一致性。Eureka 的各个节点间采用异步复制来交换服务注册信息，当有新服务注册进来时，并不需要等待信息在其他节点复制完成，而是马上在该服务发现节点宣告服务可见，只是不保证在其他节点上多长时间后才会可见。同时，当有旧的服务发生变动，譬如下线或者断网，只会由超时机制来控制何时从哪一个服务注册表中移除，变动信息不会实时的同步给所有服务端与客户端。

    这样的设计使得不论是 Eureka 的服务端还是客户端，都能够持有自己的服务注册表缓存，并以 TTL（Time to Live）机制来进行更新，哪怕服务注册中心完全崩溃，客户端在仍然可以维持最低限度的可用。Eureka 的服务发现模型对节点关系相对固定，服务一般不会频繁上下线的系统是很合适的，以较小的同步代价换取了最高的可用性。

    Eureka 能够选择这种模型的底气在于万一客户端拿到了已经发生变动的错误地址，也能够通过 Ribbon 和 Hystrix 模块配合来兜底，实现故障转移（Failover）或者快速失败（Failfast）。

- CP 类实现
    Consul 的选择是优先保证高可靠性，相对牺牲系统服务发现的可用性。Consul 采用 Raft 算法，要求多数派节点写入成功后服务的注册或变动才算完成，严格地保证了在集群外部读取到的服务发现结果必定是一致的；同时采用 Gossip 协议，支持多数据中心之间更大规模的服务同步。Consul 优先保证高可靠性一定程度上是基于产品现实情况而做的技术决策，它不像 Netflix OSS 那样有着全家桶式的微服务组件，万一从服务发现中取到错误地址，就没有其他组件为它兜底了。

这两种的选取在于如何看待网络分区对系统的影响：假设系统形成了 A、B 两个网络分区后，A 区的服务只能从区域内的服务发现节点获取到 A 区的服务坐标，B 区的服务只能取到在 B 区的服务坐标，这对你的系统会有什么影响？

- 假如没有影响甚至还是有益的话那么倾向于 AP 选择
    譬如假设 A、B 就是不同的机房，是机房间的网络交换机导致服务发现集群出现的分区问题，但每个分区中的服务仍然能独立提供完整且正确的服务能力，此时尽管不是有意而为，但网络分区在事实上避免了跨机房的服务请求，反而还带来了服务调用链路优化的效果。
- 影响很大甚至可能宕机
    倾向于选择 CP 式的服务发现。譬如系统中大量依赖了集中式缓存、消息总线、或者其他有状态的服务，一旦这些服务全部或者部分被分隔到某一个分区中，会对整个系统的操作的正确性产生直接影响的话，那与其最后弄出一堆数据错误，还不如直接停机来得痛快。

当下直接以服务发现、服务注册中心为目标的组件库，或者间接用来实现这个目标的工具主要有以下三类：

- 在分布式 K/V 存储框架上自己开发的服务发现，这类的代表是 ZooKeeper、Doozerd、Etcd
    这些 K/V 框架提供了分布式环境下读写操作的共识算法，基于这些框架提供的算法和基础的 API 来构建完整的服务发现能力。
- 以基础设施（主要指 DNS）来实现服务发现，这类的代表是 SkyDNS、CoreDNS
    在 Kubernetes 1.3 之前的版本使用 SkyDNS 作为默认的 DNS 服务，其工作原理是从 API Server 中监听集群服务的变化，然后根据服务生成 NS、SRV 等 DNS 记录存放到 Etcd 中，kubelet 会为每个 Pod 设置 DNS 服务的地址为 SkyDNS 的地址，需要调用服务时，只需查询 DNS 把域名转换成 IP 列表便可实现分布式的服务发现。

    在 Kubernetes 1.3 之后，SkyDNS 不再是默认的 DNS 服务器，而是由不使用 Etcd，只将 DNS 记录存储在内存中的 KubeDNS 代替，到了 1.11 版，就更推荐采用扩展性很强的 CoreDNS，此时可以通过各种插件来决定是否要采用 Etcd 存储、重定向、定制 DNS 记录、记录日志，等等。

    以基础设施来做服务发现，好处是对应用透明，任何语言、框架、工具都肯定是支持 HTTP、DNS 的，所以完全不受程序技术选型的约束，但坏处是**透明的并不一定是简单的，你必须自己考虑如何去做客户端负载均衡、如何调用远程方法等这些问题**，而且必须遵循或者说受限于这些基础设施本身所采用的实现机制，譬如服务健康检查里，服务的缓存期限就应该由 TTL 来决定，这是 DNS 协议所规定的，如果想改用 KeepAlive 长连接来实时判断服务是否存活就相对麻烦。

- 采用专门的服务发现工具和框架，这类的代表是 Eureka、Consul 和 Nacos
    这一类框架中，可以自己决定是 CP 还是 AP 的问题，譬如 CP 的 Consul、AP 的 Eureka，还有同时支持 CP 和 AP 的 Nacos（Nacos 采用类 Raft 协议做的 CP，采用自研的 Distro 协议做的 AP，这里“同时”是“都支持”的意思，它们必须二取其一，不是说 CAP 全能满足）。

#### 6.2.2. 网关路由

微服务中网关的首要职责就是作为统一的出口对外提供服务，将外部访问网关地址的流量，**根据适当的规则路由到内部集群中正确的服务节点之上**。因此，微服务中的网关，也常被称为“服务网关”或者“API 网关”，微服务中的网关首先应该是个路由器，在满足此前提的基础上，网关还可以根据需要作为流量过滤器来使用，提供某些额外的可选的功能，譬如安全、认证、授权、限流、监控、缓存，等等。

针对路由这个基础职能，服务网关主要考量的是能够支持路由的“网络协议层次”和“性能与可用性”两方面的因素。网络协议层次是指负载均衡中介绍过的四层流量转发与七层流量代理，仅从技术实现角度来看，对于路由这项工作，负载均衡器与服务网关在实现上是没有什么差别的，具体在于前者是为了根据均衡算法对流量进行平均地路由，后者是为了**根据流量中的某种特征**进行正确地路由。

网关必须能够识别流量中的特征，这意味着网关能够支持的网络通信协议的层次将会直接限制后端服务节点能够选择的服务通信方式。如果服务集群只提供像 Etcd 这样直接基于 TCP 的访问的服务，那只部署四层网关便可满足，网关以 IP 报文中源地址、目标地址为特征进行路由；如果服务集群要提供 HTTP 服务的话，那就必须部署一个七层网关，网关根据 HTTP 报文中的 URL、Header 等信息为特征进行路由；如果服务集群还要提供更上层的 WebSocket、SOAP 等服务，那就必须要求网关同样能够支持这些上层协议，才能从中提取到特征。

网关的另一个主要关注点是它的性能与可用性：

- 性能
    性能与它的工作模式和自身实现算法都有关系，但毫无疑问工作模式是最关键的因素，如果能够采用 DSR 三角传输模式，原理上就决定了性能一定会比代理模式来的强。

    不过，因为今天 REST 和 JSON-RPC 等基于 HTTP 协议的服务接口在对外部提供的服务中占绝对主流的地位，所以我们所讨论的服务网关默认都必须支持七层路由，通常就默认无法直接进行流量转发，只能采用代理模式。在这个前提约束下，**网关的性能主要取决于它们如何代理网络请求，也即它们的网络 I/O 模型**。

- 可用性
    - 网关应尽可能轻量
        尽管网关作为服务集群统一的出入口，可以很方便地做安全、认证、授权、限流、监控，等等的功能，但给网关附加这些能力时还是要仔细权衡，取得功能性与可用性之间的平衡，过度增加网关的职责是危险的。
    - 尽可能选择成熟的产品实现
    - 在需要高可用的生产环境中，应当考虑在网关之前部署负载均衡器或者等价路由器（ECMP），让那些更成熟健壮的设施（往往是硬件物理设备）去充当整个系统的入口地址

BFF （Backends for Frontends）网关：网关不必为所有的前端提供无差别的服务，而是应该针对不同的前端，聚合不同的服务，提供不同的接口和网络访问协议支持。

![image.png](https://r2.129870.xyz/img/2025/4e365e62c2d87bac93d139cdeaabfa70.png)

#### 6.2.3. 客户端负载均衡

随着微服务日渐流行，服务集群的收到的请求来源不再局限于外部，越来越多的访问请求是由集群内部的某个服务发起，由集群内部的另一个服务进行响应的。对于这类流量的负载均衡，既有的方案依然是可行的，但**针对内部流量的特点，直接在服务集群内部消化掉，肯定是更合理更受开发者青睐的办法**。由此一种全新的、独立位于每个服务前端的、分散式的负载均衡方式正逐渐变得流行起来。

客户端均衡器：服务实例一一对应的，而且与服务实例并存于同一个进程之内：

![image.png](https://r2.129870.xyz/img/2025/c649a4bbff4f4883287db3e085975c97.png)

客户端负载均衡器具有如下好处：

- 均衡器与服务之间信息交换是进程内的方法调用，不存在任何额外的网络开销
- 不依赖集群边缘的设施，所有内部流量都仅在服务集群的内部循环
- 分散式的均衡器意味着天然避免了集中式的单点问题
- 更加灵活
    可以针对每一个服务实例单独设置均衡策略等参数，访问某个服务，是不是需要具备亲和性，选择服务的策略是随机、轮询、加权还是最小连接等等，都可以单独设置而不影响其它服务。

但同样它有不少缺点：

- 与服务运行于同一个进程之内，意味着它的选型受到服务所使用的编程语言的限制
- 资源占用问题
    从个体服务来看，由于是共用一个进程，**均衡器的稳定性会直接影响整个服务进程的稳定性**，消耗的 CPU、内存等资源也同样影响到服务的可用资源。从集群整体来看，在服务数量达成千乃至上万规模时，客户端均衡器消耗的资源总量是相当可观的。
- 节点关系变得更复杂
    由于请求的来源可能是来自集群中任意一个服务节点，而不再是统一来自集中式均衡器，这就使得**内部网络安全和信任关系变得复杂**，当攻破任何一个服务时，更容易通过该服务突破集群中的其他部分。
- 集群关系维护的成本
    服务集群的拓扑关系是动态的，每一个客户端均衡器必须持续跟踪其他服务的健康状况，以实现上线新服务、下线旧服务、自动剔除失败的服务、自动重连恢复的服务等均衡器必须具备的功能。由于这些操作都需要通过访问服务注册中心来完成，数量庞大的客户端均衡器一直持续轮询服务注册中心，也会为它带来不小的负担。

#### 6.2.4. 代理类负载均衡器

服务网格（Service Mesh）开始逐渐盛行，另外一种被称为“代理客户端负载均衡器”（Proxy Client-Side Load Balancer，后文简称“代理均衡器”）的客户端均衡器变体形式开始引起不同编程语言的微服务开发者共同关注，它解决了此前客户端均衡器的大多数缺陷。代理均衡器对此前的客户端负载均衡器的改进是将原本嵌入在服务进程中的均衡器提取出来，作为一个进程之外，同一 Pod 之内的特殊服务，放到边车代理中去实现：

![image.png](https://r2.129870.xyz/img/2025/3312e8859f95ad468e72a1106b40c02f.png)

虽然代理均衡器与服务实例不再是进程内通信，而是通过网络协议栈进行数据交换的，数据要经过操作系统的协议栈，要进行打包拆包、计算校验和、维护序列号等网络数据的收发步骤，流量比起之前的客户端均衡器确实多增加了一系列处理步骤。不过，Kubernetes 严格保证了同一个 Pod 中的容器不会跨越不同的节点，这些容器共享着同一个网络名称空间，因此代理均衡器与服务实例的交互，实质上是对本机回环设备的访问，仍然要比真正的网络交互高效且稳定得多。代理均衡器付出的代价较小，但从服务进程中分离出来所获得的收益却是非常显著的：

- 代理均衡器不再受编程语言的限制
- 在服务拓扑感知方面代理均衡器也要更有优势
    由于边车代理接受控制平面的统一管理，当服务节点拓扑关系发生变化时，控制平面就会主动向边车代理发送更新服务清单的控制指令，这避免了此前客户端均衡器必须长期主动轮询服务注册中心所造成的浪费。
- 安全性、可观测性方面，由于边车代理都是一致的实现，有利于在服务间建立双向 TLS 通信，也有利于对整个调用链路给出更详细的统计信息

### 6.3. 流量治理

> [!abstract] 容错性设计
> 由于服务随时都有可能崩溃，因此快速的失败检测和自动恢复就显得至关重要。

微服务的架构下，多个服务之间的调用面临以下问题：

- 服务雪崩效应
    由于某一个服务的崩溃，导致所有用到这个服务的其他服务都无法正常工作，一个点的错误经过层层传递，最终波及到调用链上与此有关的所有服务。
- 服务处理能力有限
    服务虽然没有崩溃，但由于处理能力有限，面临超过预期的突发请求时，大部分请求直至超时都无法完成处理。

#### 6.3.1. 服务容错

容错性设计不能妥协源于分布式系统的本质是不可靠的，一个大的服务集群中，程序可能崩溃、节点可能宕机、网络可能中断，这些“意外情况”其实全部都在“意料之中。

常见的容错策略有以下几种：

- 故障转移（FailOver）
    如果调用的服务器出现故障，系统不会立即向调用者返回失败结果，而是自动切换到其他服务副本，尝试其他副本能否返回成功调用的结果，从而保证了整体的高可用性。

    故障转移的容错策略应该有一定的调用次数限制，譬如允许最多重试三个服务，如果都发生报错，那还是会返回调用失败。原因不仅是因为重试是有执行成本的，更是因为过度的重试反而可能让系统处于更加不利的状况。譬如有以下调用链：

    ```txt
    Service A --> Service B --> Service
    ```

    假设 A 的超时阈值为 100 毫秒，而 B 调用 C 花费 60 毫秒，然后不幸失败了，这时候做故障转移其实已经没有太大意义了。

- 快速失败（FailFast）
    一些业务场景是不允许做故障转移的，**故障转移策略能够实施的前提是要求服务具备幂等性**，对于非幂等的服务，重复调用就可能产生脏数据，引起的麻烦远大于单纯的某次服务调用失败，此时就应该以快速失败作为首选的容错策略。
- 安全失败（FailSafe）
    在一个调用链路中的服务通常也有主路和旁路之分，并不见得其中每个服务都是不可或缺的，有部分服务失败了也不影响核心业务的正确性。对这类逻辑，一种理想的容错策略是即使旁路逻辑调用实际失败了，也当作正确来返回，如果需要返回值的话，系统就自动返回一个符合要求的数据类型的对应零值，然后自动记录一条服务调用出错的日志备查即可，这种策略被称为安全失败。
- 沉默失败（FailSilent）
    如果大量的请求需要等到超时（或者长时间处理后）才宣告失败，很容易由于某个远程服务的请求堆积而消耗大量的线程、内存、网络等资源，进而影响到整个系统的稳定。面对这种情况，一种合理的失败策略是**当请求失败后，就默认服务提供者一定时间内无法再对外提供服务**，不再向它分配请求流量，将错误隔离开来，避免对系统其他部分产生影响，此即为沉默失败策略。
- 故障恢复（Failback）
    故障恢复一般不单独存在，而是作为其他容错策略的补充措施，一般在微服务管理框架中，如果设置容错策略为故障恢复的话，通常默认会采用快速失败加上故障恢复的策略组合。它是指当服务调用出错了以后，将该次调用失败的信息存入一个消息队列中，然后由系统自动开始异步重试调用。

    故障恢复策略一般用于对实时性要求不高的主路逻辑，同时也适合处理那些不需要返回值的旁路逻辑。为了避免在内存中异步调用任务堆积，故障恢复与故障转移一样，应该有最大重试次数的限制。

- 并行调用（Forking）
    一开始就同时向多个服务副本发起调用，只要有其中任何一个返回成功，那调用便宣告成功，这是一种在关键场景中使用更高的执行成本换取执行时间和成功概率的策略。
- 广播调用（Broadcast）
    广播调用与并行调用是相对应的，都是同时发起多个调用，但并行调用是任何一个调用结果返回成功便宣告成功，广播调用则是要求所有的请求全部都成功，这次调用才算是成功，任何一个服务提供者出现异常都算调用失败，广播调用通常会被用于实现“刷新分布式缓存”这类的操作。

容错设计模式：

- 断路器模式
    断路器本质是一种快速失败策略的实现方式。通过持续监控并统计服务返回的成功、失败、超时、拒绝等各种结果，当出现故障（失败、超时、拒绝）的次数达到断路器的阈值时，它状态就自动变为“OPEN”，后续此断路器代理的远程访问都将直接返回调用失败，而不会发出真正的远程服务请求。

    ![image.png](https://r2.129870.xyz/img/2025/2ed8f894f57593a679eb4d0d5a16ce82.png)

    从调用序列来看，断路器就是一种有限状态机，断路器模式就是根据自身状态变化自动调整代理请求策略的过程。一般要设置以下三种断路器的状态：

    - CLOSED
        断路器关闭，此时的远程请求会真正发送给服务提供者。
    - OPEN
        表示断路器开启，此时不会进行远程请求，直接给服务调用者返回调用失败的信息，以实现快速失败策略。
    - HALF OPEN
        这是一种中间状态，**断路器必须带有自动的故障恢复能力**，当进入 OPEN 状态一段时间以后，将“自动”（一般是由下一次请求而不是计时器触发的，所以这里自动带引号）切换到 HALF OPEN 状态。该状态下，会放行一次远程调用，然后根据这次调用的结果成功与否，转换为 CLOSED 或者 OPEN 状态，以实现断路器的弹性恢复。

    ![image.png](https://r2.129870.xyz/img/2025/59ff1a6b825d5179223e44f76faccf1a.png)

    现实中，比较可行的办法是在以下两个条件同时满足时，断路器状态转变为 OPEN：

    - 请求数达到阈值
        例如一段时间（譬如 10 秒以内）内请求数量达到一定阈值（譬如 20 个请求）
    - 故障率达到阈值
        例如一段时间（譬如 10 秒以内）内请求的故障率（发生失败、超时、拒绝的统计比例）到达一定阈值（譬如 50%）。

    断路器做的事情是自动进行服务熔断，这是一种快速失败的容错策略的实现方法。在快速失败策略明确反馈了故障信息给上游服务以后，**上游服务必须能够主动处理调用失败的后果，而不是坐视故障扩散**，这里的“处理”指的就是一种典型的服务降级逻辑。

- 舱壁隔离模式
    舱壁隔离模式是常用的实现服务隔离的设计模式，舱壁这个词是来自造船业的舶来品，它原本的意思是设计舰船时，要在每个区域设计独立的水密舱室，一旦某个舱室进水，也只是影响这个舱室中的货物，而不至于让整艘舰艇沉没。这种思想就很符合容错策略中失败静默策略。

    ![image.png](https://r2.129870.xyz/img/2025/d9cc9454b2edd440a8a128f6592b33f1.png)

    例如对于分布式系统中依赖的某个服务，为每个服务设置独立的线程池，这些线程池默认不预置活动线程，只用来控制单个服务的最大连接数。此时，当某个服务出现问题时，其他不依赖该服务的用户线程依然能够正常对外提供服务。

    ![image.png](https://r2.129870.xyz/img/2025/917ad537af887b721813c8387983b100.png)

    使用线程池以后会增加资源的消耗，还有一种更轻量的可以用来控制服务最大连接数的办法：信号量机制。可以使用一个单独维护的作为计数器的信号量来控制请求数。

- 重试模式
    故障转移和故障恢复策略都需要对服务进行重复调用，差别是这些重复调用有可能是同步的，也可能是后台异步进行；有可能会重复调用同一个服务，也可能会调用到服务的其他副本。无论具体是通过怎样的方式调用、调用的服务实例是否相同，都可以归结为重试设计模式的应用范畴。

    重试模式适合解决系统中的瞬时故障，有可能自己恢复（Resilient，称为自愈，也叫做回弹性）的临时性失灵。

    判断是否应该且是否能够对一个服务进行重试时，应同时满足以下几个前提条件：

    - 仅在主逻辑的关键服务上进行同步的重试
    - 仅对瞬时故障进行重试
        尽管一个故障是否属于可自愈的瞬时故障并不容易精确判定，但从 HTTP 的状态码上至少可以获得一些初步的结论。
    - 仅针对幂等性的服务进行重试
    - 重试必须有明确的终止条件
        - 超时终止
            并不限于重试，所有调用远程服务都应该要有超时机制避免无限期的等待。
        - 次数终止
            重试必须要有一定限度，不能无限制地做下去。

    由于重试模式可以在网络链路的多个环节中去实现，因此在设定重试前需要尽可能的梳理调用链路上的重试策略，避免在每个节点都配置重试，引起不必要的资源消耗。例如网关、负载均衡器、微服务内部等多个环节都可能发生重试。

#### 6.3.2. 流量控制

一个健壮的系统需要做到恰当的流量控制，更具体地说，需要妥善解决以下三个问题：

- 依据什么限流
    要不要控制流量，要控制哪些流量，控制力度要有多大，等等这些操作都没法在系统设计阶段静态地给出确定的结论，必须根据系统此前一段时间的运行状况，甚至未来一段时间的预测情况来动态决定。
- 具体如何限流
    如何做到允许一部分请求能够通行，而另外一部分流量实行受控制的失败降级。
- 超额流量如何处理
    超额流量可以有不同的处理策略，也许会直接返回失败（如 429 Too Many Requests），或者被迫使它们进入降级逻辑，这种被称为否决式限流。也可能让请求排队等待，暂时阻塞一段时间后继续处理，这种被称为阻塞式限流。

流量统计指标：

- 每秒事务数（Transactions per Second，TPS）
    TPS 是衡量信息系统吞吐量的最终标准。“事务”可以理解为一个逻辑上具备原子性的业务操作。
- 每秒请求数（Hits per Second，HPS）
    HPS 是指每秒从客户端发向服务端的请求数。
- 每秒查询数（Queries per Second，QPS）
    QPS 是指一台服务器能够响应的查询次数。但在分布式系统中，一个请求的响应往往要由后台多个服务节点共同协作来完成，**QPS 关注的是查询操作的累计数量**。

限流设计模式：

- 计数器模式
    设置一个计算器，根据当前时刻的流量计数结果是否超过阈值来决定是否限流。流量计数器的缺陷根源在于它只是针对时间点进行离散的统计。
- 滑动窗口
    滑动时间窗的工作过程：

    1. 将数组最后一位的元素丢弃掉，并把所有元素都后移一位，然后在数组第一个插入一个新的空元素。这个步骤即为“滑动窗口”
    2. 将计数器中所有统计信息写入到第一位的空元素中
    3. 对数组中所有元素进行统计，并复位清空计数器数据供下一个统计周期使用

    ![image.png](https://r2.129870.xyz/img/2025/7eee29e042bb77593dd4508db4d13e15.png)

    滑动时间窗口模式的限流完全解决了流量计数器的缺陷，可以保证任意时间片段内，只需经过简单的调用计数比较，就能控制住请求次数一定不会超过限流的阈值，在单机限流或者分布式服务单点网关中的限流中很常用。

    不过，这种限流也有其缺点，它通常**只适用于否决式限流**，超过阈值的流量就必须强制失败或降级，很难进行阻塞等待处理，也就很难在细粒度上对流量曲线进行整形，起不到削峰填谷的作用。

- 令牌桶
    漏桶在代码实现上非常简单，它其实就是一个以请求对象作为元素的先入先出队列（FIFO Queue），队列长度就相当于漏桶的大小，当队列已满时便拒绝新的请求进入。漏桶实现起来很容易，困难在于如何确定漏桶的两个参数：桶的大小和水的流出速率。
- 漏桶模式
    现实中系统的处理速度往往受到其内部拓扑结构变化和动态伸缩的影响，所以能够支持变动请求处理速率的令牌桶算法往往可能会更受青睐。

    假设要限制系统在 X 秒内最大请求次数不超过 Y，那就每间隔 X/Y 时间就往桶中放一个令牌，当有请求进来时，首先要从桶中取得一个准入的令牌，然后才能进入系统处理。任何时候，一旦请求进入桶中却发现没有令牌可取了，就应该马上失败或进入服务降级逻辑。与漏桶类似，令牌桶同样有最大容量，这意味着当系统比较空闲时，桶中令牌累积到一定程度就不再无限增加，**预存在桶中的令牌便是请求最大缓冲的余量**。

    令牌桶模式的实现看似比较复杂，每间隔固定时间就要放新的令牌到桶中，但其实并不需要真的用一个专用线程或者定时器来做这件事情，只要**在令牌中增加一个时间戳记录，每次获取令牌前，比较一下时间戳与当前时间，就可以轻易计算出这段时间需要放多少令牌进去**，然后一次性放入即可。

能够精细控制分布式集群中每个服务消耗量的限流算法称为分布式限流。分布式限流有两种实现思路：

- 集中共享流量统计信息
    将所有服务的统计结果都存入集中式缓存（如 Redis）中，以实现在集群内的共享，并通过分布式锁、信号量等机制，解决这些数据的读写访问时并发控制的问题。
- 货币化机制
    在令牌桶限流模式基础上进行货币化改造”，即不把令牌看作是只有准入和不准入的“通行证”，而看作数值形式的“货币额度”。当请求进入集群时，首先在 API 网关处领取到一定数额的“货币”，访问每个服务时都要求消耗一定量的“货币”，直至货币消耗为空。

    基于额度的限流方案对限流的精确度有一定的影响，可能存在业务操作已经进行了一部分服务调用，却无法从令牌桶中再获取到新额度，因“资金链断裂”而导致业务操作失败。这种失败的代价是比较高昂的，它**白白浪费了部分已经完成了的服务资源**，但总体来说，它仍是一种并发性能和限流效果上都相对折衷可行的分布式限流方案。

### 6.4. 可观测性

可观测性：事件日志、链路追踪和聚合度量，这三个方向各有侧重，又不是完全独立，它们天然就有重合或者可以结合之处。

![image.png](https://r2.129870.xyz/img/2025/79f31c9cd5e968e5e88c2379eca59efa.png)

#### 6.4.1. 事件日志

从打印日志到分析查询之间，还隔着收集、缓冲、聚合、加工、索引、存储等若干个步骤：

![image.png](https://r2.129870.xyz/img/2025/f878779164ec407bec080e1f4a108e0f.png)

日志输出应避免：

- 避免打印敏感信息
- 避免引用慢操作
- 避免打印追踪诊断信息
    日志中不要打印方法输入参数、输出结果、方法执行时长之类的调试信息，日志的职责是记录事件，追踪诊断应由追踪系统去处理。
- 避免误导他人

应需要包含：

- 处理请求时的 TraceId
- 系统运行过程中的关键事件
- 启动时输出配置信息
    与避免输出诊断信息不同，对于系统启动时或者检测到配置中心变化时更新的配置，应将非敏感的配置信息输出到日志中，譬如连接的数据库、临时目录的路径等等，初始化配置的逻辑一般只会执行一次，不便于诊断时复现，所以应该输出到日志中。

事件日志处理过程：

- 收集与缓冲
    写日志是在服务节点中进行的，但我们不可能在每个节点都单独建设日志查询功能。这不是资源或工作量的问题，而是**分布式系统处理一个请求要跨越多个服务节点**，为了能看到跨节点的全部日志，就要有能覆盖整个链路的全局日志系统。这个需求决定了每个节点输出日志到文件后，必须**将日志文件统一收集起来集中存储、索引**，由此便催生了专门的日志收集器。

    日志收集器不仅要保证能覆盖全部数据来源，还要尽力保证日志数据的连续性，但也不应该为此付出过高成本。换而言之，日志不追求绝对的完整精确，只追求在代价可承受的范围内保证尽可能地保证较高的数据质量。一种最常用的缓解压力的做法是将日志接收者从 Logstash 和 Elasticsearch 转移至抗压能力更强的队列缓存，譬如在 Logstash 之前架设一个 Kafka 或者 Redis 作为缓冲层，面对突发流量，Logstash 或 Elasticsearch 处理能力出现瓶颈时自动削峰填谷，甚至当它们短时间停顿，也不会丢失日志数据。

- 加工与聚合
    将日志集中收集之后，存入 Elasticsearch 之前，一般还要对它们进行加工转换和聚合处理。

    Logstash 的基本职能是把日志行中的非结构化数据，通过 Grok 表达式语法转换为上面表格那样的结构化数据，进行结构化的同时，还可能会根据需要，调用其他插件来完成时间处理（统一时间格式）、类型转换（如字符串、数值的转换）、查询归类（譬如将 IP 地址根据地理信息库按省市归类）等额外处理工作，然后以 JSON 格式输出到 Elasticsearch 中（这是最普遍的输出形式，Logstash 输出也有很多插件可以具体定制不同的格式）。

    聚合也是 Logstash 的另一个常见职能，日志收集后的聚合，一种解决方案是通过 Elasticsearch 本身的处理能力做实时的聚合统计，这很便捷，不过要消耗 Elasticsearch 服务器的运算资源。另一种解决方案是**在收集日志后自动生成某些常用的、固定的聚合指标**，这种聚合就会在 Logstash 中通过聚合插件来完成。这两种聚合方式都有不少实际应用，前者一般用于应对即席查询，后者用于应对固定查询。

- 存储与查询
     Elasticsearch 在日志分析这方面完全没有什么值得一提的竞争者，日志数据的特征如下：
     
     - 典型的基于时间的数据流
         日志的数据特征决定了所有用于日志分析的 Elasticsearch 都会使用时间范围作为索引。以时间为维度进行索引，可以预先的创建索引避免动态创建导致的寻找节点、创建分片、在集群中广播变动信息等开销。
     - 数据价值呈时间性
        日志基本以最近日期的数据为检索目标，这点决定了很容易区分冷数据和热数据。
    - 分析日志是近实时性需求，不要求完全写后立刻被查询

#### 6.4.2. 链路追踪

广义上讲，一个完整的分布式追踪系统应该由数据收集、数据存储和数据展示三个相对独立的子系统构成，而狭义上讲的追踪则就只是特指链路追踪数据的收集部分。

由于每次 Trace 都可能会调用数量不定、坐标不定的多个服务，为了能够记录具体调用了哪些服务，以及调用的顺序、开始时点、执行时长等信息，每次开始调用服务前都要先埋入一个调用记录，这个记录称为一个“跨度”（Span）。

![image.png](https://r2.129870.xyz/img/2025/406b6c15cc41bbf072ea5402098735ac.png)

追踪系统在功能性和非功能性上都有不小的挑战。功能上的挑战来源于服务的异构性，**各个服务可能采用不同程序语言，服务间交互可能采用不同的网络协议**。而非功能性的挑战具体就来源于以下这四个方面：

- 低性能损耗
- 对应用透明
- 随应用扩缩
- 持续的监控

目前，追踪系统根据数据收集方式的差异，可分为三种主流的实现方式：

- 基于日志的追踪
    将 Trace、Span 等信息直接输出到应用日志中，然后随着所有节点的日志归集过程汇聚到一起，再从全局日志信息中反推出完整的调用链拓扑关系。

    优点：

    - 侵入性小
    - 性能影响低

    缺点：

    - 依赖于日志收集过程，精准性不足
    - 日志与追踪不同步
        业务服务的调用与日志的归集并不是同时完成的，也通常不由同一个进程完成，有可能发生业务调用已经顺利结束了，但由于日志归集不及时或者精度丢失，导致日志出现延迟或缺失记录，进而产生追踪失真。
- 基于服务的追踪
    基于服务的追踪是目前最为常见的追踪实现方式，通过某些手段给目标应用注入追踪探针（Probe），针对 Java 应用一般就是通过 Java Agent 注入的。探针在结构上可视为一个寄生在目标服务身上的小型微服务系统，它一般会有自己专用的服务注册、心跳检测等功能，有专门的数据收集协议，把从目标系统中监控得到的服务调用信息，通过另一次独立的 HTTP 或者 RPC 请求发送给追踪系统。

    基于服务的追踪会比基于日志的追踪消耗更多的资源，也有更强的侵入性，换来的收益是追踪的精确性与稳定性都有所保证，不必再依靠日志归集来传输追踪数据。

- 基于边车代理的追踪
    基于边车代理的追踪是服务网格的专属方案，也是最理想的分布式追踪模型，它对应用完全透明，无论是日志还是服务本身都不会有任何变化；它与程序语言无关，无论应用采用什么编程语言实现，只要它还是通过网络（HTTP 或者 gRPC）来访问服务就可以被追踪到；它有自己独立的数据通道，追踪数据通过控制平面进行上报，避免了追踪对程序通信或者日志归集的依赖和干扰，保证了最佳的精确性。

    边车代理本身的对应用透明的工作原理决定了它只能实现服务调用层面的追踪。

#### 6.4.3. 聚合度量

度量是用经过聚合统计后的高维度信息，度量总体上可分为客户端的指标收集、服务端的存储查询以及终端的监控预警三个相对独立的过程。

- 指标收集
    指标收集部分要解决两个问题：如何定义指标”以及“如何将这些指标告诉服务端。确定目标系统前我们无法决定要收集什么指标，但指标的数据类型（Metrics Types）是可数的，所有通用的度量系统都是面向指标的数据类型来设计的：
    
    - 计数度量器（Counter）
    - 瞬态度量器（Gauge）
    - 吞吐率度量器（Meter）
    - 直方图度量器（Histogram）
    - 采样点分位图度量器（Quantile Summary）
    - Timer、Set、Fast Compass、Cluster Histogram 等其他各种度量器

    对于“如何将这些指标告诉服务端”这个问题，通常有两种解决方案：拉取式采集（Pull-Based Metrics Collection）和推送式采集（Push-Based Metrics Collection）。

    一般来说，度量系统只会支持其中一种指标采集方式，因为度量系统的网络连接数量，以及对应的线程或者协程数可能非常庞大，如何采集指标将直接影响到整个度量系统的架构设计。Prometheus 基于 Pull 架构的同时还能够有限度地兼容 Push 式采集，是因为它有 Push Gateway 的存在。

    ![image.png](https://r2.129870.xyz/img/2025/aa3156287aba11a3f4ba41ff01a28c1a.png)

    Prometheus 设计 Push Gateway 的本意是**为了解决 Pull 的一些固有缺陷**，譬如目标系统位于内网，通过 NAT 访问外网，外网的 Prometheus 是无法主动连接目标系统的，这就只能由目标系统主动推送数据；又譬如某些小型短生命周期服务，可能还等不及 Prometheus 来拉取，服务就已经结束运行了，因此也只能由服务自己 Push 来保证度量的及时和准确。

- 存储查询
    存储通常基于时序数据库完成，写操作，时序数据通常只是追加，很少删改或者根本不允许删改。针对数据热点只集中在近期数据、多写少读、几乎不删改、数据只顺序追加这些特点，时序数据库被允许做出很激进的存储、访问和保留策略（Retention Policies）：
    
    - 以日志结构的合并树（Log Structured Merge Tree，LSM-Tree）代替传统关系型数据库中的 B+Tree 作为存储结构
    - 设置激进的数据保留策略，譬如根据过期时间（TTL）自动删除相关数据以节省存储空间，同时提高查询性能
    - 对数据进行再采样（Resampling）以节省空间

    时序数据库中甚至还有一种并不罕见却更加极端的形式，叫作轮替型数据库（Round Robin Database，RRD），以环形缓冲（在“服务端缓存”一节介绍过）的思路实现，只能存储固定数量的最新数据，超期或超过容量的数据就会被轮替覆盖，因此也有着固定的数据库容量，却能接受无限量的数据输入。

- 监控预警
    指标度量是手段，最终目的是做分析和预警。

## 7. 从微服务到云原生

### 7.1. 虚拟化容器

容器的首要目标是让软件分发部署过程从传统的发布安装包、靠人工部署转变为直接发布已经部署好的、包含整套运行环境的虚拟化镜像。

#### 7.1.1. 容器技术

##### 7.1.1.1. 虚拟化技术

一个计算机软件要能够正确运行，需要有以下三方面的兼容性来共同保障：

- ISA 兼容
    目标机器指令集兼容性，譬如 ARM 架构的计算机无法直接运行面向 x86 架构编译的程序。
- ABI 兼容
    目标系统或者依赖库的二进制兼容性，譬如 Windows 系统环境中无法直接运行 Linux 的程序，又譬如 DirectX 12 的游戏无法运行在 DirectX 9 之上。
- 环境兼容
    目标环境的兼容性，譬如没有正确设置的配置文件、环境变量、文件系统的权限等等。

> [!info] ISA 与 ABI
> 指令集架构（Instruction Set Architecture，ISA）是计算机体系结构中与程序设计有关的部分，包含了基本数据类型，指令集，寄存器，寻址模式，存储体系，中断，异常处理以及外部 I/O。指令集架构包含一系列的 Opcode 操作码（即通常所说的机器语言），以及由特定处理器执行的基本命令。
> 
> 应用二进制接口（Application Binary Interface，ABI）是应用程序与操作系统之间或其他依赖库之间的低级接口。ABI 不同于应用程序接口（Application Programming Interface，API），API 定义的是源代码和库之间的接口，因此同样的代码可以在支持这个 API 的任何系统中编译，而 ABI 允许编译好的目标代码在使用兼容 ABI 的系统中无需改动就能直接运行。

根据抽象目标与兼容性高低的不同，虚拟化技术又分为下列五类：

- 指令集虚拟化（ISA Level Virtualization）
    通过软件来模拟不同 ISA 架构的处理器工作过程，将虚拟机发出的指令转换为符合本机 ISA 的指令，代表为 QEMU 和 Bochs。

    指令集虚拟化就是仿真，能提供了几乎完全不受局限的兼容性，甚至能做到直接在 Web 浏览器上运行完整操作系统这种令人惊讶的效果，但由于每条指令都要由软件来转换和模拟，它也是性能损失最大的虚拟化技术。

- 硬件抽象层虚拟化（Hardware Abstraction Level Virtualization）
    以软件或者直接通过硬件来模拟处理器、芯片组、内存、磁盘控制器、显卡等设备的工作过程。常说的“虚拟机”就是指这一类虚拟化技术。
- 操作系统层虚拟化（OS Level Virtualization）
    无论是指令集虚拟化还是硬件抽象层虚拟化，都会运行一套完全真实的操作系统来解决 ABI 兼容性和环境兼容性问题。而操作系统层虚拟化则不会提供真实的操作系统，而是采用隔离手段，使得不同进程拥有独立的系统资源和资源配额，看起来仿佛是独享了整个操作系统一般，其实系统的内核仍然是被不同进程所共享的。

    操作系统层虚拟化的另一个名字就是“容器化”（Containerization），由此可见，**容器化仅仅是虚拟化的一个子集，只能提供操作系统内核以上的部分 ABI 兼容性与完整的环境兼容性**。这意味着如果没有其他虚拟化手段的辅助，在 Windows 系统上是不可能运行 Linux 的 Docker 镜像的（现在可以，是因为有其他虚拟机或者 WSL2 的支持），反之亦然。也同样决定了如果 Docker 宿主机的内核版本是 Linux Kernel 5.6，那无论上面运行的镜像是 Ubuntu、RHEL、Fedora、Mint 或者任何发行版的镜像，看到的内核一定都是相同的 Linux Kernel 5.6。容器化牺牲了一定的隔离性与兼容性，换来的是比前两种虚拟化更高的启动速度、运行性能和更低的执行负担。

- 运行库虚拟化（Library Level Virtualization）
    运行库虚拟化选择使用软件翻译的方法来模拟系统，它**以一个独立进程来代替操作系统内核来提供目标软件运行所需的全部能力**，这种虚拟化方法获得的 ABI 兼容性高低，取决于软件是否能足够准确和全面地完成翻译工作，其代表为 WINE（Wine Is Not an Emulator 的缩写，一款在 Linux 下运行 Windows 程序的软件）和 WSL（特指 Windows Subsystem for Linux Version 1）。
- 语言层虚拟化（Programming Language Level Virtualization）
    由虚拟机将高级语言生成的中间代码转换为目标机器可以直接执行的指令。

##### 7.1.1.2. 容器的崛起

容器的最初的目的不是为了部署软件，而是为了隔离计算机中的各类资源，以便降低软件开发、测试阶段可能产生的误操作风险，或者专门充当蜜罐。

隔离的不同实现阶段如下：

1. 隔离文件：chroot
    经过 chroot 操作之后，它的根目录就会被锁定在命令参数所指定的位置，以后它或者它的子进程将不能再访问和操作该目录之外的其他文件。

    原本按照 UNIX 的设计哲学，一切资源都可以视为文件（In UNIX，Everything is a File），一切处理都可以视为对文件的操作，理论上，只要隔离了文件系统，一切资源都应该被自动隔离才对。可是从硬件层面暴露的低层次资源，如磁盘、网络、内存、处理器，到经操作系统层面封装的高层次资源，如 UNIX 分时（UNIX Time-Sharing，UTS）、进程 ID（Process ID，PID）、用户 ID（User ID，UID）、进程间通信（Inter-Process Communication，IPC）都存在大量以非文件形式暴露的操作入口，因此，以 chroot 为代表的文件隔离，仅仅是容器崛起之路的起点而已。

2. 隔离访问：namespaces
    Linux 名称空间（Linux Namespaces），一种由内核直接提供的全局资源封装，是**内核针对进程设计的访问隔离机制**。不仅文件系统是独立的，还有着独立的 PID 编号（譬如拥有自己的 0 号进程，即系统初始化的进程）、UID/GID 编号（譬如拥有自己独立的 root 用户）、网络（譬如完全独立的 IP 地址、网络栈、防火墙等设置），等等。

    Linux 名称空间支持以下八种资源的隔离：

    ![image.png](https://r2.129870.xyz/img/2025/491d37c1a6fbe7c81a74a45ee4d536a3.png)

3. 隔离资源：cgroups
    如果要让一台物理计算机中的各个进程看起来像独享整台虚拟计算机的话，不仅要隔离各自进程的访问操作，还必须能**独立控制分配给各个进程的资源使用配额**。

    Linux 系统解决以上问题的方案是控制群组（Control Groups，目前常用的简写为 cgroups），它与名称空间一样都是直接由内核提供的功能，用于隔离或者说分配并限制某个进程组能够使用的资源配额，资源配额包括处理器时间、内存大小、磁盘 I/O 速度，等等。

    ![image.png](https://r2.129870.xyz/img/2025/1d26829084c307e0aeadf35780cf790f.png)

4. 封装系统：LXC
    Linux 容器（LinuX Containers，LXC）的系统级虚拟化功能，LXC 中的容器的定义是一种封装系统的轻量级虚拟机。

    以封装系统为出发点，仍是按照先装系统然再装软件的思路，就永远无法做到一两分钟甚至十几秒钟就构造出一个合乎要求的软件运行环境，也决定了 LXC 不可能形成今天的容器生态的。

5. 封装应用：docker
    Docker 除了包装来自 Linux 内核的特性之外，它的价值还在于：
    
    - 跨机器的绿色部署
        Docker 定义了一种**将应用及其所有的环境依赖都打包到一起的格式**，而 LXC 并没有提供这样的能力，使用 LXC 部署的新机器很多细节都依赖人的介入。
    - 以应用为中心的封装
        Docker **封装应用而非封装机器**的理念贯穿了它的设计、API、界面、文档等多个方面。
    - 自动构建
        Docker 提供了开发人员从在容器中构建产品的全部支持，开发人员无需关注目标机器的具体配置，即可使用任意的构建工具链，在容器中自动构建出最终产品。
    - 多版本支持
        支持像 Git 一样管理容器的连续版本，进行检查版本间差异、提交或者回滚等操作。从历史记录中你可以查看到该容器是如何一步一步构建成的，并且只增量上传或下载新版本中变更的部分。
    - 组件重用
        允许将任何现有容器作为基础镜像来使用，以此构建出更加专业的镜像。
    - 共享
        拥有公共的镜像仓库。
    - 工具生态
        开放了一套可自动化和自行扩展的接口，在此之上，还有很多工具来扩展其功能，譬如容器编排、管理界面、持续集成等等。

    2014 年，Docker 开源了自己用 Golang 开发的 libcontainer，这是一个越过 LXC 直接操作 namespaces 和 cgroups 的核心模块，有了 libcontainer 以后，Docker 就能直接与系统内核打交道，不必依赖 LXC 来提供容器化隔离能力了。

    2015 年，多家公司联合制定了“开放容器交互标准”（Open Container Initiative，OCI）：

    - 运行时标准（runtime-spec ）
        运行时标准定义了应该如何运行一个容器、如何管理容器的状态和生命周期、如何使用操作系统的底层特性（namespaces、cgroup、pivot_root 等）。
    - 容器镜像标准（image-spec）
        容器镜像标准规定了容器镜像的格式、配置、元数据的格式，可以理解为对镜像的静态描述。
    - 镜像分发标准（distribution-spec，分发标准还未正式发布）
        镜像分发标准则规定了镜像推送和拉取的网络交互过程。

    为了符合 OCI 标准，Docker 首先将 libcontainer 独立出来，封装重构成 runC 项目，runC 是 OCI Runtime 的首个参考实现。

    为了能够兼容所有符合标准的 OCI Runtime 实现，Docker 进一步重构了 Docker Daemon 子系统，将其中与运行时交互的部分抽象为 containerd 项目，这是一个负责**管理容器执行、分发、监控、网络、构建、日志等功能的核心模块**，内部会为每个容器运行时创建一个 containerd-shim 适配进程，默认与 runC 搭配工作。

    ![image.png](https://r2.129870.xyz/img/2025/5fed1b2e53b5976c91f785d87422a3bd.png)

6. 封装集群
    如果说以 Docker 为代表的容器引擎**将软件的发布流程从分发二进制安装包转变为直接分发虚拟化后的整个运行环境**，令应用得以实现跨机器的绿色部署；那以 Kubernetes 为代表的容器编排框架，就是**把大型软件系统运行所依赖的集群环境也进行了虚拟化，令集群得以实现跨数据中心的绿色部署，并能够根据实际情况自动扩缩**。

    ![image.png](https://r2.129870.xyz/img/2025/0fc023308fe861088cc0714d19e06f3c.png)

    kubernetes 的演进史：

    - 阶段一：蜜月期与紧密耦合（K8s 1.5 之前）
        Kubelet 内部有一个专门的 `DockerManager`，通过 HTTP API 直接与 Docker Engine 通信，命令 Docker 去创建、启动、停止容器。
    - 阶段二：解耦的序幕 —— CRI 与 Shim（K8s 1.5 - K8s 1.10）
        Kubernetes 引入了 **CRI（容器运行时接口）** ，这是一个基于 gRPC 的标准规范。由于 Docker 本身不支持 CRI，社区开发了一个“适配器”—— DockerShim，它负责将 CRI 的 gRPC 调用翻译成 Docker Engine 能听懂的 HTTP API 调用。

        CRI 的诞生是整个演进的转折点。它将 Kubelet 与具体的容器运行时解耦，Kubelet 只关心“CRI 接口”，不再关心“谁来实现这个接口”。

    - 阶段三：原生竞争者的出现（2017 年至今）
        CRI-O: 由 Red Hat, Google 等公司主导，是一个轻量级的、专门为 Kubernetes 而生的 CRI 标准原生实现。它不包含 Docker Engine 那些额外的功能（如镜像构建），目标纯粹且高效。

        Docker 公司将 containerd 捐献给 CNCF 后，社区为其增加了对 CRI 的原生支持（cri-containerd 插件内置）。这意味着 Kubernetes 可以绕过 Docker Engine 和 DockerShim，直接与 containerd 对话。

    - 新时代的标准与未来（K8s 1.24 至今）
        Kubernetes 社区在 v1.24 版本中正式移除了 Kubelet 内置的 DockerShim。这意味着 Kubernetes 不再原生支持通过 Docker Engine 来运行容器。

#### 7.1.2. 以容器构建系统

##### 7.1.2.1. 隔离与协作

单体时代过去之后，分布式系统里应用的概念已不再等同于进程，此时的应用需要多个进程共同协作，通过集群的形式对外提供服务，以虚拟化方法实现这个目标的过程就被称为容器编排（Container Orchestration）。

容器之间顺畅地交互通信是协作的核心需求，但容器协作并不仅仅是将容器以高速网络互相连接而已。**如何调度容器，如何分配资源，如何扩缩规模，如何最大限度地接管系统中的非功能特性，让业务系统尽可能免受分布式复杂性的困扰都是容器编排框架必须考虑的问题**。

不能简单的在 docker 容器中直接启动多个应用，Docker 只能通过监视 PID 为 1 的进程（即由 ENTRYPOINT 启动的进程）的运行状态来判断容器的工作状态是否正常，容器退出执行清理，容器崩溃自动重启等操作都必须先判断状态。即使我们使用了 supervisord 之类的进程控制器来解决同时启动多个进程的问题，如果因某种原因它们不停发生崩溃、重启，那 Docker 也无法察觉到，它只能观察到 supervisord 的运行状态，不能完全的监控到容器内的运行情况。

容器不仅可以共享文件系统，同时还能进行 IPC 名称空间的共享以及 UTS 名称空间的共享等，提供了 `--ipc` 参数和 `--uts` 参数以及 `--net` 参数等就能实现，这的确可以工作，却并不够优雅，也谈不上有什么扩展性。

容器的本质是对 cgroups 和 namespaces 所提供的隔离能力的一种封装，在 Docker 提倡的单进程封装的理念影响下，容器蕴含的隔离性也多了仅针对于单个进程的额外局限，然而 Linux 的 cgroups 和 namespaces 原本都是针对进程组而不仅仅是单个进程来设计的，**同一个进程组中的多个进程天然就可以共享着相同的访问权限与资源配额**。如果现在我们把容器与进程在概念上对应起来，那容器编排的第一个扩展点，就是要找到容器领域中与“进程组”相对应的概念，这是实现容器从隔离到协作的第一步，在 Kubernetes 的设计里，这个对应物叫作 Pod。

扮演容器组的角色，**满足容器共享名称空间的需求**，是 Pod 的两大最基本职责之一，同处于一个 Pod 内的多个容器，相互之间以超亲密的方式协作。

对于普通非亲密的容器，它们一般以网络交互方式（其他譬如共享分布式存储来交换信息也算跨网络）协作；对亲密协作的容器，是指它们被调度到同一个集群节点上，可以通过共享本地磁盘等方式协作；而超亲密的协作是特指多个容器位于同一个 Pod 这种特殊关系，它们将默认共享：

- UTS 名称空间：所有容器都有相同的主机名和域名
- 网络名称空间：所有容器都共享一样的网卡、网络栈、IP 地址，等等。因此，同一个 Pod 中不同容器占用的端口不能冲突
- IPC 名称空间：所有容器都可以通过信号量或者 POSIX 共享内存等方式通信
- 时间名称空间：所有容器都共享相同的系统时间

> [!info] 共享的实现
> Pod 内部多个容器共享 UTS、IPC、网络等名称空间是通过一个名为 Infra Container 的容器来实现的，这个容器是整个 Pod 中第一个启动的容器，只有几百 KB 大小（代码只有很短的几十行，见这里），Pod 中的其他容器都会以 Infra Container 作为父容器，UTS、IPC、网络等名称空间实质上都是来自 Infra Container 容器。

同一个 Pod 的容器，只有 PID 名称空间和文件名称空间默认是隔离的。PID 的隔离令每个容器都有独立的进程 ID 编号，它们封装的应用进程就是 PID 为 1 的进程，可以通过 Pod 元数据定义中的 `spec.shareProcessNamespace` 来改变这点。

Pod 的另外一个基本职责是实现原子性调度，如果容器编排不跨越集群节点，是否具有原子性都无关紧要。但是在集群环境中，容器可能跨机器调度时，这个特性就变得非常重要。协同调度是十分麻烦的，但是如果将运行资源的需求声明定义在 Pod 上，直接以 Pod 为最小的原子单位来实现调度的话，由于多个 Pod 之间必定不存在超亲密的协同关系，只会通过网络非亲密地协作，那就根本没有协同的说法，自然也不需要考虑复杂的调度了。

Pod 是隔离与调度的基本单位，**Kubernetes 将一切皆视为资源，不同资源之间依靠层级关系相互组合协作**，这个思想是贯穿 Kubernetes 整个系统的两大核心设计理念之一，不仅在容器、Pod、主机、集群等计算资源上是这样，在工作负载、持久存储、网络策略、身份权限等其他领域中也都有着一致的体现。

![image.png](https://r2.129870.xyz/img/2025/9270e2c9de7176439a150a7dddfc6955.png)

##### 7.1.2.2. 韧性与弹性

无论是软件缺陷、意外操作或者硬件故障，都可能导致在复杂协作的过程中某个容器出现异常，进而出现系统性的崩溃。 Kubernetes 通过**控制器设计模式**来实现具有韧性与弹性的系统。

控制回路的思想迁移应用到容器编排上，为 Kubernetes 中的资源附加上了期望状态与实际状态两项属性。不论是用于抽象容器运行环境的计算资源，还是安全、服务、令牌、网络等功能的资源，用户要想使用这些资源来实现某种需求，并不提倡像平常编程那样去调用某个或某一组方法来达成目的，而是通过描述清楚这些资源的期望状态，**由 Kubernetes 中对应监视这些资源的控制器来驱动资源的实际状态逐渐向期望状态靠拢**，以此来达成目的。

![image.png](https://r2.129870.xyz/img/2025/db35b1b919a1ff757f1e6ac53683c980.png)

与资源相对应，只要是实际状态有可能发生变化的资源对象，通常都会由对应的控制器进行追踪，每个控制器至少会追踪一种类型的资源。为了管理众多资源控制器，Kubernetes 设计了统一的控制器管理框架（kube-controller-manager）来维护这些控制器的正常运作，以及统一的指标监视器（kube-apiserver）来为控制器工作时提供其追踪资源的度量数据。

以副本集、滚动更新和动态扩缩容为例：

- 副本集（ReplicaSet）
    副本集是属于工作负荷一类的资源，它代表一个或多个 Pod 副本的集合。当 ReplicaSet 成功创建之后，确保任何时候集群中这个 Pod 副本的数量都向期望状态靠拢。
- 滚动更新
    ![image.png](https://r2.129870.xyz/img/2025/bf862c47b2948a23e95139866e0bfd22.png)
    部署资源（Deployment）与部署控制器，当更新 Deployment 中的信息（譬如更新了镜像的版本）以后，部署控制器就会跟踪到你新的期望状态，自动地创建新 ReplicaSet，并逐渐缩减旧的 ReplicaSet 的副本数，直至升级完成后彻底删除掉旧 ReplicaSet。
- Autoscaling 资源和自动扩缩控制器
    自动根据度量指标，如处理器、内存占用率、用户自定义的度量值等，来设置 Deployment（或者 ReplicaSet）的期望状态，实现当度量指标出现变化时，系统自动按照“Autoscaling→Deployment→ReplicaSet→Pod”这样的顺序层层变更，最终实现根据度量指标自动扩容缩容。

#### 7.1.3. 以应用为中心的封装

Kubernetes 被誉为云原生时代的操作系统，自诞生之日起就因其出色的管理能力、扩展性与以声明代替命令的交互理念收获了无数喝彩声；但从易用角度讲，云原生基础设施的其中一个重要目标是**接管掉业务系统复杂的非功能特性，让业务研发与运维工作变得足够简单，不受分布式的牵绊**，然而 Kubernetes 被诟病得最多的就是复杂，自诞生之日起就以陡峭的学习曲线而闻名。

复杂性的根本原因：

- 分布式架构的原罪：本质复杂性无法消除
- 缺乏应用级封装：只有服务级（Docker 镜像）和集群级（K8s 资源），缺少应用整体封装
- 角色关注点混杂：开发、运维、平台人员的需求都堆叠在同一配置文件中

### 7.2. 容器间网络

虚拟化网络：基于 Linux 系统的网络虚拟化技术，为了相互隔离的 Linux 网络名称空间可相互通信而设计出来的虚拟化网络设施。

#### 7.2.1. Linux 网络虚拟化

##### 7.2.1.1. 干预网络通信

从 Linux Kernel 2.4 版开始，内核开放了一套通用的、可供代码干预数据在协议栈中流转的过滤器框架。这套名为 Netfilter 的框架围绕网络层（IP 协议）的周围，埋下了五个钩子（Hooks），每当有数据包流到网络层，经过这些钩子时，就会自动触发由内核模块注册在这里的回调函数，程序代码就能够通过回调来干预 Linux 的网络通信：

- PREROUTING
    **来自设备的数据包进入协议栈后立即触发此钩子**。PREROUTING 钩子在进入 IP 路由之前触发，这意味着只要接收到的数据包，无论是否真的发往本机，都会触发此钩子。一般用于目标网络地址转换（Destination NAT，DNAT）。
- INPUT
    报文经过 IP 路由后，如果确定是发往本机的，将会触发此钩子，一般用于加工发往本地进程的数据包。
- FORWOARD
    报文经过 IP 路由后，如果确定不是发往本机的，将会触发此钩子，一般用于处理转发到其他机器的数据包。
- OUTPUT
    从本机程序发出的数据包，在经过 IP 路由前，将会触发此钩子，一般用于加工本地进程的输出数据包。
- POSTROUTING
    从本机网卡出去的数据包，无论是本机的程序所发出的，还是由本机转发给其他机器的，都会触发此钩子，一般用于源网络地址转换（Source NAT，SNAT）。

![image.png](https://r2.129870.xyz/img/2025/ccc63aacf405d9c17ee4e64e14beb396.png)

Netfilter 允许在同一个钩子处注册多个回调函数，向钩子注册回调函数时必须提供明确的优先级，以便触发时能按照优先级从高到低进行激活，钩子触发的回调函数集合就被称为“回调链”（Chained Callbacks）。Linux 系统提供的许多网络能力，如数据包过滤、封包处理（设置标志位、修改 TTL 等）、地址伪装、网络地址转换、透明代理、访问控制、基于协议类型的连接跟踪，带宽限速，等等，都是在 Netfilter 基础之上实现的。

以 Netfilter 为基础的应用有很多，譬如 iptables、ebtables、arptables、ip6tables 等等。iptables 比较贴切的定位应是能够代替 Netfilter 多数常规功能的 IP 包过滤工具。iptables 把用户常用的管理意图总结成具体的行为预先准备好，然后在满足条件时自动激活行为。以下列出了部分 iptables 预置的行为：

- DROP：直接将数据包丢弃
- REJECT：给客户端返回 Connection Refused 或 Destination Unreachable 报文
- QUEUE：将数据包放入用户空间的队列，供用户空间的程序处理
- RETURN：跳出当前链，该链里后续的规则不再执行
- ACCEPT：同意数据包通过，继续执行后续的规则
- JUMP：跳转到其他用户自定义的链继续执行
- REDIRECT：在本机做端口映射
- MASQUERADE：地址伪装，自动用修改源或目标的 IP 地址来做 NAT
- LOG：在/var/log/messages 文件中记录日志信息

iptables 内置了五张不可扩展的规则表：

1. raw 表：用于去除数据包上的连接追踪机制（Connection Tracking）
2. mangle 表：用于修改数据包的报文头信息，如服务类型（Type Of Service，ToS）、生存周期（Time to Live，TTL）以及为数据包设置 Mark 标记，典型的应用是链路的服务质量管理（Quality Of Service，QoS）
3. nat 表：用于修改数据包的源或者目的地址等信息，典型的应用是网络地址转换（Network Address Translation）
4. filter 表：用于对数据包进行过滤，控制到达某条链上的数据包是继续放行、直接丢弃或拒绝（ACCEPT、DROP、REJECT），典型的应用是防火墙
5. security 表：用于在数据包上应用 SELinux，这张表并不常用

ptables 不仅仅是 Linux 系统自带的一个网络工具，它在容器间通信中扮演相当重要的角色，譬如 Kubernetes 用来管理 Service 的 Endpoints 的核心组件 kube-proxy，就依赖 iptables 来完成 ClusterIP 到 Pod 的通信（也可以采用 IPVS，IPVS 同样是基于 Netfilter 的），这种通信的本质就是一种 NAT 访问。

##### 7.2.1.2. 虚拟化网络设备

###### 7.2.1.2.1. 网卡：tun/tap、veth

目前主流的虚拟网卡方案有 tun/tap 和 veth 两种：

- tun/tap
    tun 和 tap 是两个相对独立的虚拟网络设备，其中 tap 模拟了以太网设备，操作二层数据包（以太帧），tun 则模拟了网络层设备，操作三层数据包（IP 报文）。**使用 tun/tap 设备的目的是实现把来自协议栈的数据包先交由某个打开了 `/dev/net/tun` 字符设备的用户进程处理后，再把数据包重新发回到链路中**。

    只要协议栈中的数据包能被用户态程序截获并加工处理，就有足够的舞台空间去玩出各种花样，譬如数据压缩、流量加密、透明代理等功能都能够以此为基础来实现，以最典型的 VPN 应用程序为例，程序发送给 tun 设备的数据包，会经过以下顺序流进 VPN 程序：

    ![image.png](https://r2.129870.xyz/img/2025/9c5e329bf8885f0fed025f16419a92b6.png)

    **使用 tun/tap 设备传输数据需要经过两次协议栈，不可避免地会有一定的性能损耗**，如果条件允许，容器对容器的直接通信并不会把 tun/tap 作为首选方案，一般是基于稍后介绍的 veth 来实现的。但是 tun/tap 没有 veth 那样要求设备成对出现、数据要原样传输的限制，数据包到用户态程序后，程序员就有完全掌控的权力，要进行哪些修改，要发送到什么地方，都可以编写代码去实现，因此 tun/tap 方案比起 veth 方案有更广泛的适用范围。
- veth
    veth 实际上不是一个设备，而是一对设备，因而也常被称作 veth pair。要使用 veth，必须在两个独立的网络名称空间中进行才有意义，因为 **veth pair 是一端连着协议栈，另一端彼此相连的**，在 veth 设备的其中一端输入数据，这些数据就会从设备的另外一端原样不变地流出：

    ![image.png](https://r2.129870.xyz/img/2025/e4eb216337bfa6a7ed13df0aa13afd71.png)

    由于两个容器之间采用 veth 通信不需要反复多次经过网络协议栈，这让 veth 比起 tap/tun 具有更好的性能，也让 veth pair 的实现变的十分简单。veth 以模拟网卡直连的方式很好地解决了两个容器之间的通信问题，然而对多个容器间通信，如果仍然单纯只用 veth pair 的话，事情就会变得非常麻烦，**让每个容器都为与它通信的其他容器建立一对专用的 veth pair 并不实际**，这时就迫切需要有一台虚拟化的交换机来解决多容器之间的通信问题了。

###### 7.2.1.2.2. 交换机：Linux Bridge

有了虚拟网卡，很自然也会联想到让网卡接入到交换机里，实现多个容器间的相互连接。Linux Bridge 便是 Linux 系统下的虚拟化交换机。

Linux Bridge 创建以后，便能够接入任何位于二层的网络设备，无论是真实的物理设备（譬如 eth0）抑或是虚拟的设备（譬如 veth 或者 tap）都能与 Linux Bridge 配合工作。当有二层数据包（以太帧）从网卡进入 Linux Bridge，它将根据数据包的类型和目标 MAC 地址，按如下规则转发处理：

- 如果数据包是广播帧，转发给所有接入网桥的设备
- 如果数据包是单播帧
    - MAC 地址在地址转发表中不存在
        则洪泛（Flooding）给所有接入网桥的设备，并将响应设备的接口与 MAC 地址学习（MAC Learning）到自己的 MAC 地址转发表中。
    - MAC 地址在地址转发表中已存在，则直接转发到地址表中指定的设备
- 数据包是此前转发过的，又重新发回到此 Bridge，说明冗余链路产生了环路
    由于以太帧不像 IP 报文那样有 TTL 来约束，因此一旦出现环路，如果没有额外措施来处理的话就会永不停歇地转发下去。对于这种数据包就需要交换机实现生成树协议（Spanning Tree Protocol，STP）来交换拓扑信息，生成唯一拓扑链路以切断环路。

与普通的物理交换机有所区别，普通交换机只会单纯地做二层转发，Linux Bridge 却还支持把发给它自身的数据包接入到主机的三层的协议栈中。

对于通过 brctl 命令显式接入网桥的设备，Linux Bridge 与物理交换机的转发行为是完全一致的，也不允许给接入的设备设置 IP 地址，因为网桥是根据 MAC 地址做二层转发的，就算设置了三层的 IP 地址也毫无意义。

Linux Bridge 与普通交换机的区别是除了显式接入的设备外，它自己也无可分割地连接着一台有着完整网络协议栈的 Linux 主机，因为 Linux Bridge 本身肯定是在某台 Linux 主机上创建的，可以看作 Linux Bridge 有一个与自己名字相同的隐藏端口，隐式地连接了创建它的那台 Linux 主机。因此，**Linux Bridge 允许给自己设置 IP 地址**，比普通交换机多出一种特殊的转发情况：如果数据包的目的 MAC 地址为网桥本身，并且网桥有设置了 IP 地址的话，那该数据包即**被认为是收到发往创建网桥那台主机的数据包，此数据包将不会转发到任何设备，而是直接交给上层（三层）协议栈去处理**。此时，网桥就取代了 eth0 设备来对接协议栈，进行三层协议的处理。设置这条特殊转发规则的好处是：**只要通过简单的 NAT 转换，就可以实现一个最原始的单 IP 容器网络**。这种组网是最基本的容器间通信形式。

![image.png](https://r2.129870.xyz/img/2025/9575a58a7a41eea1650de4314389b110.png)

###### 7.2.1.2.3. 网络：VXLAN

VLAN“虚拟局域网”（Virtual Local Area Network），由于二层网络本身的工作特性决定了它非常依赖于广播，无论是广播帧（如 ARP 请求、DHCP、RIP 都会产生广播帧），还是泛洪路由，其执行成本都随着接入二层网络设备数量的增长而等比例增加，当**设备太多，广播又频繁的时候，很容易就会形成广播风暴（Broadcast Radiation）**。因此，VLAN 的首要职责就是划分广播域，将连接在同一个物理网络上的设备区分开来，划分的具体方法是在以太帧的报文头中加入 VLAN Tag，让所有广播只针对具有相同 VLAN Tag 的设备生效。这样既缩小了广播域，也附带提高了安全性和可管理性，因为两个 VLAN 之间不能直接通信。如果确有通信的需要，就必须通过三层设备来进行，（Router on a Stick）或者三层交换机。

VLAN 有两个明显的缺陷：

- 长度限制
    第一个缺陷在于 VLAN Tag 的设计，其设计之初只留了 12bit 的长度来存储 VLAN ID，即 VLAN ID 最多只能有 $2^{12} = 4096$ 种取值，不满足后续的大规模场景。

    后来 IEEE 的工程师们又提出 802.1AQ 规范力图补救这个缺陷，大致思路是给以太帧连续打上两个 VLAN Tag，每个 Tag 里仍然只有 12 Bits 的 VLAN ID，但两个加起来就可以存储 $2^{24}=16,777,216$ 个不同的 VLAN ID 了。该方案直到现在还没有特别普及。

- 跨数据中心的传递
    VLAN 本身是为二层网络所设计的，但是在两个独立数据中心之间，信息只能够通过三层网络传递，由于云计算的发展普及，大型分布式系统已不局限于单个数据中心，完全有跨数据中心运作的可能性，此时如何让 VLAN Tag 在两个数据中心间传递又成了不得不考虑的麻烦事。

    VXLAN 在 IP 网络上创建了一个**逻辑的大二层网络**。属于同一个 VXLAN 段的虚拟机，即使其所在的物理服务器位于不同的 IP 子网（不同的三层路由域），在逻辑上它们也像是在同一个二层网络中。这使得虚拟机可以在任何连接到 VXLAN Underlay IP 网络的主机之间自由迁移，**打破了物理二层域对虚拟机迁移的地理限制**，实现了真正的“任意点迁移”。

为了统一解决以上两个问题，IETF 定义了 VXLAN 规范，这是三层虚拟化网络（Network Virtualization over Layer 3，NVO3）的标准技术规范之一，是一种典型的 Overlay 网络。VXLAN 采用 L2 over L4 （MAC in UDP）的报文封装模式，把原本在二层传输的以太帧放到四层 UDP 协议的报文体内，同时加入了自己定义的 VXLAN Header。在 VXLAN Header 里直接就有 24 Bits 的 VLAN ID，同样可以存储 1677 万个不同的取值，VXLAN 让二层网络得以在三层范围内进行扩展，不再受数据中心间传输的限制。

![image.png](https://r2.129870.xyz/img/2025/2e165806a20d0ad83f55b6b951df4e84.png)

VXLAN 网络的每个边缘入口上布置有一个 VTEP（VXLAN Tunnel Endpoints）设备，它既可以是物理设备，也可以是虚拟化设备，负责 VXLAN 协议报文的封包和解包。一台 Linux 主机经过简单配置之后，便可以把 Linux Bridge 作为 VTEP 设备使用。

VXLAN 带来了很高的灵活性、扩展性和可管理性，同一套物理网络中可以任意创建多个 VXLAN 网络，每个 VXLAN 中接入的设备都仿佛是在一个完全独立的二层局域网中一样，不会受到外部广播的干扰，也很难遭受外部的攻击，这使得 VXLAN 能够良好地匹配分布式系统的弹性需求。不过，VXLAN 也带来了额外的复杂度和性能开销，具体表现在：

- 传输速率的下降
    额外增加的 header 属性使得传输成本变高。
- 传输性能的下降
    每个 VXLAN 报文的封包和解包操作都属于额外的处理过程，尤其是用软件来实现的 VTEP，额外的运算资源消耗有时候会成为不可忽略的性能影响因素。

###### 7.2.1.2.4. 副本网卡：MACVLAN

两个 VLAN 之间是完全二层隔离的，不存在重合的广播域，因此要通信就只能通过三层设备，最简单的三层通信就是靠单臂路由了。

![image.png](https://r2.129870.xyz/img/2025/e103b1a0232f25e50f36c6bfda8c3f58.png)

假设位于 VLAN-A 中的主机 A1 希望将数据包发送给 VLAN-B 中的主机 B2，由于 A、B 两个 VLAN 之间二层链路不通，因此引入了单臂路由，单臂路由不属于任何 VLAN，它与交换机之间的链路允许任何 VLAN ID 的数据包通过，这种接口被称为 TRUNK。这样，A1 要和 B2 通信，A1 就将数据包先发送给路由（只需把路由设置为网关即可做到），然后路由根据数据包上的 IP 地址得知 B2 的位置，去掉 VLAN-A 的 VLAN Tag，改用 VLAN-B 的 VLAN Tag 重新封装数据包后发回给交换机，交换机收到后就可以顺利转发给 B2 了。

由于 A1、B2 各自处于独立的网段上，它们又各自要将同一个路由作为网关使用，这就要求路由器必须同时具备 192.168.1.0/24 和 192.168.2.0/24 的 IP 地址。如果真的就只有 VLAN-A、VLAN-B 两个 VLAN，那把路由器上的两个接口分别设置不同的 IP 地址，然后用两条网线分别连接到交换机上也勉强算是一个解决办法，但 VLAN 最多支持 4096 个 VLAN，如果要接四千多条网线就太离谱了。为了解决这个问题，802.1Q 规范中专门定义了子接口（Sub-Interface）的概念，其作用是允许**在同一张物理网卡上，针对不同的 VLAN 绑定不同的 IP 地址**。

MACVLAN 借用了 VLAN 子接口的思路，并且在这个基础上更进一步，不仅允许对同一个**网卡设置多个 IP 地址，还允许对同一张网卡上设置多个 MAC 地址**，这也是 MACVLAN 名字的由来。原本 MAC 地址是网卡接口的“身份证”，应该是严格的一对一关系，而 MACVLAN 打破这层关系，方法是在物理设备之上、网络栈之下生成多个虚拟的 Device，每个 Device 都有一个 MAC 地址，新增 Device 的操作本质上相当于在系统内核中注册了一个收发特定数据包的回调函数，每个回调函数都能对一个 MAC 地址的数据包进行响应，当物理设备收到数据包时，会先根据 MAC 地址进行一次判断，确定交给哪个 Device 来处理。

![image.png](https://r2.129870.xyz/img/2025/310df4ee6dd2b5b69e0c49662321c321.png)

用 MACVLAN 技术虚拟出来的副本网卡，在功能上和真实的网卡是完全对等的，此时真正的物理网卡实际上确实承担着类似交换机的职责，收到数据包后，根据目标 MAC 地址判断这个包应转发给哪块副本网卡处理，由同一块物理网卡虚拟出来的副本网卡，天然处于同一个 VLAN 之中，可以直接二层通信，不需要将流量转发到外部网络。

与 Linux Bridge 相比，这种以网卡模拟交换机的方法在目标上并没有本质的不同，但 MACVLAN 在内部实现上要比 Linux Bridge 轻量得多。从数据流来看，副本网卡的通信只比物理网卡多了一次判断而已，能获得很高的网络通信性能；从操作步骤来看，由于 MAC 地址是静态的，所以 MACVLAN 不需要像 Linux Bridge 那样考虑 MAC 地址学习、STP 协议等复杂的算法，这进一步突出了 MACVLAN 的性能优势。

##### 7.2.1.3. 容器间通信

Docker 的网络方案在操作层面上是指能够直接通过 `docker run --network` 参数指定的网络，或者先 `docker network create` 创建后再被容器使用的网络。安装 Docker 过程中会自动在宿主机上创建一个名为 docker0 的网桥，以及三种不同的 Docker 网络：

- bridge 桥接网络
    使用 `--network=bridge` 指定。这种也是未指定网络参数时的默认网络。桥接模式下，Docker 会为新容器分配独立的网络名称空间，创建好 veth pair，一端接入容器，另一端接入到 docker0 网桥上。Docker 为每个容器自动分配好 IP 地址，默认配置下地址范围是 172.17.0.0/24，docker0 的地址默认是 172.17.0.1，并且设置所有容器的网关均为 docker0，这样所有接入同一个网桥内的容器直接依靠二层网络来通信，在此范围之外的容器、主机就必须通过网关来访问。
- host 主机网络
    使用 `--network=host` 指定。主机模式下，Docker 不会为新容器创建独立的网络名称空间，这样容器一切的网络设施，如网卡、网络栈等都直接使用宿主机上的真实设施，容器也就不会拥有自己独立的 IP 地址。此模式下与外界通信无须进行 NAT 转换，没有性能损耗，但缺点也十分明显，没有隔离就无法避免网络资源的冲突，譬如端口号就不允许重复。
- nono 空置模式
    使用 `--network=none` 指定，空置模式下，Docker 会给新容器创建独立的网络名称空间，但是不会创建任何虚拟的网络设备，此时容器能看到的只有一个回环设备（Loopback Device）而已。提供这种方式是为了**方便用户去做自定义的网络配置，如自己增加网络设备、自己管理 IP 地址，等等**。

除了三种开箱即用的网络外，Docker 还支持以下由用户自行创建的网络：

- 容器模式
    创建容器后使用 `--network=container:容器名称` 指定。容器模式下，**新创建的容器将会加入指定的容器的网络名称空间，共享一切的网络资源**，但其他资源，如文件、PID 等默认仍然是隔离的，两个容器间可以直接使用回环地址（localhost）通信，端口号等网络资源不能有冲突。
- MACVLAN 模式
    使用 `docker network create -d macvlan` 创建，此网络允许为容器指定一个副本网卡，容器通过副本网卡的 MAC 地址来使用宿主机上的物理设备，在追求通信性能的场合，这种网络是最好的选择。Docker 的 MACVLAN 只支持 Bridge 通信模式，因此在功能表现上与桥接模式相类似。
- Overlay 模式
    使用 `docker network create -d overlay` 创建，Docker 说的 Overlay 网络实际上就是特指 VXLAN，这种网络模式主要用于 Docker Swarm 服务之间进行通信。然而由于 Docker Swarm 败于 Kubernetes，并未成为主流，所以这种网络模式实际很少使用。

#### 7.2.2. 容器网络与生态

与 libcontainer 是作为 OCI 的标准实现类似，libnetwork 是作为 Docker 提出的 CNM 规范（Container Network Model）的标准实现而设计的。如今容器网络的事实标准 CNI（Container Networking Interface）与 CNM 在目标上几乎是完全重叠的，由此决定了 CNI 与 CNM 之间只能是你死我活的竞争关系，这与容器运行时中提及的 CRI 和 OCI 的关系明显不同，CRI 与 OCI 目标并不一样，两者有足够空间可以和平共处。

网络的专业性与针对性也决定了 CNM 和 CNI 均采用了插件式的设计，需要接入什么样的网络，就设计一个对应的网络插件即可。从程序功能上看，CNM 和 CNI 的网络插件提供的能力都能划分为网络的管理与 IP 地址的管理两类，插件可以选择只实现其中的某一个，也可以全部都实现。

- 管理网络创建与删除
    解决如何创建网络，如何将容器接入到网络，以及容器如何退出和删除网络。这个过程实际上是对容器网络的生命周期管理。
- 管理 IP 地址分配与回收
    解决如何为三层网络分配唯一的 IP 地址的问题，二层网络的 MAC 地址天然就具有唯一性，无须刻意地考虑如何分配的问题。但是三层网络的 IP 地址只有通过精心规划，才能保证在全局网络中都是唯一的，否则，如果两个容器之间可能存在相同地址，那它们就最多只能做 NAT，而不可能做到直接通信。

CNM 规范还未提出之前，Kubernetes 自己来维护网络是必然的结果，因为 Docker 自带的网络基本上只聚焦于如何解决本地通信，完全无法满足 Kubernetes 跨集群节点的容器编排的需要。

### 7.3. 持久化存储

容器是镜像的运行时实例，为了**保证镜像能够重复地产生出具备一致性的运行时实例，必须要求镜像本身是持久而稳定的**，这决定了**在容器中发生的一切数据变动操作都不能真正写入到镜像当中，否则必然会破坏镜像稳定不变的性质**。为此，容器中的数据修改操作，大多是基于写入时复制（Copy-on-Write）策略来实现的，容器会利用叠加式文件系统（OverlayFS）的特性，在用户意图对镜像进行修改时，自动将变更的内容写入到独立区域，再与原有数据叠加到一起，使其外观上看来像是“覆盖”了原有内容。这种改动通常都是临时的，一旦容器终止运行，这些存储于独立区域中的变动信息也将被一并移除，不复存在。由此可见，如果不去进行额外的处理，容器默认是不具备持久化存储能力的。

而另一方面，容器作为信息系统的运行载体，必定会产生出有价值的、应该被持久保存的信息，多个容器之间也经常需要通过共享存储来实现某些交互操作。正因为镜像的稳定性与生产数据持久性存在矛盾，由此才产生了本章的主题：如何实现容器的持久化存储。

#### 7.3.1. Kubetnetes 存储设计

Kubernetes 在规划持久化存储能力的时候，依然遵循着它的一贯设计哲学，用户负责以资源和声明式 API 来描述自己的意图，Kubernetes 负责根据用户意图来完成具体的操作。

存储技术本来就门类众多，为了尽可能多地兼容各种存储，Kubernetes 不得不预置了很多 In-Tree（在 Kubernetes 的代码树里）插件来对接，让用户根据自己业务按需选择。同时，为了兼容那些不在预置范围内的需求场景，支持用户使用 FlexVolume 或者 CSI 来定制 Out-of-Tree（在 Kubernetes 的代码树之外）的插件，实现更加丰富多样的存储能力。

##### 7.3.1.1. Mount 和 Volume

Docker 内建支持了三种挂载类型，分别是 Bind（`--mount type=bind`）、Volume（`--mount type=volume`）和 tmpfs（`--mount type=tmpfs`），其中 tmpfs 用于在内存中读写临时数据。

![image.png](https://r2.129870.xyz/img/2025/04a5b08f484a91324f01a56700d300d3.png)

Bind Mount 是 Docker 最早提供的（发布时就支持）挂载类型，作用是把宿主机的某个目录（或文件）挂载到容器的指定目录（或文件）下。

```bash
docker run -v /icyfenix/html:/usr/share/nginx/html nginx:latest
```

从 Docker 17.06 版本开始，它在 Docker Swarm 中借用了 `--mount` 参数过来，这个参数默认创建的是 Volume Mount，可以通过明确的 type 子参数来指定另外两种挂载类型。上面命令可以等价于 `--mount` 版本如下形式：

```bash
docker run --mount type=bind,source=/icyfenix/html,destination=/usr/share/nginx/html nginx:latest
```

从 Bind Mount 到 Volume Mount，实质是容器发展过程中对存储抽象能力提升的外在表现。存储的位置并不局限只在外部宿主机、存储的介质并不局限只是物理磁盘、存储的管理也并不局限只有映射关系。

- 跨主机的文件共享
    Bind Mount 只能让容器与本地宿主机之间建立了某个目录的映射，如果想要在不同宿主机上的容器共享同一份存储，就必须先把共享存储挂载到每一台宿主机操作系统的某个目录下，然后才能逐个挂载到容器内使用。这种存储范围超越了宿主机的共享存储，配置过程却要涉及到大量与宿主机环境相关的操作，只能由管理员人工去完成，不仅烦琐，而且每台宿主机环境的差异导致还很难自动化。
- 数据的管控
    Bind Mount 的设计里，Docker 只有容器的控制权，存放容器生产数据的主机目录是完全独立的，与 Docker 没有任何关系，既不受 Docker 保护，也不受 Docker 管理。**Docker 希望能有一种抽象的资源来代表在宿主机或网络中存储的区域，以便让 Docker 能管理这些资源**。
- 提升 Docker 对不同存储介质的支撑能力
    **存储并不是仅有挂载在宿主机上的物理存储这一种介质**，云计算时代，网络存储渐成数据中心的主流选择，不同的网络存储有各自的协议和交互接口，而且并非所有存储系统都适合先挂载到操作系统，然后再挂载到容器的，如果 Docker 想要越过操作系统去支持挂载某种存储系统，首先必须要知道该如何访问它，然后才能将容器中的读写操作自动转移到该位置。Docker 把解决如何访问存储的功能模块称为存储驱动（Storage Driver）。

    面对云计算的快速迭代，仅靠 Docker 自己来支持全部云计算厂商的存储系统是完全不现实的，为此，Docker 提出了与 Storage Driver 相对应的 Volume Driver（卷驱动）的概念。用户可以通过 docker plugin install 命令安装外部的卷驱动，并在创建 Volume 时指定一个与其存储系统相匹配的卷驱动。

##### 7.3.1.2. 静态存储分配

Kubernetes 将 Volume 分为持久化的 PersistentVolume 和非持久化的普通 Volume 两类。

![image.png](https://r2.129870.xyz/img/2025/f00241c2a63d3d2d53cdddb950f1ade3.png)

普通 Volume 的设计目标不是为了持久地保存数据，而是为**同一个 Pod 中多个容器提供可共享的存储资源**，因此 Volume 具有十分明确的生命周期——**与挂载它的 Pod 相同的生命周期**，这意味着尽管普通 Volume 不具备持久化的存储能力，但至少比 Pod 中运行的任何容器的存活期都更长，Pod 中不同的容器能共享相同的普通 Volume，当容器重新启动时，普通 Volume 中的数据也会能够得到保留。当然，一旦整个 Pod 被销毁，普通 Volume 也将不复存在，数据在逻辑上也会被销毁掉，至于实质上会否会真正删除数据，就取决于存储驱动具体是如何实现 Unmount、Detach、Delete 接口的。

PersistentVolume 是指能够将数据进行持久化存储的一种资源对象，它可以独立于 Pod 存在，生命周期与 Pod 无关，因此也决定了 **PersistentVolume 不应该依附于任何一个宿主机节点，否则必然会对 Pod 调度产生干扰限制**。

将 PersistentVolume 与 Pod 分离后，便需要专门考虑 PersistentVolume 该如何被 Pod 所引用的问题。原本在 Pod 中引用其他资源是常有的事，要么直接通过资源名称直接引用，要么通过标签选择器（Selectors）间接引用。但是类似的方法在这里却都不太妥当，至于原因，请你想一下“Pod 该使用何种存储”这件事情，应该是系统管理员（运维人员）说的算，还是由用户（开发人员）说的算？

最合理的答案是他们一起说的才算，因为只有开发能准确评估 Pod 运行需要消耗多大的存储空间，只有运维能清楚知道当前系统可以使用的存储设备状况，为了让他们得以各自提供自己擅长的信息，Kubernetes 又额外设计出了 PersistentVolumeClaim 资源。

PersistentVolume 是 Volume 这个抽象概念的具象化表现，它是已经被管理员分配好的具体的存储，这里的“具体”是指有明确的存储系统地址，有明确的容量、访问模式、存储位置等信息；而 PersistentVolumeClaim 则是 Pod 对其所需存储能力的声明，是满足这个 Pod 正常运行要满足怎样的条件，譬如要消耗多大的存储空间、要支持怎样的访问方式。因此两者并不是谁引用谁的固定关系，而是根据实际情况动态匹配的，两者配合工作的具体过程如下：

1. 存储系统准备
    管理员准备好要使用的存储系统，它应是某种网络文件系统（NFS）或者云储存系统，一般来说应该具备跨主机共享的能力。
2. 存储配置
    管理员根据存储系统的实际情况，手工预先分配好若干个 PersistentVolume，并定义好每个 PersistentVolume 可以提供的具体能力。
3. 存储需求生命
    用户根据业务系统的实际情况，创建 PersistentVolumeClaim，声明 Pod 运行所需的存储能力。
4. 需求配对
    Kubernetes 创建 Pod 的过程中，会根据系统中 PersistentVolume 与 PersistentVolumeClaim 的供需关系对两者进行撮合，如果系统中存在满足 PersistentVolumeClaim 声明中要求能力的 PersistentVolume 则撮合成功，将它们绑定。如果撮合不成功，Pod 就不会被继续创建，直至系统中出现新的或让出空闲的 PersistentVolume 资源。

![image.png](https://r2.129870.xyz/img/2025/7a515624c392731fe5c22002b9175d3f.png)

PersistentVolumeClaim 与 PersistentVolume 撮合的结果是产生一对一的绑定关系，PersistentVolume 一旦绑定在某个 PersistentVolumeClaim 上，直到释放以前都会被这个 PersistentVolumeClaim 所独占，不能再与其他 PersistentVolumeClaim 进行绑定。这意味着**即使 PersistentVolumeClaim 申请的存储空间比 PersistentVolume 能够提供的要少，依然要求整个存储空间都为该 PersistentVolumeClaim 所用**，这有可能会造成资源的浪费。

##### 7.3.1.3. 动态存储分配

动态存储分配方案，指在用户声明存储能力的需求时，不是期望通过 Kubernetes 撮合来获得一个管理员人工预置的 PersistentVolume，而是**由特定的资源分配器（Provisioner）自动地在存储资源池或者云存储系统中分配符合用户存储需要的 PersistentVolume，然后挂载到 Pod 中使用**，完成这项工作的资源被命名为 StorageClass，它的具体工作过程如下：

1. 管理员根据存储系统的实际情况，先准备好对应的 Provisioner
2. 管理员不再是手工去分配 PersistentVolume，而是根据存储去配置 StorageClass
    **Pod 是可以动态扩缩的，而存储则是相对固定的**，哪怕使用的是具有扩展能力的云存储，也会将它们视为存储容量、IOPS 等参数可变的固定存储来看待，譬如你可以将来自不同云存储提供商、不同性能、支持不同访问模式的存储配置为各种类型的 StorageClass，这也是它名字中“Class”（类型）的由来
3. 用户声明需求
    依然通过 PersistentVolumeClaim 来声明所需的存储，但是应在声明中明确指出该由哪个 StorageClass 来代替 Kubernetes 处理该 PersistentVolumeClaim 的请求。
4. PersistentVolume 自动生产
    如果 PersistentVolumeClaim 中要求的 StorageClass 及它用到的 Provisioner 均是可用的话，那这个 StorageClass 就会接管掉原本由 Kubernetes 撮合 PersistentVolume 与 PersistentVolumeClaim 的操作，按照 PersistentVolumeClaim 中声明的存储需求，自动产生出满足该需求的 PersistentVolume 描述信息，并发送给 Provisioner 处理。
5. 存储分配
    Provisioner 接收到 StorageClass 发来的创建 PersistentVolume 请求后，会操作其背后存储系统去分配空间，如果分配成功，就生成并返回符合要求的 PersistentVolume 给 Pod 使用。

![image.png](https://r2.129870.xyz/img/2025/d0200e012d05bea5e98e06eadcd562c0.png)

使用 Dynamic Provisioning 来分配存储无疑是更合理的设计：

- 节省人工操作
    不仅省去了管理员的人工操作的中间层，也不再需要将 PersistentVolume 这样的概念暴露给最终用户，因为 Dynamic Provisioning 里的 PersistentVolume 只是处理过程的中间产物，用户不再需要接触和理解它，只需要知道由 PersistentVolumeClaim 去描述存储需求，由 StorageClass 去满足存储需求即可。只描述意图而不关心中间具体的处理过程是声明式编程的精髓，也是流程自动化的必要基础。
- 获得更高的管理性
    Dynamic Provisioning 中由于有 Provisioner 的存在，如何创建、如何回收都是由 Provisioner 的代码所管理的，这就带来了更高的灵活性。

#### 7.3.2. 容器存储与生态

容器存储具有很强的多样性，如何对接后端实际的存储系统，并且完全发挥出它所有的性能与功能并不是 Kubernetes 团队所擅长的工作，这件事情只有存储提供商自己才能做到最好。由此可以理解容器编排系统为何会有很强烈的意愿想把存储功能独立到外部去实现。

Kubernetes 参考了传统操作系统接入或移除新存储设备做法，把接入或移除外部存储这件事情分解为以下三种操作：

- 存储设备准备
    决定应准备（Provision）何种存储，确定了接入存储的来源、容量、性能以及其他技术参数，它的逆操作是移除（Delete）。
- 存储设备附加
    将准备好的存储附加（Attach）到系统中，Attach 可类比为将存储设备接入操作系统，此时尽管设备还不能使用，但你已经可以用操作系统的 `fdisk -l` 命令查看到设备。这步确定了存储的设备名称、驱动方式等面向系统一侧的信息，它的逆操作是分离（Detach）存储设备。
- 存储设备挂载
    将附加好的存储挂载（Mount）到系统中，Mount 可类比为将设备挂载到系统的指定位置，也就是操作系统中 mount 命令的作用。这步确定了存储的访问目录、文件系统格式等面向应用一侧的信息，它的逆操作是卸载（Unmount）存储设备。

以上提到的 Provision、Delete、Attach、Detach、Mount、Unmount 六种操作，并不是直接由 Kubernetes 来实现，实际行为均是在存储插件中完成的，它们会分别被 Kubernetes 通过两个控制器及一个管理器来进行调用，这些控制器、管理器的作用分别是：

- PV 控制器（PersistentVolume Controller）
    PV 控制器的期望状态有两个，分别是“所有未绑定的 PersistentVolume 都能处于可用状态”以及“所有处于等待状态的 PersistentVolumeClaim 都能配对到与之绑定的 PersistentVolume”，它内部也有两个相对独立的核心逻辑（ClaimWorker 和 VolumeWorker）来分别跟踪这两种期望状态，可以简单地理解为 PV 控制器实现了 PersistentVolume 和 PersistentVolumeClaim 的生命周期管理职能，在这个过程中，会根据需要调用存储驱动插件的 Provision/Delete 操作。
- AD 控制器（Attach/Detach Controller）
    AD 控制器的期望状态是“所有被调度到准备新创建 Pod 的节点，都附加好了要使用的存储；当 Pod 被销毁后，原本运行 Pod 的节点都分离了不再被使用的存储”，如果实际状态不符合该期望，会根据需要调用存储驱动插件的 Attach/Detach 操作。
- Volume 管理器（Volume Manager）
    支持本节点中 Volume 执行 Attach/Detach/Mount/Unmount 操作。

![image.png](https://r2.129870.xyz/img/2025/3239716af947a20c0daf2b5e0bc72fdb.png)

CSI（Container Storage Interface），CSI 规范可以分为需要容器系统去实现的组件，以及需要存储提供商去实现的组件两大部分。前者包括了存储整体架构、Volume 的生命周期模型、驱动注册、Volume 创建、挂载、扩容、快照、度量等内容，这些 Kubernetes 都已经完整地实现了，大体上包括以下几个组件：

- Driver Register：负责注册第三方插件，CSI 0.3 版本之后已经处于 Deprecated 状态，将会被 Node Driver Register 所取代
- External Provisioner：调用第三方插件的接口来完成数据卷的创建与删除功能
- External Attacher：调用第三方插件的接口来完成数据卷的挂载和操作
- External Resizer：调用第三方插件的接口来完成数据卷的扩容操作
- External Snapshotter：调用第三方插件的接口来完成快照的创建和删除
- External Health Monitor：调用第三方插件的接口来提供度量监控数据

需要存储提供商去实现的组件才是 CSI 的主体部分，即前文中多次提到的“第三方插件”。这部分着重定义了外部存储挂载到容器过程中所涉及操作的抽象接口和具体的通讯方式，主要包括以下三个 gRPC 接口：

- CSI Identity 接口
    用于描述插件的基本信息，譬如插件版本号、插件所支持的 CSI 规范版本、插件是否支持存储卷创建、删除功能、是否支持存储卷挂载功能，等等。此外 Identity 接口还用于检查插件的健康状态，开发者可以通过实现 Probe 接口对外提供存储的健康度量信息。
- CSI Controller 接口
    用于从存储系统的角度对存储资源进行管理，譬如准备和移除存储（Provision、Delete 操作）、附加与分离存储（Attach、Detach 操作）、对存储进行快照，等等。存储插件并不一定要实现这个接口的所有方法，对于存储本身就不支持的功能，可以在 CSI Identity 接口中声明为不提供。
- CSI Node 接口
    用于从集群节点的角度对存储资源进行操作，譬如存储卷的分区和格式化、将存储卷挂载到指定目录上、或者将存储卷从指定目录上卸载，等等。

CSI 插件本身便是由一组标准的 Kubernetes 资源所构成，CSI Controller 接口是一个以 StatefulSet 方式部署的 gRPC 服务，CSI Node 接口则是基于 DaemonSet 方式部署的 gRPC 服务。通过 gRPC 协议传递参数比通过命令行参数传递参数更加严谨，灵活和可靠，最起码不会出现多个接口之间协作只能写临时文件这样的尴尬状况。

### 7.4. 资源与调度

调度是指为新创建出来的 Pod 寻找到一个最恰当的宿主机节点来运行它，调度结果关键取决于容器编排系统是如何管理与分配集群节点的资源的，可以认为调度是必须以容器编排系统的资源管控为前提。

从编排系统的角度来看，Node 是资源的提供者，Pod 是资源的使用者，调度是将两者进行恰当的撮合。Node 通常能够提供的三方面的资源：计算资源（如处理器、图形处理器、内存）、存储资源（如磁盘容量、不同类型的介质）和网络资源（如带宽、网络地址），其中与调度关系最密切的是处理器和内存，虽然两者同属于计算资源，但在调度时有细微的差别：

- 可压缩资源（Compressible Resources）
    当可压缩资源不足时，Pod 只会处于“饥饿状态”，运行变慢，但不会被系统杀死，即容器被直接终止，或被要求限时退出。
- 不可压缩资源（Incompressible Resources）
    当不可压缩资源不足，或者超过了容器自己声明的最大限度时，Pod 就会因为内存溢出（Out-Of-Memory，OOM）而被系统直接杀掉。

#### 7.4.1. 服务质量的优先级

设定资源计量单位的目的是为了管理员能够限制某个 Pod 对资源的过度占用，避免影响到其他 Pod 的正常运行。 Kubernetes 给出的配置中有 limits 和 requests 两个设置项，requests 是给调度器用的，Kubernetes 选择哪个节点运行 Pod，只会根据 requests 的值来进行决策；limits 才是给 cgroups 用的，Kubernetes 在向 cgroups 的传递资源配额时，会按照 limits 的值来进行设置。

用户提交工作负载时设置的资源配额，并不是容器调度一定必须严格遵守的值，因为根据实际经验，大多数的工作负载运行过程中真正使用到的资源，其实都远小于它所请求的资源配额。

当节点无法继续遵守调度时对 Pod 许下的资源承诺，此时，Kubernetes 迫不得已要杀掉一部分 Pod 腾出资源来保证其余 Pod 能正常运行，这个操作驱逐机制（Eviction）。要进行驱逐，首先 Kubernetes 就必须拿出资源不足时该先牺牲哪些 Pod、该保留哪些 Pod 的明确准则，由此就形成了 Kubernetes 的服务质量等级（Quality of Service Level，QoS Level）和优先级（Priority）的概念。

Kubernetes 目前提供的服务质量等级一共分为三级，由高到低分别为：

- Guaranteed
    如果 Pod 中所有的容器都设置了 limits 和 requests，且两者的值相等，那此 Pod 的服务质量等级便为最高的 Guaranteed。
- Burstable 
    如果 Pod 中有部分容器的 requests 值小于 limits 值，或者只设置了 requests 而未设置 limits，那此 Pod 的服务质量等级为第二级 Burstable。
- BestEffort
    limits 和 requests 两个都没设置就是最低的 BestEffort 了。

除了服务质量等级以外，Kubernetes 还允许系统管理员自行决定 Pod 的优先级，这是通过类型为 PriorityClass 的资源来实现的。优先级决定了 Pod 之间并不是平等的关系，而且这种不平等还不是谁会占用更多一点的资源的问题，而是会直接影响 Pod 调度与生存的关键。

当多个 Pod 同时被调度的话，高优先级的 Pod 会优先被调度。Pod 越晚被调度，就越大概率因节点资源已被占用而不能成功。但优先级影响更大的另一方面是指 Kubernetes 的抢占机制（Preemption），正常未设置优先级的情况下，如果 Pod 调度失败，就会暂时处于 Pending 状态被搁置起来，直到集群中有新节点加入或者旧 Pod 退出。但是，**如果有一个被设置了明确优先级的 Pod 调度失败无法创建的话，Kubernetes 就会在系统中寻找出一批牺牲者（Victims），将它们杀掉以便给更高优先级的 Pod 让出资源**。寻找的原则是根据在优先级低于待调度 Pod 的所有已调度 Pod 里，按照优先级从低到高排序，从最低的杀起，直至腾出的资源足以满足待调度 Pod 的成功调度为止，或者已经找不到更低优先级的 Pod 为止。

#### 7.4.2. 驱逐机制

kubelet 一旦发现某种不可压缩资源将要耗尽，就会主动终止节点上较低服务质量等级的 Pod，以保证其他更重要的 Pod 的安全。被驱逐的 Pod 中所有的容器都会被终止，Pod 的状态会被更改为 Failed。

默认配置下，资源即将耗尽具体阈值是可用内存小于 100 Mi。除了可用内存（`memory.available`）外，其他不可压缩资源还包括有：宿主机的可用磁盘空间（`nodefs.available`）、文件系统可用 inode 数量（`nodefs.inodesFree`），以及可用的容器运行时镜像存储空间（`imagefs.available`）。后面三个的阈值都是按照实际容量的百分比来计算的，具体的默认值如下：

```txt
memory.available < 100Mi
nodefs.available < 10%
nodefs.inodesFree < 5%
imagefs.available < 15%
```

驱逐机制中就有了软驱逐（Soft Eviction）、硬驱逐（Hard Eviction）以及优雅退出期（Grace Period）的概念:

- 软驱逐
    配置一个较低的警戒线（譬如可用内存仅剩 20%），触及此线时，系统将进入一段观察期。如果只是暂时的资源抖动，在观察期内能够恢复到正常水平的话，那就不会真正启动驱逐操作。否则，资源持续超过警戒线一段时间，就会触发 Pod 的优雅退出。**在优雅退出期结束后，系统会强制杀掉还未曾自行了断的 Pod**。
- 硬驱逐
    通常配置一个较高的终止线（譬如可用内存仅剩 10%），一旦触及此红线，立即强制杀掉 Pod，不理会优雅退出。
- 优雅退出期
    优雅退出（Grace Shutdown），系统会通知 Pod 进行必要的清理工作（譬如将缓存的数据落盘），然后自行结束。

软驱逐是为了减少资源抖动对服务的影响，硬驱逐是为了保障核心系统的稳定，它们并不矛盾，一般会同时使用。

Kubernetes 的驱逐与编程语言中垃圾收集器另一个不同之处是垃圾收集可以“应收尽收”，而驱逐显然不行，不能无缘无故把整个节点中所有可驱逐的 Pod 都清空掉。但是，通常也不能只清理到刚刚低于警戒线就停止，**必须考虑到驱逐之后的新 Pod 调度与旧 Pod 运行的新增消耗**。譬如 kubelet 驱逐了若干个 Pod，让资源使用率勉强低于阈值，那么很可能在极短的时间内，资源使用率又会因某个 Pod 稍微占用了些许资源而重新超过阈值，再产生新一次驱逐，如此往复。为此，Kubernetes 提供了 `--eviction-minimum-reclaim` 参数用于设置一旦驱逐发生之后，至少清理出来多少资源才会终止。

为了避免被驱逐的 Pod 出现“阴魂不散”的问题（刚被清除出资源的节点立马又被分配 pod 导致资源不够），Kubernetes 还提供了另一个参数 `--eviction-pressure-transition-period` 来约束调度器，在驱逐发生之后多长时间内不得往该节点调度 Pod。

#### 7.4.3. 默认调度器

Kubernetes 是如何撮合 Pod 与 Node 的，这其实也是最困难的一个问题。调度是为新创建出来的 Pod 寻找到一个最恰当的宿主机节点去运行它，这句话里就包含有“运行”和“恰当”两个调度中关键过程：

- 运行
    从集群所有节点中找出一批剩余资源可以满足该 Pod 运行的节点。为此，Kubernetes 调度器设计了一组名为 Predicate 的筛选算法。
- 恰当
    从符合运行要求的节点中找出一个最适合的节点完成调度。为此，Kubernetes 调度器设计了一组名为 Priority 的评价算法。

由于调度器的工作负载与集群规模大致成正比，随着集群和它们的工作负载不断增长，调度器很有可能会成为扩展性瓶颈所在。kubrnetes 共享状态（Shared State）的双循环调度机制：

![image.png](https://r2.129870.xyz/img/2025/6bbd5d63ebfa1474cbf4170c2631e20a.png)

状态共享的双循环：

- Informer Loop
    一系列 Informer 的集合，这些 Informer 持续监视 Etcd 中与调度相关资源（主要是 Pod 和 Node）的变化情况，一旦 Pod、Node 等资源出现变动，就会触发对应 Informer 的 Handler。

    Informer Loop 的职责是**根据 Etcd 中的资源变化去更新调度队列（Priority Queue）和调度缓存（Scheduler Cache）中的信息**，譬如当有新 Pod 生成，就将其入队（Enqueue）到调度队列中，如有必要，还会根据优先级触发上一节提到的插队和抢占操作。又譬如有新的节点加入集群，或者已有节点资源信息发生变动，Informer 也会将这些信息更新同步到调度缓存之中。

- Scheduler Loop
    核心逻辑是不停地将调度队列中的 Pod 出队（Pop），然后使用 Predicate 算法进行节点选择。Predicate 本质上是一组节点过滤器（Filter），它根据预设的过滤策略来筛选节点，Kubernetes 中默认有三种过滤策略，分别是：
    
    - 通用过滤策略
        最基础的调度过滤策略，用来检查节点是否能满足 Pod 声明中需要的资源。譬如处理器、内存资源是否满足，主机端口与声明的 NodePort 是否存在冲突，Pod 的选择器或者 nodeAffinity 指定的节点是否与目标相匹配，等等。
    - 卷过滤策略
        与存储相关的过滤策略，用来检查节点挂载的 Volume 是否存在冲突。
    - 节点过滤策略
        与宿主机相关的过滤策略，最典型的是 Kubernetes 的污点与容忍度机制（Taints and Tolerations），譬如默认情况下 Kubernetes 会设置 Master 节点不允许被调度，这就是通过在 Master 中施加污点来避免的。之前提到的控制节点处于驱逐状态，或者在驱逐后一段时间不允许调度，也是在这个策略里实现的。

**Predicate 算法所使用的一切数据均来自于调度缓存，绝对不会去远程访问节点本身**。只有 Informer Loop 与 Etcd 的监视操作才会涉及到远程调用，**Scheduler Loop 中除了最后的异步绑定要发起一次远程的 Etcd 写入外，其余全部都是进程内访问，这一点是调度器执行效率的重要保证**。

调度缓存就是两个控制循环的共享状态（Shared State），这样的设计避免了每次调度时主动去轮询所有集群节点，保证了调度器的执行效率。但是并不能完全避免因节点信息同步不及时而导致调度过程中实际资源发生变化的情况，譬如节点的某个端口在获取调度信息后、发生实际调度前被意外占用了。为此，当调度结果出来以后，**kubelet 真正创建 Pod 以前，还必须执行一次 Admit 操作，在该节点上重新做一遍 Predicate 来进行二次确认**。

经过 Predicate 算法筛选出来符合要求的节点集，会交给 Priorities 算法来打分排序，以便挑选出最恰当的一个。Kubernetes 也提供了不同的打分规则来满足不同的主观需求，譬如最常用的 LeastRequestedPriority 规则（处理器和内存资源可用性规则） 和 BalancedResourceAllocation 规则（资源均衡性规则）。

经过 Predicate 的筛选、Priorities 的评分之后，调度器已经选出了调度的最终目标节点，最后一步是通知目标节点的 kubelet 可以去创建 Pod 了。调度器并不会直接与 kubelet 通讯来创建 Pod，它只需要把待调度的 Pod 的 nodeName 字段更新为目标节点的名字即可，kubelet 本身会监视该值的变化来接手后续工作。

从调度器在 Etcd 中更新 nodeName，到 kubelet 从 Etcd 中检测到变化，再执行 Admit 操作二次确认调度可行性，最后到 Pod 开始实际创建，这个过程可能会持续一段不短的时间，如果一直等待这些工作都完成了才宣告调度最终完成，那势必也会显著影响调度器的效率。实际上 **Kubernetes 调度器采用了乐观绑定（Optimistic Binding）的策略来解决此问题，它会同步地更新调度缓存中 Pod 的 nodeName 字段，并异步地更新 Etcd 中 Pod 的 nodeName 字段**，这个操作被称为绑定（Binding）。如果最终调度成功了，那 Etcd 与调度缓存中的信息最终必定会保持一致，否则，如果调度失败了，那将会由 Informer 来根据 Pod 的变动，将调度成功却没有创建成功的 Pod 清空 nodeName 字段，重新同步回调度缓存中，以便促使另外一次调度的开始。

