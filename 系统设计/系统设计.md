## 1. 互联网场景设计

### 1.1. 分页查询

#### 1.1.1. 查询方式

1. from+size 的形式
    适用于小数据量或者分页数量不多的情况（ES 中该上限默认为 1 万，超过此条数的分页查询无法使用 from+size 的方式实现）。实现原理为跳过前 from 条数据然后取之后的 size 条数据，例如 mysql 中的 limit 语句。

    此方式在大数据量情况下性能不佳的原因是必须跳过前 from 条数据，并且随着页码越大需要跳过的数据则越多，性能损失越大。

2. 滚动翻页
    滚动翻页实现效果为逐页浏览，无法跳页，实现方式为游标。

    整体实现思路如下：

    1. 首先根据一定的过滤条件进行查询（同时可能会携带排序条件）获取第一页数据
    2. 将第一页数据最后一条数据的偏移量作为第二页数据的起始偏移量
        这个偏移量是一个**唯一 ID**。如果查询条件中本身已经携带了唯一 ID 的排序条件，那么可以直接使用该 ID，否则需要显式或者隐式的生成一个唯一 ID。例如基于主键的 ID 或者基于数据节点的 ID。

        唯一 ID 的作用在于避免数据相同（例如名称相同）的情况下无法精准定位的问题。

    3. 为了能有效利用该偏移量，数据必须是有序的，排序过程可能也是显式或者隐式的

#### 1.1.2. 数据混乱问题

不管是哪种查询方式，都可能出现数据混乱的问题。由于查询期间的数据插入，编辑和删除的操作，这些变更的数据会影响原查询数据的顺序。

- 数据插入
    例如原查询列表按照 ID 倒序，此时新插入的数据 ID 会出现在原列表的第一页，导致第二页数据重复。
- 数据删除
    删除原第一页中的部分数据，第二页数据查询时错误的跳过一定条数的数据。
- 数据修改
    由于参与排序的字段值被修改，导致原查询条件中排序结果不再适用。

解决方案：

- 携带上次查询的 ID 
    - 方案
        将上一次查询数据中的最后一条数据 ID 作为参数传递给下一次的请求，后续页的数据查询条件中，其数据 ID 需要大于或小于该值。

        ```sql
        SELECT *
        FROM TABLE
        WHERE id > 'id' LIMIT m,n;
        ```

    - 前提
        数据数据包含有序的 ID。
- 请求时间&创建时间
    - 方案
        类似于 ID 的方式，在查询结果中返回首次查询的时间，之后将该时间作为参数用于控制后续查询，被查询的数据创建时间必须在该时间之前。

        ```sql
        SELECT *
        FROM TABLE
        WHERE create_time < 'time' LIMIT m,n;
        ```

    - 前提
        数据数据包含创建时间。
- 分页位置标记
    - 方案
        查询不再基于 from+size 的方式，而是基于上一次查询的最后位置然后偏移 size 的方式。第一次查询后返回最后一条数据的位置（唯一 ID 或者时间戳），之后的数据根据此位置向后再偏移 size 条数的数据。

        ```sql
        SELECT *
        FROM TABLE
        WHERE tid > 'tid' LIMIT n;
        ```

    - 前提
        数据列表中需要返回这样的偏移量。
- 快照
    - 方案
        首次查询后，将数据集进行快照化存储，之后每次的查询都基于这个快照进行。
    - 前提
        需要具备数据快照化的能力。
- 全量返回，客户端分页
    - 方案
        服务端直接返回全部的数据，由客户端进行分页效果展示。
    - 前提
        数据条数足够少，否则返回全量数据性能不好。

解决程度：

| 方案         | 新增数据问题 | 删除数据问题 | 修改数据问题 |
| ---------- | ------ | ------ | ------ |
| 携带上次查询的 ID | 是      | 否      | 否      |
| 请求时间&创建时间  | 是      | 否      | 否      |
| 分页位置标记     | 是      | 是      | 否      |
| 快照         | 是      | 是      | 是      |
| 全量返回，客户端分页 | 是      | 是      | 是      |

性能与资源消耗对比：

| 方案         | CPU 消耗 | 内存消耗 | 存储消耗 | 实现复杂度 | 适用规模  |
| ---------- | ----- | ---- | ---- | ----- | ----- |
| 携带上次查询的 ID  | 低     | 低    | 无    | 低     | 大规模系统 |
| 请求时间&创建时间  | 低     | 低    | 无    | 低     | 大规模系统 |
| 分页位置标记     | 低     | 低    | 低    | 中     | 大规模系统 |
| 快照         | 高     | 高    | 高    | 中     | 小规模系统 |
| 全量返回，客户端分页 | 高     | 高    | 无    | 低     | 仅小数据量 |

#### 1.1.3. ES 的深度分页示例

ES 支持深度分页查询，基于 search_after 方式实现。

1. 第一页查询

    ```js
    POST my-index-000001/_search
    {
        "size": 10,
        "query": {
            "match" : {
                "title" : "es"
            }
        },
        "sort": [
            {"date": "asc"},
            // 确保唯一性
            {"_id": "desc"}
        ]
    }
    ```

2. ES 返回数据

    ```js
    {
          "took" : 29,
          "timed_out" : false,
          "_shards" : {
            "total" : 1,
            "successful" : 1,
            "skipped" : 0,
            "failed" : 0
          },
          "hits" : {
            "total" : {
              "value" : 5,
              "relation" : "eq"
            },
            "max_score" : null,
            "hits" : [
              {
                ...
                },
                "sort" : [
                  ...
                ]
              },
              {
                ...
                },
                "sort" : [
                  124648691,
                  "624812"
                ]
              }
            ]
          }
        }
    ```

3. 传入分页位置标记：将返回的最后一条记录的 sort 值作为条件传入

    ```js
    GET my-index-000001/_search
    {
        "size": 10,
        "query": {
            "match" : {
                "title" : "es"
            }
        },
        // 上一次返回的结果
        "search_after": [124648691, "624812"],
        "sort": [
            {"date": "asc"},
            {"_id": "desc"}
        ]
    }
    ```

为了避免新写入的数据影响原查询，可以采用 [PIT](https://www.elastic.co/guide/en/elasticsearch/reference/8.4/point-in-time-api.html) 快照的方式进行：

1. 创建快照
    keep_alive 指定了该快照的存活时间。

    ```js
    POST /my-index-000001/_pit?keep_alive=1m
     
    // 返回一个PIT ID：
    {
      "id": "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA=="
    }
    ```

2. 查询该快照
    利用上一步返回的快照 ID 进行查询，查询后会自动将该快照续期。

    ```js
    GET /_search
    {
      "size": 10000,
      "query": {
        "match" : {
          "user.id" : "elkbee"
        }
      },
      "pit": {
         "id":  "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==", 
         "keep_alive": "1m"
      },
      "sort": [ 
        {"@timestamp": {"order": "asc", "format": "strict_date_optional_time_nanos", "numeric_type" : "date_nanos" }}
      ]
    }
    ```

3. 销毁快照
    虽然快照有有效期会自动清理，但为了性能考虑尽可能的在使用完后手动将其释放。

    ```js
    DELETE /_pit
    {
        "id" : "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA=="
    }
    ```

### 1.2. 字段加密方案设计

需求：

1. 需要对部分字段加密，读取时解密。又希望这个逻辑能尽量收敛，避免业务层代码遍地都是加解密，同时又能收敛和管控加密的算法，强度，秘钥等。要怎么做？
2. 如果用来加密的服务不是自己开发的，行规要求必须引入第三方服务，每次存储都得带一次 rpc 怎么办？
3. 如果用来加解密的 rpc 临时失败了，要降级吗？还是直接报错？
4. 有部分获取数据的请求根本就不需要那条被加密的字段，只需要其余几列。能把加解密优化掉吗？

#### 1.2.1. 阶段一：实现透明、可收敛的加解密

核心诉求是：**逻辑收敛、非侵入式、统一管控**。在业务代码中到处写 `encrypt(field)` 和 `decrypt(field)` 是绝对不可取的，它会导致：

- **代码冗余**：每个读写操作都需要重复逻辑。
- **维护噩梦**：更换密钥或算法时，需要修改无数个地方。
- **安全风险**：密钥管理分散，容易泄露。

##### 1.2.1.1. 架构方案：利用持久化框架的扩展点

最优雅的方案是在数据持久化层（DAO/Repository 层）实现自动加解密，对业务层完全透明。以 Java 生态中广泛使用的 MyBatis 为例，最佳实践是使用其提供的 **`TypeHandler`** 机制。

1. **写入数据库时 (`setNonNullParameter`)**: 在将 Java 对象的 `String` 字段存入数据库前，调用加密方法，将明文转换为密文。
2. **读取数据库时 (`getNullableResult`)**: 从数据库查询出密文后，调用解密方法，将密文转换为明文，再赋值给 Java 对象。

![字段加解密.svg](https://r2.129870.xyz/img/2025/1477912213f9a0fade81dd56eb6477bb.svg)

通过这种方式，`sensitiveInfo` 字段的加解密对业务代码 `UserService` 是完全透明的。`cryptoService` 可以由 Spring 等 IoC 容器统一注入和管理，实现密钥、算法的集中管控。

#### 1.2.2. 阶段二：引入第三方 RPC 加密服务

现在情况变复杂了，加密能力由外部服务提供，每次操作都涉及一次 RPC 调用。

 挑战分析：

1. **性能急剧下降**：每次数据库读/写都增加了一次网络往返（RTT）。对于批量操作或高频读写，这会成为严重瓶颈。
2. **可用性降低**：系统强依赖第三方服务。如果加密服务宕机或网络抖动，整个用户-CRUD 链路都会失败。

##### 1.2.2.1. 架构调整与优化

`TypeHandler` 的设计依然有效，我们只需要修改其内部实现。但必须引入**缓存**来缓解性能问题。

**优化思路：对加解密结果进行缓存。**由于加密算法（在密钥和原文都固定的情况下）的输出是确定的，我们可以缓存 `明文 -> 密文` 和 `密文 -> 明文` 的映射关系。

- **写入时**：先查缓存看明文是否已加密过，有则直接用，没有则 RPC 调用加密，再将结果存入缓存和数据库。
- **读取时**：先查缓存看密文是否已解密过，有则直接用，没有则 RPC 调用解密，再将结果存入缓存并返回。

![加密缓存.svg](https://r2.129870.xyz/img/2025/5dfbe9db02cfb80d9b292c080f5164f4.svg)

**缓存选型**：推荐使用 JVM 进程内缓存，如 **Google Guava Cache** 或 **Caffeine**。它们提供了容量限制、过期策略等高级功能，非常适合此场景，且访问速度极快（纳秒级）。

#### 1.2.3. 阶段三：处理 RPC 失败与服务降级

当第三方加密服务临时不可用时，我们该怎么办？这直接关系到系统的**健壮性**和**可靠性**。

**这是一个典型的业务决策，而非纯技术决策。** 架构师需要提供选项，并和产品、业务方一起决定。

##### 1.2.3.1. 选项一：快速失败 (Fail Fast) - 推荐

- **策略**：直接抛出异常，中断当前操作。如果是在一个事务中，整个事务将回滚。
- **适用场景**：
    - 数据安全性、一致性要求极高（如金融信息、用户密码相关的凭证）。
    - 业务上无法接受数据以明文形式存在，哪怕是暂时的。
- **优点**：逻辑简单，保证数据状态的一致性和安全性。
- **缺点**：系统可用性降低，当依赖的服务不稳定时，会频繁影响主业务。

##### 1.2.3.2. 选项二：服务降级 (Degradation)

- **策略**：当 RPC 失败时，采取一个备用方案来完成操作，以保证主业务流程可用。
- **实现方式**：
    1. **存储明文并标记**：将数据以明文形式存入数据库，同时在一个额外的字段（如 `encryption_status`）中标记为 `"DEGRADED"` 或 `"PLAINTEXT"`。
    2. **启动一个后台补偿任务**：该任务定期扫描数据库，找出所有被标记为降级的记录，待加密服务恢复后，重新调用 RPC 进行加密，并更新数据和标记字段。
- **适用场景**：
    - 系统高可用性优先于强一致性。
    - 业务能接受短暂的数据明文存储（例如，数据本身敏感度不是最高级别，且数据库访问是受控的）。
- **优点**：提高了系统的容错能力和整体可用性。
- **缺点**：
    - **架构复杂度剧增**：需要引入状态标记、后台补偿任务、监控告警等一系列机制。
    - **短暂的安全风险**：在数据被加密之前，它以明文形式存储在数据库中。

**默认选择“快速失败”**。它最简单、最安全。只有当业务明确提出“即使加密服务挂了，用户也要能注册/下单”这类强可用性需求时，才考虑实现复杂的降级方案。在实现降级方案前，必须与安全团队和业务负责人充分沟通，让他们了解其中的风险。

此外，可以在 RPC 调用处引入 **重试（Retry）** 和 **熔断器（Circuit Breaker）** 模式（如使用 `Resilience4j` 库）。

- **重试**：可以解决瞬时网络抖动导致的失败。
- **熔断**：当检测到加密服务持续失败时，可以快速切断后续请求，避免无用的等待和资源消耗，直接执行降级逻辑或快速失败。

#### 1.2.4. 阶段四：优化非必要字段的解密开销

问题根源：如果查询是 `SELECT * FROM user WHERE ...`，MyBatis 会把所有字段都查出来，包括加密的 `sensitiveInfo`。当它尝试将结果映射到 `User` 对象时，发现 `sensitiveInfo` 字段，自然会调用 `EncryptTypeHandler` 去解密，造成不必要的开销（特别是涉及 RPC 时）。

解决方案：DTO 投影 (DTO Projection)。这是解决此类问题的标准模式。不要总是返回包含所有字段的完整领域对象（Entity），而应该根据不同场景，返回只包含所需字段的数据传输对象（DTO）。

这种方式从根源上解决了问题，不仅节省了解密的 CPU/RPC 开销，还减少了数据库到应用服务器的网络传输数据量，是一举多得的最佳实践。

#### 1.2.5. 阶段五：加密优先级的引入

**“不是所有数据都生而平等”**，采用基于数据敏感度和业务影响的差异化治理策略。

核心思想：差异化加密与最终一致性。我们将数据根据其敏感度划分为不同的保护级别，并为每个级别设计不同的加密策略和故障预案。

- **高优先级（High Priority）**：核心敏感数据，如支付密码、核心密钥。数据安全性和一致性 > 可用性。
- **中优先级（Medium Priority）**：次级敏感数据，如身份证号、手机号。可用性与数据安全并重。
- **低优先级（Low Priority）**：一般敏感数据，如住址、昵称。可用性 > 即时的数据安全强度。

##### 1.2.5.1. 数据模型扩展

首先，我们需要在数据模型层面标记数据的状态。在需要加密的字段所在的表中，增加一个字段，例如 `encryption_state`（加密状态）。

 **`encryption_state` (TINYINT/ENUM)**:
 
- `0`: `RPC_ENCRYPTED` (由 RPC 服务强加密)
- `1`: `LOCAL_ENCRYPTED` (由本地服务降级加密)
- `2`: `PLAINTEXT` (明文存储，等待处理 - 仅用于最低优先级)

##### 1.2.5.2. 注解驱动的策略定义

为了让这个机制对业务代码尽可能透明，我们继续沿用并增强注解。

```java
public enum EncryptionLevel {
    HIGH,   // 必须RPC，失败则报错
    MEDIUM, // 优先RPC，失败则本地降级
    LOW     // 直接本地存储，异步RPC
}

@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.FIELD)
public @interface Encryptable {
    EncryptionLevel level() default EncryptionLevel.HIGH;
}
```

在实体类中，我们可以这样使用：

```java
public class UserProfile {
    // ...
    
    @Encryptable(level = EncryptionLevel.HIGH)
    private String paymentPassword; // 高优先级

    @Encryptable(level = EncryptionLevel.MEDIUM)
    private String idCardNumber; // 中优先级

    @Encryptable(level = EncryptionLevel.LOW)
    private String homeAddress; // 低优先级

    private int encryptionStateForIdCard; // 记录idCardNumber的加密状态
    // ... 可以为每个字段设计状态，或采用更复杂的JSONB/TEXT字段存储所有状态
}
```

**注意**：为每个可加密字段都配一个状态字段会使表结构变得臃肿。一个更优雅的替代方案是使用一个 `JSON` 或 `TEXT` 类型的字段，如 `encryption_metadata`，来存储一个 map，key 是字段名，value 是其加密状态。

##### 1.2.5.3. 智能化的 `TypeHandler` 逻辑调整

现在，我们的 `TypeHandler`（或 JPA `@Converter`）需要变得更加“智能”。它在执行时需要知道当前字段的 `EncryptionLevel`。这实现起来有些技巧，通常需要结合 MyBatis 的 Interceptor 来传递上下文，但我们先聚焦于其核心逻辑。

**写入数据库时 (`setNonNullParameter`) 的伪代码：**

```java
public void setParameter(PreparedStatement ps, /*...,*/ String plaintext, Field field) {
    Encryptable annotation = field.getAnnotation(Encryptable.class);
    EncryptionLevel level = (annotation != null) ? annotation.level() : EncryptionLevel.HIGH; // 默认高
    
    String ciphertext = "";
    int newState = -1;

    switch (level) {
        case HIGH:
            try {
                ciphertext = rpcCryptoService.encrypt(plaintext);
                newState = State.RPC_ENCRYPTED;
            } catch (RpcException e) {
                // 高优先级：快速失败
                throw new DataSecurityException("High priority field encryption failed", e);
            }
            break;
            
        case MEDIUM:
            try {
                ciphertext = rpcCryptoService.encrypt(plaintext);
                newState = State.RPC_ENCRYPTED;
            } catch (RpcException e) {
                // 中优先级：降级为本地加密
                log.warn("RPC encryption failed for medium priority field, degrading to local encryption.");
                ciphertext = localCryptoService.encrypt(plaintext); // 使用本地的、可能较弱的算法
                newState = State.LOCAL_ENCRYPTED;
            }
            break;
            
        case LOW:
            // 低优先级：直接使用本地方案，甚至可以是明文，异步处理
            // 为了安全起见，至少进行本地加密
            ciphertext = localCryptoService.encrypt(plaintext); 
            newState = State.LOCAL_ENCRYPTED;
            break;
    }
    
    ps.setString(columnIndex, ciphertext);
    // !! 还需要更新该行的 encryption_state 字段为 newState
    // 这就是TypeHandler的局限性，它只能处理单个字段。
    // 实际项目中，这部分逻辑更适合放在Repository/DAO的save方法中，而不是TypeHandler里
}
```

**重要洞察**：如伪代码注释所示，`TypeHandler` 难以同时更新多个字段。因此，**最佳实践是将这个多级加密逻辑上移到 Repository 或 Service 层的方法中**，在调用 `save` 或 `update` 时，一次性准备好加密后的字段值和对应的状态值。

##### 1.2.5.4. 异步补偿与升级任务

这是整个策略闭环的关键。我们需要一个后台定时任务（例如，使用 `@Scheduled` 注解的 Spring Bean，或 `XXL-Job`、`Quartz` 等分布式调度框架）。

- **任务职责**: 定期扫描数据库中 `encryption_state` 不为 `RPC_ENCRYPTED` 的记录。
- **处理流程**:
    1. 捞取一批 `state = LOCAL_ENCRYPTED` 或 `state = PLAINTEXT` 的记录。
    2. 对于每条记录：
        a.  使用本地密钥解密（如果 `state = LOCAL_ENCRYPTED`），得到明文。
        b.  调用第三方 RPC 服务，用强加密算法加密明文。
        c.  如果 RPC 调用成功，用新的密文更新数据字段，并将 `encryption_state` 更新为 `RPC_ENCRYPTED`。
        d.  如果 RPC 调用失败，则跳过，等待下一轮调度。需要有完善的日志和告警。
- **任务要点**: 任务必须是 **幂等的**、**可中断的**，并且支持 **分批处理** 以免对数据库和 RPC 服务造成冲击。

![加密级别.svg](https://r2.129870.xyz/img/2025/dd8a7dbdbce73e7c03efcb244d3c1cbe.svg)

##### 1.2.6. 优劣势分析 (Trade-offs)

优点：

1. **高度灵活性和可用性**：系统在核心依赖（RPC 加密服务）部分不可用时，依然能为中、低优先级的业务提供服务，最大化系统可用性。
2. **性能与安全的平衡**：对性能要求高、但敏感度不那么顶级的操作（如 `LOW` 级），可以绕开同步 RPC 调用，极大提升响应速度。
3. **差异化安全治理**：实现了基于数据价值的安全策略，将最强的保护和最高的成本用在最需要的地方。

缺点与挑战：

1. **架构复杂度显著增加**：引入了状态管理、后台补偿任务、差异化逻辑分支，开发和维护成本更高。
2. **安全风险窗口**：对于中、低优先级的字段，在后台任务完成“升级”之前，它们是以较弱的加密方式（甚至是明文）存储的。这个“时间窗口”是一个明确的安全妥协，必须经过安全团队的评审和业务方的确认。
3. **数据最终一致性问题**：在数据状态达到 `RPC_ENCRYPTED` 之前，如果其他系统或查询逻辑依赖于这个“最终状态”，可能会读到旧的、未完全加密的数据。整个系统设计必须能容忍这种短暂的不一致。
4. **补偿任务的健壮性要求高**：后台任务自身需要高可用和高可靠，包括失败重试、监控告警、幂等性保证等，它本身就是一个需要精心设计的小系统。

这个方案是一个非常高级和完善的模式。它不再是将系统看作一个整体，而是深入到数据内部，根据业务价值进行精细化控制。这在需要同时平衡高安全、高性能和高可用的复杂系统中，是非常有价值的设计思路。
