#数据库 #消息队列 #分布式

> [!abstract] 相信你近年来一定被层出不穷的商业名词所包围：NoSQL、Big Data、Web-scale、Sharding、Eventual consistency、ACID、CAP 理论、云服务、MapReduce 和 Real-time 等一系列理论包围，所有这些其实都围绕着如何构建高效存储与数据处理这一核心主题。

# 1. 数据系统基础

数据密集性系统遵守若干基本原则，其中以下三个原则先得尤为重要：

- 可靠性
    容忍硬件，软件或者人为的错误。
- 可扩展性
    评测负载与性能，延迟百分位数，吞吐量等。随着规模的增长，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长。
- 可维护性
    可运维，简单与可演化。

这些原则是为了应对数据量，数据的复杂度以及数据的快速多变性而做出的努力。

设计数据系统或数据服务时，一定会碰到很多棘手的问题。例如，当系统内出现了局部失效时，如何确保数据的正确性与完整性? 当发生系统降级 (degrade) 时，该如何为客户提供一致的良好表现? 负载增加时，系统如何扩展? 友好的服务 API 该如何设计？

## 1.1. 数据模型

### 1.1.1. 数据模型分类

- 关系数据模型
- 文档数据模型
- 图数据模型
    在属性图模型中，每个顶点包括：
    - 唯一的标识符。
    - 出边的集合。
    - 入边的集合。
    - 属性的集合（键-值对）
    
    每个边包括：
    - 唯一的标识符。
    - 边开始的顶点（尾部顶点）
    - 边结束的顶点
    - 头部顶点
    - 描述两个顶点间关系类型的标签。
    - 属性的集合（键-值对）
  
图查询语言：
- Cypher 查询语言
    Cypher 是一种用于属性图的声明式查询语言，最早为 Neo 4 j 图形数据库而创建。
- 利用 SQL 建立关系表查询
- 三元存储与 SPARQL
    在三元存储中，所有信息都以非常简单的三部分形式存储 (主体，谓语，客体)。例如，在三元组 (吉姆，喜欢，香蕉) 中，吉姆是主体，喜欢是谓语 (动词)，香蕉是客体。
- Datalog
    Datalog 的数据模型类似于三元存储模式，但更为通用一些。它采用 “ 谓语 (主体，客体)” 的表达方式而不是三元组 (主体，谓语，客体)。

文档数据库和图数据库有一个共同点，那就是它们**通常不会对存储的数据强加某个模式**，这可以使应用程序更容易适应不断变化的需求。但是，应用程序很可能仍然假定数据具有一定的结构，只不过是**模式是显式 (写时强制) 还是隐式 (读时处理) 的问题**。

### 1.1.2. 数据查询语言

- 命令行语言
    命令行语言类似于程序代码的方式，通过命令行查询数据。
    ```javascript
    function getSharks() {
        var sharks = [];
        for (var i = o; i < animals.length; i++) { 
            if (animals[i].family === "Sharks") {
                sharks.push(animals[i]);
            }}
            return sharks;
        }
    ```

- 声明式语言
    声明式语言类似于 SQL。

## 1.2. 数据存储与检索

### 1.2.1. 哈希表索引
 
假设数据存储全部采用追加式文件组成，那么最简单的索引策略就是：保存内存中的 `hash map`，把每个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。这就是 `Bitcask (Riak 中的默认存储引擎) ` 所采用的核心做法。 `Bitcask` 可以提供高性能的读和写，只要所有的 key 可以放入内存 (因为 `hash map` 需要保存在内存中)。而 value 数据量则可以超过内存大小，只需一次磁盘寻址，就可以将 value 从磁盘加载到内存。如果那部分数据文件已经在文件系统的缓存中，则读取根本不需要任何的磁盘 I/O。

`Bitcask` 这样的存储引擎非常适合每个键的值频繁更新的场景。
  
#### 1.2.1.1. 追加式的设计优点

- 追加和分段合并主要是顺序写，它通常比随机写入快得多，特别是在旋转式磁性硬盘上。在 SSD 上也是适合的。
- 段文件是追加的或不可变的，则并发和崩溃恢复要简单得多。
- 合并旧段可以避免随着时间的推移数据文件出现碎片化的问题。

#### 1.2.1.2. 哈希表索引局限性

- 哈希表必须存放在内存中，如果存放在磁盘中，需要大量的随机 IO 访问。
- 区间查询效率不高，例如，不能简单地支持扫描 kittyooooo 和 kitty 99999 区间内的所有键，只能采用逐个查找的方式查询每一个键。

### 1.2.2. SSTables (SortStringTables)

#### 1.2.2.1. SSTable 优势
   
SSTables 要求 key-value 对的顺序按键排序，这样相比哈希索引表有以下优点：

1. 合并段更加高效，可以采取类似归并排序的算法进行段合并。
2. 查找特定 key 时，无需在内存中保存所有键的索引。   
    假设正在查找键 handiwork, 且不知道该键在段文件中的确切偏移。但是，如果知道键 handbag 和键 handsome 的偏移量，考虑到根据键排序，则键 handiwork 一定位于它们两者之间。
    
    这样代表着 **SSTables 索引可以是稀疏的**。
3. 由于读请求往往需要扫描请求范围内的多个 key-value 对，可以考虑将这些记录存到一个块中并在存磁盘前压缩它们。稀疏内存索引每个条目指向每个压缩块的开头。这样除了节省磁盘空间，还减少了 IO 带宽。

#### 1.2.2.2. SSTables 写入与维护
   
将稀疏索引表保存在内存中（当然，磁盘中亦可，如 B-Tree），可以使用红黑树或 AVL 树。使用这些结构可以按任意顺序插入然后读取它们。

1. 写入时，将其写入到内存的平衡树结构中，这个结构有时称为内存表。
  
2. 内存表大于某个阈值（通常几兆字节），将其写入磁盘。写入的数据称为数据库最新的部分，当 SSTbale 写入磁盘时，新的索引写入可以添加到一个新的内存表实例。
  
3. 为了处理读请求，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标。
  
4. 后台进程周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。
	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20211222230226.png)
	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20211222230244.png)

上述方案可以很好地工作。但它还存在一个问题: 如果数据库崩溃，最近的写入 (在内存表中但尚未写入磁盘) 将会丢失。

为了避免该问题，可以在 **磁盘上保留单独的日志，每个写入都立即追加到该日志**，就像上一节哈希表索引存储的那样。这个日志文件不需要按键排序，这并不重要，因为它的唯一目的是在崩溃后恢复内存表。每当将内存表写入 SSTable 时，相应的日志可以被丢弃。

因为基于日志合并，所以这个被简称为 `Log-Structured Merge-Tree, 或 LSM-Tree`。

> [!info] 应用
> 以上描述的算法本质上正是 LevelDB 和 RocksDB 所使用的，主要用于嵌入到其他应用程序的 key-value 存储引擎库。此外，在 Riak 中 LevelDB 可以用作 Bitcask 的替代品。类似的存储引擎还被用于 Cassandra 和 HBase, 这两个引擎都受到 Google 的    `Bigtable 论文` 的启发 (它引入了 SSTable 和内存表这两个术语)。
> 
> Lucene 是 Elasticsearch 和 Solr 等全文搜索系统所使用的索引引擎，它采用了类似的方法来保存其词典。

#### 1.2.2.3. SSTables 的优化
 
1. 优化不存在的 key 查询
    查找数据库中某个不存在的键时， LSM-Tree 算法可能很慢：在确定键不存在之前，必须先检查内存表，然后将段一直回溯访问到最旧的段文件 (可能必须从磁盘多次读取)。为了优化这种访问，存储引擎通常使用额外的布隆过滤器。
2. 优化内存表的压缩与合并
    1. 大小分级压缩
        在大小分级的压缩中，较新的和较小的 SSTables 被连续合并到较旧和较大的 SSTables。
    2. 分层压缩
        在分层压缩中，键的范围分裂成多个更小的 SSTables, 旧数据被移动到单独的 "层级”。

### 1.2.3. B-Trees

#### 1.2.3.1. B-Tree 概念

 B-Tree 像 SSTable 一样， B-Tree 保留按键排序的 key-value 对，这样可以实现高效的 key-value 查找和区间查询。 
 
 上面提到的 SSTables 日志结构索引将数据库分解为可变大小的段，通常大小为几兆字节或更大，并且始终按顺序写入段。相比之下， B-Tree 将数据库分解成固定大小的块或页，传统上大小为 4 KB (有时更大)，页是内部读/写的最小单元。这种设计更接近底层硬件，因为磁盘也是以固定大小的块排列。 
 
 每个页面都可以使用地址或位置进行标识，这样可以让一个页面引用另一个页面，类似指针，不过是指向磁盘地址，而不是内存。可以使用这些页面引用来构造一个树状页面，如图 3-6 所示。
 
 某一页被指定为 B-Tree 的根; 每当查找索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个叶子节点都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20211222232248.png)

#### 1.2.3.2. B-Tree 的查询

 在图 3-6 的例子中，假定正在查找键 251，因此需要沿着 200\~300 间的页引用，到达类似的页，它进一步将 200\~300 范围分解成子范围。最终，我们到达一个包含单个键的页 (叶子页)，该页包含每个内联键的值或包含可以找到值的页的引用。

 B-Tree 中一个页所包含的子页引用数觉称为分支因子。 

#### 1.2.3.3. B-Tree 的写入

如果要更新 B-Tree 中现有键的值，首先搜索包含该键的叶子页，更改该页的值，并将页写回到磁盘 (对该页的任何引用仍然有效) 。如果要添加新键，则需要找到其范围包含新键的页，并将其添加到该页。如果页中没有足够的可用空间来容纳新键，则将其分裂为两个半满的页，并且父页也需要更新以包含分裂之后的新的键范围，如图 3-7 所示。
  
  ![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20211224125151.png)

   该算法确保树保持平衡: 具有 n 个键的 B-Tree 总是具有 O (log n) 的深度。大多数数据库可以适合 3~4 层的 B-Tree, 因此不需要遍历非常深的页面层次即可找到所需的页 (分支因子为 500 的 4 KB 页的四级树可以存储高达 256 TB)。

#### 1.2.3.4. B-Tree 的优化

##### 1.2.3.4.1. 使 B-Tree 保持可靠

B-Tree 的实现是采用新数据覆盖磁盘上的旧页，它假设不会改变页的存储位置，当页被覆盖时，对该页的引用保持不变。这与 [[数据密集系统设计/数据密集型系统设计1：引入#1.2.2. SSTables (SortStringTables)|LSM-Tree]] 形成鲜明对比，LSM-Tree 仅追加与合并日志而不会改写日志。这意味着 B-Tree 需要实现更多的功能以保障数据的准确性：
   
1. 物理磁盘数据变更
    磁头需要先移动到正确位置，然后旋转盘面，最后用新的数据覆盖相应的扇区。对于 SSD，由于 SSD 必须一次擦除并重写非常大的存储芯片块，情况会更为复杂。
1. 部分操作可能涉及多个页
    某些操作需要覆盖多个不同的页。例如，如果插入导致页溢出，因而需分裂页，那么需要写两个分裂的页，并且覆盖其父页以更新对两个子页的引用。这是个比较危险的操作，因为如果数据库在完成部分页写入之后发生崩溃，最终会导致索引破坏 (例如，可能有一个孤儿页，没有被任何其他页所指向)。
    
    **为了使数据库能从崩溃中恢复，常见 B-Tree 的实现需要支持磁盘上的额外的数据结构：预写日志 (write-ahead log，WAL)，也称为重做日志**。这是一个仅支持追加修改的文件，每个 B-Tree 的修改必须先更新 WAL 然后再修改树本身的页。当数据库在崩溃后需要恢复时，该日志用于将 B-Tree 恢复到最近一致的状态。
3. 多个线程写页时，需要进行控制
    如果多个线程要同时访问 B-Tree，则需要注意并发控制，否则线程可能会看到树处于不一致的状态。通常使用锁存器 (轻量级的锁) 保护树的数据结构。

##### 1.2.3.4.2. B-Tree 的优化

1. 降低写入成本
    不使用覆盖页和维护 WAL 来进行崩溃恢复：一些数据库 (如 LMDB) 不使用覆盖页和避免维护 WAL 来进行崩溃恢复，而是使用[[附件资料#^86cdca|写时复制方案]]。修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置。这种方法对于并发控制也很有帮助。
2. 节省存储空间
    保存键的缩略信息而不是完整键：特别是在树中间的页中，只需要提供足够的信息来描述键的起止范围。这样可以将更多的键压入到保存键的缩略信息，而不是完整的键，这样可以节省页空间，让树具有更高的分支因子，从而减少层数。
    
    这个变种有时候被称为 [[B+树]]。
3. 提升查询效率：减少 IO 操作
    1. 使逻辑相邻的页物理磁盘相邻
        如果查询需要按照顺序扫描大段的键范围，考虑到每个读取的页都可能需要磁盘 I/O，所以逐页的布局可能是低效的。许多 B-Tree 的实现都尝试对树进行布局，以便相邻叶子页可以按顺序保存在磁盘上。然而，随着树的增长，维持这个顺序会变得越来越困难。	   
    8. 添加额外指针
        添加额外的指针到树中，如每个叶子页面都可能向左或者向右扫描同级兄弟页，这样就可以顺序扫描而无需回跳到父页。
    9. 减少磁盘寻道
        借鉴一些其他日志结构设计如[[附件资料#^9df9ab|分形树]]来减少磁盘寻道。
        
        > [!info] 分形树
        > 分形树是一种根据数据的属性进行划分的树型结构，它可以将相似的数据放在同一个节点下，从而减少磁盘访问的次数。因此，在设计日志结构时，也可以采用类似的思路，将相似的数据尽量聚集在一起，以减少磁盘寻道的次数，提高系统的性能。

### 1.2.4. LSM-Tree 与 B-Tree 对比

尽管 B-Tree 的实现比 LSM-Tree 的实现更为成熟，然而由于 LSM-Tree 的性能特点，LSM-Tree 目前很有吸引力。根据经验，LSM-Tree 通常对于写入更快，而 B-Tree 被认为对于读取更快。读取通常在 LSM-Tree 上较慢，因为它们必须在不同的压缩阶段检查多个不同的数据结构和 SSTable。

然而，基准测试通常并不太确定，而且取决于很多工作负载的具体细节。最好测试 `特定工作负载`，这样方便进行更有效的比较。

#### 1.2.4.1. LSM -Tree 的优点

由于 LSM-Tree 基于追加文件的方式进行数据写入，所以相比 B-Tree 有以下优点：
 
1. 数据重写次数少
    B-Tree 索引必须至少写两次数据: 一次写入预写日志，一次写入树的页本身 (还可能发生页分裂)。即使该页中只有几个字节更改，也必须承受写整个页的开销。
	  
    LSM-Tree 在压缩与合并时会重写数据多次，这种影响 (在数据库内，由于一次数据库写入请求导致的多次磁盘写称为 `写放大`)。对于 SSD，由于只能承受[[附件资料#^e79710|有限次地擦除覆盖]]，因此尤为关注写放大指标。

    对于大量写密集的应用程序，性能瓶颈很可能在于数据库写入磁盘的速率。在这种情况下，写放大具有直接的性能成本：存储引擎写入磁盘的次数越多，可用磁盘带宽中每秒可以处理的写入越少。
2. LSM-Tree 可以承受更大的写入吞吐量
    LSM-Tree 通常能够承受比 B-Tree 更高的写入吞吐最，部分是因为它们有时具有较低的写放大 (尽管这取决于存储引擎的配置和工作负载)，部分原因是它们以顺序方式写入紧凑的 SSTable 文件，而不必重写树中的多个页。这种差异对于磁盘驱动器尤为重要，原因是磁盘的顺序写比随机写要快得多。
3. LSM-Tree 具有更好的存储开销
    LSM-Tree 可以支持更好地压缩，因此通常磁盘上的文件比 B-Tree 小很多。 由于碎片， B-Tree 存储引擎使某些磁盘空间无法使用：当页被分裂或当一行的内容不能适合现有页时，页中的某些空间无法使用。由于 LSM-Tree 不是面向页的，并且定期重写 SSTables 以消除碎片化，所以它们具有较低的存储开销，特别是在使用分层压缩时。

在许多 SSD 上，固件内部使用日志结构化算法将随机写入转换为底层存储芯片上的顺序写入，所以存储引擎写入模式的影响不那么明显。然而，更低的写放大和碎片减少对于 SSD 上仍然有益，以更紧凑的方式表示数据，从而在可用的 I/O 带宽中支持更多的读写请求。

#### 1.2.4.2. LSM-Tree 的缺点

1. LSM-Tree 在压缩过程中会干扰正在进行的读写操作
    日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。即使存储引擎尝试增量地执行压缩，并且不影响并发访问，但由于磁盘的并发资源有限，所以当磁盘执行昂贵的压缩操作时，很容易发生读写请求等待的情况。这对吞吐量和平均响应时间的影响通常很小，但是如果观察较高的百分位数日志结构化存储引擎的查询响应时间有时会相当高，而 **B-Tree 的响应延迟则更具确定性**。
1. 高写入吞吐量时，磁盘的有限写入带宽需要在初始写入 (记录并刷新内存表到磁盘) 和后台运行的压缩线程之间所共享。
2. 事务处理相比 B-Tree 更复杂
    B-Tree 的优点则是每个键都恰好唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同键的多个副本。如果数据库希望提供强大的事务语义，这方面 B-Tree 显得更具有吸引力。

B-Tree 在数据库架构中已经根探蒂固，为许多工作负载提供了一贯良好的性能，所以不太可能在短期内会消失。对于新的数据存储，日志结构索引则越来越受欢迎。不存在快速和简单的规则来确定哪种存储引擎更适合你的用例，因此，实地的测试总是需要的。

### 1.2.5. 其它索引类型

#### 1.2.5.1. 二级索引

上面讨论了 key-value 索引，它们像关系模型中的主键 (primary key) 索引。主键唯一标识关系表中的一行，或文档数据库中的一个文档，或图形数据库中的一个顶点。数据库中的其他记录可以通过其主键 (或 ID) 来引用该行文档/顶点，该索引用于解析此类引用。 

当 key 不唯一（ 即可能有许多行，文档，顶点具有相同键）时同样可以用于索引，这个时候索引被称为二级索引。这种情况下若要基于 key-value 索引构建，则可以采取以下两种方式：
1. 使索引中当每个值成为匹配行标志符的列表，类似于全文索引的 posting list。 
> [!info] Position List
> 全文索引中的 posting list 是一个用于记录单个词项（term）出现在哪些文档中的数据结构。它是由一系列的文档 ID 和对应的词项频率构成的列表，每一个元素表示该词项出现在一个文档中，并且给出了该文档中该词项出现的次数。posting list 可以帮助搜索引擎快速地找到包含某个特定词项的文档，并且可以用来计算相关性得分。在实际的搜索引擎系统中，posting list 通常会被存储在倒排索引（Inverted Index）中，以便快速地查找包含特定词项的文档。
1. 追加一些行标志符来使每个键变得唯一。 

 无论哪种方式，B-tree 和日志结构索引都可以用作二级索引。

#### 1.2.5.2. 多列索引

迄今为止讨论的索引只将一个键映射到一个值。如果需要同时查询表的多个列或文档中的多个字段，那么这是不够的。 
  
最常见的多列索引类型称为级联索引，它通过将一列追加到另一列，将几个字段简单地组合成一个键 (索引的定义指定字段连接的顺序)。
  
多维索引是更普遍的一次查询多列的方法，这对地理空间数据尤为重要。例如，餐馆搜索网站可能有一个包含每个餐厅的纬度和经度的数据库。当用户在地图上查看餐馆时，网站需要搜索用户正在查看的矩形地图区域内的所有餐馆。这要求一个二维的范围查询，如下所示: 
  ![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20211226213448.png)
   
 标准 B-tree 或 LSM-tree 索引无法高效地应对这种查询，它只能提供一个纬度范围内 (但在任何经度) 的所有餐馆，或者所有经度范围内的餐厅 (在北极和南极之间的任何地方)，但不能同时满足。
  
一种选择是使用空格填充曲线将二维位置转换为单个数字，然后使用常规的 B-tree 索引。更常见的是使用专门的空间索引，如 [[附件资料#^372f2c|R树]]。例如， PostGIS 使用 PostgreSQL 的广义搜索树索引实现了地理空间索引作为 R 树。

### 1.2.6. 索引数据的存储方式

索引中的键是查询搜索的对象，而值则可以是以下两类之一: 
- 索引值存储实际的实际行，文档或顶点。
- 索引值存储对其他地方存储的行的引用。
    存储行的具体位置被称为 `堆文件`，并且它不以特定的顺序存储数据 (它可以是追加的，或者记录删掉的行以便用新数据在之后覆盖它们)。堆文件方法比较常见，这样当存在多个二级索引时，它可以避免复制数据，即每个索引只引用堆文件中的位置信息，实际数据仍保存在一个位置。

    当更新值而不更改键时，堆文件方法会非常高效: 只要新值的字节数不大于旧值，记录就可以直接覆盖。如果新值较大，则情况会更复杂，它可能需要移动数据以得到一个足够大空间的新位置。在这种情况下，所有索引都需要更新以指向记录的新的堆位四，或者在旧堆位置保留一个间接指针。

某些情况下，**从索引到堆文件的额外跳转对于读取来说意味着太多的性能损失，因此可能希望将索引行直接存储在索引中。这被称为聚簇索引**。例如，在 MySQL InnoDB 存储引擎中，表的主键始终是聚集索引，二级索引引用主键 (而不是堆文件位置)。

聚集索引 (在索引中直接保存行数据) 和非聚集索引 (仅存储索引中的数据的引用) 之间有一种折中设计称为[[Mysql大纲#3.2.1. 索引覆盖|覆盖索引 ]]或包含列的索引，它在索引中保存一些表的列值。它可以支持只通过索引即可回答某些简单查询 (在这种情况下，称索引覆盖了查询)。

与任何类型的数据冗余一样，聚集和覆盖索引可以加快读取速度，但是它们需要额外的存储，并且会增加写入的开销。此外，数据库还需要更多的工作来保证事务性，这样应用程序不会因为数据冗余而得到不一致的结果。

# 2. 数据编码

 程序通常使用 (至少) 两种不同的数据表示形式：
 
1. 在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对 CPU 的高效访问和操作进行了优化 (通常使用指针)。
2. 数据写入文件或网络发送时，将其编码为字节序列，如 JSON 文档。由于指针对其他进程没有意义，所以这个字节序列表示看起来与内存中使用的数据结构大不一样。

数据通常编码为 JSON、XML 或一些二进制编码格式，当然 JSON 与 XML 底层仍依赖于二进制编码。

## 2.1. 一些二进制编码格式

下面的示例都将以这个 JSON 作为对象进行编码说明：

```json
{
	"userName": "Martin",
	"favoriteNumber": 1337,
	"interests": ["daydreaming", "hacking"]
}
```

### 2.1.1. Thrift 与 Protocol Buffers

Apache Thrifth 和 Buffers (protobuf) 是基于相同原理的两种二进制编码库。 Protocol Buffers 最初是在 Google 开发的， Thrift 最初是在 Facebook 开发的，并且都是在 2007~2008 年开源的。Thrift 和 Protocol Buffers 都需要模式来编码任意的数据，类似于 JAVA 中的类，按照一个模式来进行编码。

基于上面的 JSON 示例，Thrift 编码的一个模式为：

 ```json
 struct Person{
	1: required string userName, 
	2: optional i 64 favoriteNumber,
	3: optional list<string> interests
}
 ```

Thrift 的 BinaryProtocol 编码为：

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20211228130846.png)

每个字段都有一个类型注释 (用于指示它是否是字符串、整数、列表等)，并且可以在需要时指定长度 (包括字符串的长度、列表中的项数)，数据中出现的字符串 ("Martin","daydreaming" , "hacking") 被编码为 ASCII。

Thrift CompactProtocol 编码在语义上等同于 BinaryProtocol，但如图 4-3 所示，它将相同的信息打包成只有 34 字节。它通过将字段类型和标签号打包到单字节中，并使用可变长度整数来实现。对数字 1337，**不使用全部 8 字节，而是使用两个字节进行编码，每字节的最高位用来指示是否还有更多的字节**。这意味着-64~63 之间的数字被编码为一字节， -8192~8191 之间的数字被编码成两个字节等。更大的数字需要更多字节。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20211228131319.png)

Protocol Buffers (只有一种二进制编码格式) 对相同的数据进行编码，如图 4-4 所示。它的位打包方式略有不同，但与 Thrift 的 CompactProtocol 非常相似。 Protocol Buffers 只用 33 字节可以表示相同的记录。

### 2.1.2. Avro

 Apache Avro 是另一种二进制编码格式，它与 Protocol Buffers 和 Thrift 有着一些有趣的差异。由于 Thrift 不适合 Hadoop 的用例，因此 Avro 在 2009 年作为 Hadoop 的子项目而启动。

## 2.2. 数据流传输

### 2.2.1. 基于数据库的数据流

在数据库中，写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。一般而言，几个不同的进程同时访问数据库是很常见的。这意味着数据库中的值可以由较新版本的代码写入，然后由仍在运行的旧版本代码读取。因此，数据库通常也需要向前兼容。

然而，还有一个额外的障碍。假设在记录模式中添加了一个字段，并且较新的代码将该新字段的值写入数据库。随后，旧版本的代码 (尚不知道该新字段) 将读取、更新记录并将其写回。在这种情况下，理想的行为通常是**旧代码保持新字段不变，即使它无法解释**。

### 2.2.2. REST

REST 不是一种协议，而是一个基于 HTTP 原则的设计理念。它强调简单的数据格式，使用 URL 来标识资源，并使用 HTTP 功能进行缓存控制、身份验证和内容类型协商。

### 2.2.3. SOAP

SOAP 是一种基于 XML 的协议，用于发出网络 API 请求。虽然它最常用 HTTP，但其目的是独立于 HTTP，并避免使用大多数 HTTP 相关但功能。它带有庞大而复杂但多种标准（WEB 服务框架，Web Servics Framework，称为 WS-\*）和新增但各种功能。

SOAP Web 服务的 API 使用被称为 WSDL (Web Services Description Language, 一种基于 XML 的语言) 来描述。 WSDL 支持代码生成，客户端可以使用本地类和方法调用 (编码为 XML 消息并由框架再次解码) 来访问远程服务。这在静态类型编程语言中非常有用，但在动态类型编程语言中用处不大。

由于 WSDL 的设计目标不是人类可读的，而且 SOAP 消息通常过于复杂，无法手动构建， SOAP 用户严重依赖工具支持、代码生成和 IDE。对于没有 SOAP 供应商支持的编程语言的用户来说，试图与 SOAP 服务集成非常困难。

### 2.2.4. RPC

RPC 模型试图使向远程网络服务发出请求看起来与在同一进程中调用编程语言中的函数或方法相同 (这种抽象称为位置透明)。

RPC 看起来很方便，但存在许多缺点：

- 本地函数调用是可预测的，并且成功或失败仅取决于控制的参数。网络请求是不可预测的。请求或响应可能由于网络问题而丢失。网络问题很常见，因此必须有所准备，例如重试失败的请求。
- 如果重试失败的网络请求，可能会发生请求实际上已经完成，只是响应丢失的情况。在这种情况下，重试将导致该操作被执行多次，除非在协议中建立重复数据消除 (幕等性) 机制。
- 每次调用本地函数时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且其延迟也有很大的变化。
- 调用本地函数时，可以高效地将引用 (指针) 传递给本地内存中的对象。当发出网络请求时，所有这些参数都需要被编码成可以通过网络发送的字节序列。
- 客户端和服务可以用不同的编程语言来实现，所以 RPC 框架必须将数据类型从一种语言转换成另一种语言。

虽然有这些问题，但是 RPC 现在却很流行。在本章提到的所有编码的基础上构建了各种 RPC 框架：例如 Thrift 和 Avro 带有 RPC 支持， gRPC 是使用 Protocol Buffers 的 RPC 实现， Finagle 也使用 Thrift，Rest. Ii 使用 HTTP 上的 JSON 。

新一代的 RPC 框架更加明确了远程请求与本地函数调用不同的事实。例如， Finagle 和 Rest. Ii 使用 `Futures` (Promises) 来封装可能失败的异步操作。Futures 还简化了需要并行请求多项服务的情况，并将其结果合并。**gRPC 支持流，其中调用不仅包括一个请求和一个响应，还包括一段时间内一系列的请求和响应**。

使用二进制编码格式的自定义 RPC 协议，可以实现比诸如 REST 上的 JSON 之类的通用 
协议更好的性能。但是， RESTful API 还有其他一些显著的优点：它有利于实验和调试 (只需使用 Web 浏览器或命令行工具 curl 即可向它发出请求，而无需任何代码生成或软件安装)，支持所有的主流编程语言和平台，并且有一个庞大的工具生态系统 (服务器、缓存、负载平衡器、代理、防火墙、监控、调试工具、测试工具等)。

由于这些原因， REST 似乎是公共 API 的主流风格。 **RPC 框架主要侧重于同一组织内多项服务之间的请求，通常发生在同一数据中心内**。

### 2.2.5. 基于消息传递的数据流

异步消息传递系统。它们与 RPC 的相似之处在于，客户端的请求 (通常称为消息) 以低延迟传递到另一个进程。它们与数据库的相似之处在于，不是通过直接的网络连接发送消息，而是通过称为消息代理 (也称为消息队列，或面向消息的中间件) 的中介发送的，该中介会暂存消息。

消息代理有以下优点：
- 如果接收方不可用或过载，它可以充当缓冲区，从而提高系统的可靠性。
- 它避免了发送方需要知道接收方的 IP 地址和端口号 (这在虚拟机经常容易起起停停的云部署中特别有用)。
- 它支持将一条消息发送给多个接收方。
- 它在逻辑上将发送方与接收方分离。
- 它可以自动将消息重新发送到崩溃的进程，从而防止消息丢失。

然而，与 RPC 的差异在于，**消息传递通信通常是单向的：发送方通常不期望收到对其消息的回复**。进程可能发送一个响应，但这通常是在一个独立的通道上完成的。这种通信模式是异步的：发送者不会等待消息被传递，而只是发送然后忘记它。

消息代理有以下的一些实现：
- 像 RabbitMQ 、 ActiveMQ 、 HornetQ 、 NATS 和 Apache Kafka 这样的消息队列。
- 分布式 Actor 的框架。
    Actor 模型是用于单个进程中并发的编程模型。逻辑被封装在 Actor 中，而不是直接处理线程 (以及竞争条件、锁定和死锁的相关问题)。每个 Actor 通常代表一个客户端或实体，它可能具有某些本地状态 (不与其他任何 Actor 共享)，并且它通过发送和接收异步消息与其他 Actor 通信。不保证消息传送: 在某些错误情况下，消息将丢失。由于每个 Actor 一次只处理一条消息，因此不需要担心线程，每个 Actor 都可以由框架独立调度。

    在分布式 Actor 框架中，这个编程模型被用来跨越多个节点来扩展应用程序。无论发送方和接收方是在同一个节点上还是在不同的节点上，都使用相同的消息传递机制。如果它们位于不同的节点上，则消息被透明地编码成字节序列，通过网络发送，并在另一端被解码。

    分布式的 Actor 框架实质上是将消息代理和 Actor 编程模型集成到单个框架中。但是，如果要对基于 Actor 的应用程序执行滚动升级，则仍需担心向前和向后兼容性问题，因为消息可能会从运行新版本的节点发送到运行旧版本的节点，反之亦然。
