#分布式 #消息队列 

## 1. 消息系统

向消费者通知新事件的常见方法是使用消息系统：生产者发送包含事件的消息，然后该消息被推送给一个或多个消费者。

消息系统需要注意以下几个问题：

1. 如果生产者发送消息的速度比消费者所能处理的快，会发生什么？
    一般来说，有三种选择：
	1. 系统丢弃消息
	2. 将消息缓存在队列中
	3. 激活背压，也称为流量控制（即阻止生产者发送更多消息）

	**如果消息被缓存在队列中，那么了解队列增长时会发生什么非常重要**。如果内存无法容纳所有队列，系统是否会崩溃？还是会将消息写入磁盘？如果是这样，磁盘访问又会如何影响消息传递系统的性能。
2. 如果节点崩溃或者暂时离线，是否会有消息丢失？
	与数据库一样，持久性可能需要写入磁盘和结合复制方案。而这都是有成本的。如果能够接受有时候会丢失消息，那么在同样的硬件上可能获得更高的吞吐量和更低的延迟。

### 1.1. 直接消息传递

许多消息系统将生产者直接连接到消费者，而不通过中间节点。如消费者在网络上公开服务，则生产者可以直接发出 HTTP 或 RPC 请求以将消息推送给消费者。这正是 webhooks 背后的想法: 一个服务的回调 URL 被注册到另一个服务中，并且每当事件发生时都会向该 URL 发出请求。

在其设计的目标场景下，这些直接消息传递方式运行效果不错，但是它们通常都**要求应用程序代码意识消息丢失的可能性**。它们只能支持有限的容错：即使协议可以检测并重新传输在网络中丢失的数据包，但通常还是假定生产者和消费者需要一直在线。

如果消费者处于离线状态，则可能会遗漏当他们掉线时发送的消息。有些协议允许生产者重试失败的消息传递，然而，如果生产者崩溃，则这种方法可能会失败，从而丢失了本应该重试的消息缓冲区。

### 1.2. 消息代理

一种广泛使用的替代方法是通过消息代理（也称为消息队列）发送消息，消息代理实质上是一种针对处理消息流而优化的数据库。它作为服务器运行，生产者和消费者作为客户端连接到它。生产者将消息写入代理，消费者通过从消息代理那里读取消息来接收消息。

通过将数据集中在代理中，这些**系统可以更容易地适应不断变化的客户端（连接、断开连接和崩溃），而持久性问题则被转移到代理那里**。一些消息代理只将消息保存在内存中，而另一些消息代理（取决于配置）将其写入磁盘，以便在代理崩溃的情况下不会丢失消息。对于速度慢的消费者，他们通常允许无限队列（而不是丢弃消息或背压），不过这种选择也可能取决于配置。

排队的结果也通常导致**消费者以异步方式工作**： 生产者发送消息时，它通常只等待代理确认它已经缓存了消息，而不会等待消息被消费者处理。向消费者的交付发生在将来某个不确定的时间点一通常是在几分之一秒内，但如果存在队列积压，有时会有很明显的延迟。

#### 1.2.1. 消息代理与数据库区别

一些消息代理甚至可以使用 XA 或 JTA 参与两阶段提交协议。这个特性使它们在本质上与数据库非常相似，虽然消息代理和数据库之间仍然存在着重要的实际差异：

- 数据删除时机不同
	数据库通常会保留数据直到被明确要求删除，而大多数消息代理在消息成功传递给消费者时就自动删除消息。这样的消息代理不适合长期的数据存储。
- 数据堆积对性能的影响
	由于消息代理很快删除了消息，多数消息系统会假定当前工作集相当小，即队列很短。如果因为消费者速度很慢，而使代理需要缓存很多消息的话（如果内存无法容纳所有的消息，可能会将部分消息唤出到磁盘），那么每个消息就需要更长的时间来处理，整个吞吐量可能会因此降低。
- 数据获取方式不同
	数据库通常支持二级索引和各种搜索数据的方式，而消息代理通常支持某种方式订阅匹配特定模式的主题。这些机制虽然是不同的，但本质上都是让客户端可以选择它们想要了解的部分数据。
- 数据通知方式不同
	查询数据库时，结果通常基于数据的时间点快照。如果另一个客户端随后向数据库写入更改查询结果的内容，那么第一个客户端不会发现之前的结果巳经过期 （除非它重复查询或轮询更改）。相比之下，消息代理不支持任意的查询，但是当数据发生变化时（即新消息可用时），它们会通知客户端。

#### 1.2.2. 消息代理多消费者实现

![](https://r2.129870.xyz/img/20220630004939.png)

当多个消费者读取同一个主题中的消息时，有两种主要的消息传递模式：

- 负载均衡模式
	每一条消息都只被传递给其中一个消费者，所以消费者可以共享主题中处理消息的工作。代理可以任意分配消息给消费者。当处理消息的代价很高时，此模式非常有用，因此希望能够添加消费者来并行处理消息（在 AMQP 中，可以通过让多个客户端使用同一个队列消费来实现负载均衡，而在 JMS 中，它称为共享订阅）。
- 扇出式
	每条消息都被传递给所有的消费者。扇出允许几个独立的消费者各自收听相同的消息广播，而不会相互影响，流相当于多个读取相同输入文件的不同批处理作业（此功能由 JMS 中的主题订阅提供和 AMQP 中的交换绑定）。

这两种模式可以组合使用。例如，两个独立的消费者群组可以各自订阅一个主题，使得每个组都能共同接收所有消息，但是在每个组内，每一条信息只有一个节点接收。

#### 1.2.3. 消息确认与重投

消费者可能会随时崩溃，所以可能会发生下面这些情况： 代理向消费者传递消息，但消费者从不处理消息，或者在崩溃之前只对消息进行了部分处理。为了确保消息不会丢失，消息代理使用确认机制：**客户端必须在处理完消息后显式地告诉代理，以便代理可以将其从队列中移除**。

如果与客户端的连接关闭或超时，而代理没有收到确认，则认为消息未处理，因此它将消息重新传递给另一个消费者（请注意，消息可能实际上已经完全处理，但是确认消息在网络传输过程中丢失。处理这种情况需要原子提交协议，正如所讨论的[[数据密集系统设计/数据密集型系统设计5：一致性与共识#1 3 2 实践中的分布式事务|实践中的分布式事务]]那样）。

当与负载均衡结合时，这种重新传递行为对消息的排序会产生一个有趣的影响。在下图中，消费者通常按照生产者发送的顺序处理消息。然而，消费者 2 在处理消息 m3 时崩溃，与此同时消费者正在处理消息 m4。未确认的消息 m3 随后被重新发送给消费者 1，结果消费者 1 按照 m4, m3, m5 的顺序处理消息。因此，m3 和 m4 不是以它们被生产者 1 发送顺序传递的。

![](https://r2.129870.xyz/img/20220630005335.png)

即使消息代理试图保留消息的顺序（如 JMS 和 AMQP 标准所要求的），**负载均衡与重新传递的组合也不可避免地导致消息被重新排序**。为了避免此问题，可以**为每个消费者使用单独的队列（即不使用负载均衡功能）**。如果消息彼此完全独立，消息重新排序就不成问题，但是如果消息之间存在因果依赖关系，那么它就成为很重要的问题了。

### 1.3. 分区日志

消息代理是基于瞬间的消息传递思维构建的，即使是将消息持久地写入磁盘的消息代理，在将消息传递给消费者之后，也会很快将其删除。数据库和文件系统采取相反的方式：在有人明确选择删除它之前，任何写入数据库或文件的内容通常都期望是永久保存。

思维方式上的这种差异对于如何创建派生数据有很大的影响。那么为什么不能混合使用，**将数据库的持久存储方法与消息传递的低延迟功能相结合**？这正是日志消息代理背后的想法。

#### 1.3.1. 基于日志的消息存储

日志是磁盘上一个仅支持追加式修改记录的序列。我们可以使用相同的结构来实现消息代理：生产者通过将消息追加到日志的末尾来发送消息，消费者通过依次读取日志来接收消息。如果消费者读到日志的末尾，它就开始等待新消息被追加的通知。 UNIX 工具 `tail -f` 正是基于这种工作思路的例子，它可以监视修改文件的尾部。

为了突破单个磁盘所能提供的带宽吞吐的上限，可以对日志进行分区。不同的节点负责不同的分区，使每个分区成为一个单独的日志，并且可以独立于其他分区读取和写入。然后可以将主题定义为一组分区，他们都携带相同类型的消息。 

![](https://r2.129870.xyz/img/20220630005628.png)

在每个分区中，代理为每个消息分配一个单调递增的序列号或偏移量（在上图，框中的数字是消息偏移量）。这样的序列号是非常有意义，因为**分区只能追加，所以分区内的消息是完全有序的。不同分区之间则没有顺序保证。**

##### 1.3.1.1. 分区分配策略

对于 topic 的多个分区与其对应的消费者，协调这些分区与消费者之间的关系被称为分区分配策略。Kafka 实现了以下几种策略：

1. RangeAssignor（范围分区策略）
    策略原理：按照单个 topic 维度，将分区尽可能均匀地分配给消费者。

    实现规则：

    1. 计算每个消费者最少应分配的分区数（总分区数 ÷ 消费者数）
    2. 将余数部分的分区按消费者顺序依次分配

    示例：假设某 topic 有分区 p0、p1、p2、p3、p4，消费者为 c0、c1、c2

    1.  5 ÷ 3 = 1...2，每个消费者至少分配 1 个分区
    2. 余下的 2 个分区依次分配给 c0、c1
    3. 最终分配：c0(p0, p1)、c1(p2, p3)、c2(p4)
2. RoundRobinAssignor（轮询分区策略）
    策略原理：跨所有订阅的 topic，对所有分区和消费者进行全局轮询分配。

    实现规则：

    1. 将所有消费者订阅的 topic 的所有分区按字典序排序
    2. 将所有消费者按字典序排序
    3. 采用轮询方式将分区分配给消费者（若消费者未订阅该 topic 则跳过）
3. StickyAssignor（粘性分区策略）
    策略原理：在保证分配均匀的前提下，尽可能保持原有的分区分配关系。

    设计目标（按优先级排序）：

    - 均匀性优先：分区分配尽可能均匀，消费者间分区数量差异最小化
    - 粘性保持：在满足均匀性的前提下，尽可能保持与上次分配的一致性
4. CooperativeStickyAssignor（协作式粘性分区策略）
    策略原理：基于 cooperative 协议实现渐进式重平衡，减少不必要的分区迁移。

    协议对比：

    - Eager 协议（前三种策略）：
        1. 触发重平衡时，所有消费者停止消费
        2. 全局重新分配所有分区
        3. 即使分区分配关系未变化，也会经历断开重连过程
    
    - Cooperative 协议（协作式策略）：
        1. 首先收集当前分区与消费者的分配关系
        2. 仅断开需要变更的分区连接
        3. 对空闲分区进行重新分配
        4. 未变化的分区分配关系保持连接状态

    优势：显著减少重平衡过程中的服务中断时间，提高系统可用性。

##### 1.3.1.2. 分区再平衡策略

分区再平衡（Rebalance）会在以下几种情况下触发：

- **消费者群组成员数发生变更**
    新增消费者加入、消费者主动退出（如优雅关闭）或被动离线（如心跳超时、进程崩溃）。

- **订阅主题数发生变化**
    Consumer Group 可以使用正则表达式订阅主题，例如 `consumer.subscribe(Pattern.compile("t.*c"))`。若新创建的主题符合订阅规则，将触发 Rebalance。

- **订阅主题的分区数发生变化**
    当 Kafka 中主题的分区数量发生变化（如新增分区）时，会触发 Rebalance。

Kafka 通过**协调者（Coordinator）**来管理消费者与订阅主题之间的关系。每个 Broker 都可能成为协调者，消费者以消费者组的形式通过协调者分配订阅主题的分区。消费者组通过 `groupId` 进行识别，相同 `groupId` 的消费者被视为同一个消费者组。

> [!info] 协调者（Coordinator）
> 协调者专门为 Consumer Group 服务，负责执行 Rebalance、提供位移管理和组成员管理等功能。
> 
> Consumer 端应用程序在提交位移时，实际上是向 Coordinator 所在的 Broker 提交位移。同样，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，由 Coordinator 负责执行消费者组的注册、成员管理等元数据管理操作。

**Rebalance 执行流程：**

1. **群主（Group Leader）的确定**
    当消费者要加入群组时，会向群组协调器发送 JoinGroup 请求。第一个加入群组的消费者将成为"群主"，群主从协调器获取群组的活跃成员列表，并负责为每个消费者分配分区。

2. **协调者的确定**
    Kafka 为某个 Consumer Group 确定 Coordinator 所在 Broker 的算法分为两步：
    
    **步骤 1：** 确定由位移主题（`__consumer_offsets`）的哪个分区来保存该 Group 数据

    ```java
    partitionId = Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)
    ```

    **步骤 2：** 上述分区的 Leader 副本所在 Broker 即为协调者
3. **消费者加入消费者组**
    消费者通过向群组协调器定期发送心跳来维持与群组的从属关系以及对分区的所有权。
4. **分区分配关系划分**
    群主从群组协调器获取群组成员列表，然后基于指定的[[数据密集型系统设计6：流数据处理#1.3.1.1. 分区分配策略| 分区分配策略]]为每个消费者分配分区。
5. **分区分配关系下发**
    群主完成分配后，将分配情况发送给群组协调器，协调器再将这些信息发送给各个消费者。每个消费者只能看到自己的分配信息，只有群主知道所有消费者的分配信息。

![image.png](https://r2.129870.xyz/img/2025/85f32b94cb8a580d0c2729a685bae58f.png)

##### 1.3.1.3. 分区再平衡的避免

分区再平衡过程对消费性能有显著影响。在 Rebalance 过程中，**所有 Consumer 实例都会停止消费**，等待 Rebalance 完成。此外，当前 Rebalance 的设计是所有 Consumer 实例共同参与，重新分配所有分区，而更高效的做法应该是尽量减少分配方案的变动。

由于分区再平衡的代价很高，应该尽量避免不必要的 Rebalance，以提高消费者的整体吞吐量。虽然订阅主题的分区数和订阅主题数量的变化通常由运维操作产生且无法避免，但**大部分情况下导致 Rebalance 的原因是组成员数量发生变化**。

以下两种情况下，消费者虽然没有宕机，但也会被视为离线：

- **未及时发送心跳**
    可以通过设置合理的心跳时间来减少这种异常情况的发生。
- **Consumer 消费时间过长**
    除了心跳时间之外，如果两次 `poll()` 调用的最大间隔超过 `max.poll.interval.ms` 配置值，该消费者也会被踢出群组。因此需要根据实际业务消费情况配置合理的消费超时时间。
    
    > [!question] 为何要控制消费时间？
    > Kafka 的心跳设计体现了其独特的设计哲学：
    > 
    > **1. 关注业务活跃度而非进程活跃度**
    > 当消费者进程出现异常、死锁或无响应等情况时，虽然进程"看起来活着"，但无法正常处理消息。由于 Kafka 采用分区独占模型，这会导致整个分区的消息积压。
    > 
    > **2. 通过背压机制实现自动负载均衡**
    > 通过控制消费时间，当某个消费者处理能力不足时，会触发重新分配，将该分区的消息转移给其他消费者处理。
    > 
    > **3. 防止僵尸 Consumer 占用资源**
    > 避免"活着但不工作"的消费者长期占用分区资源，确保系统的整体健康性。

#### 1.3.2. 日志消息系统与传统消息系统对比

因为多个**消费者可以独立地读取日志而不会相互影响，读取消息不会将其从日志中删除**，因此**基于日志的方法很自然地支持扇出式消息传递**。为了在一组消费者之间实现负载均衡，代理可以将整个分区分配给消费者组中的节点，而不是将单个消息分配给消费者客户端。

每个客户端都会使用分配给它所在分区中的所有消息。通常，当消费者被分配了一个日志分区时，它将以直接的单线程方式顺序读取分区中的消息。这种粗粒度的负载均衡方法有一些缺陷：

- 因为同一分区内的消息将被传递到同一节点，所以消费一个主题的节点数最多等于该主题中的日志分区数
- 如果单个消息处理缓慢，则会阻碍该分区中的后续消息的处理
- 消费者空闲问题，如果消费者数量多于分区数量，那么部分消费者将无法消费
- 数据倾斜问题，某个分区可能出现热点数据导致访问不均匀

相较于传统消息系统，日志消息系统具有以下优势：

- 真正的并行处理，多个分区消息者并发处理，消费者之间无锁的竞争
- 消息的顺序保证，对于单个分区消费顺序严格有序
- 分区的存储结构更易于扩展，每个分区有独立的日志文件、独立的索引、独立的副本机制。单个分区的故障不影响其他分区，分区数据可以分布在不同节点上达到负载均衡的目的
- 消息进度简化管理，无需协调多消费者之间的消费进度

因此，**在消息处理的代价很高，希望在逐个消息的基础上并行处理，而且消息排序又不那么重要的情况下， JMS/AMQP 类型的消息代理更可取。另一方面，在消息吞吐量高的情况下，每个消息处理速度快，消息顺序又很重要的情况下，基于日志的方法工作得很好**。

#### 1.3.3. 消费者偏移量

顺序读取一个分区可以很容易地判断哪些消息已经被处理：**所有偏移量小于消费者当前偏移量的消息已经被处理，并且所有更大偏移量的消息还没有被看到**。因此，代理不需要跟踪每条消息的确认，只需要定期记录消费者的偏移量。在这种方法中，减少的记录开销以及可以使用批处理和流水线操作的机会有助于提高基于日志的系统的吞吐量。

如果消费者节点失败，则消费者组中的另一个节点将被分配到失败的消费者分区，并以最后记录的偏移量开始使用消息。如果消费者已经处理了后续的消息，但还没有记录它们的偏移量，那么在重新启动后这些消息将被再次处理。

#### 1.3.4. 磁盘空间使用

如果持续不断地追加日志，磁盘空间最终将被耗尽。为了回收磁盘空间，日志实际上是被分割成段，并且不时地将旧段删除或归档保存。

这就意味着，如果一个消费者的速度慢到难以跟上消息产生的速度，并且远远落后以至于消费者偏移最指向了已经被删除的片段，那么消费者将会错过一些消息。实际上，日志实现了一个有限大小的缓冲区，当缓冲区变满时，旧的消息就被丢弃，该缓冲区也被称为循环缓冲区或环形缓冲区。由于该缓冲区在磁盘上，因此它可以非常大。

不管保留多长时间的消息，因为每个消息都被写入到磁盘，因此日志的吞吐量基本保持不变。这种行为与将消息默认保存在内存中，仅当队列变得过大时才将它们写入磁盘的消息传递系统相比，差异明显： 当队列很短的时候这些系统是很快的，当开始写入磁盘时，会变得很慢，因此吞吐量取决于保留的历史记录数量。

#### 1.3.5. 重新处理消息

我们之前提到过，**使用 AMQP 和 JMS 风格的消息代理时，由于会导致消息在代理上被删除，因此处理和确认操作可视为带有一定的破坏性**。另一方面，**在基于日志的消息代理中，使用消息更像是从文件读取： 这是只读操作，并不会更改日志**。

除了消费者的任何输出之外，处理的唯一副作用是消费者偏移量前移了。但是偏移量在消费者的控制之下，因此在必要时可以轻松地对其进行操作。例如，可以用昨天的偏移量启动一个消费者的副本，并将输出写到不同的位置，以便重新处理最后一天的消息。可以通过改变处理代码多次重复此操作。

这个特点使得基于日志的消息系统更像批处理过程，其中派生数据通过可重复的转换过程与输入数据明确分离。它支持更多的实验性尝试，也更容易从错误和故障中进行恢复，从而成为集成数据流的不错选择。
