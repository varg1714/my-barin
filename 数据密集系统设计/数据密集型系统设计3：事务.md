#数据库 #分布式 #事务

# 1. 事务

## 1.1. 事务的 ACID 属性

### 1.1.1. 原子性

ACID 中原子性所定义的特征是：在出错时中止事务，并将部分完成的写入全部丢弃。在成功时提交所有改动。

原子性保证事务中所有的操作要么全做，要么全不做。

### 1.1.2. 一致性

ACID 中的一致性的主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等条件）。 

这种一致性本质上要求**应用层来维护状态一致（或者恒等），应用程序有责任正确地定义事务来保持一致性，这不是数据库可以保证的事情**： 即如果提供的数据修改违背了恒等条件，数据库很难检测进而阻止该操作（数据库可以完成针对某些特定类型的恒等约束检查，例如使用外键约束或唯一性约束。但通常主要靠应用程序来定义数据的有效／无效状态，数据库主要负责存储）。

### 1.1.3. 隔离性

ACID 语义中的隔离性意味着并发执行的多个事务相互隔离，它们不能互相交叉，不应相互干扰。

### 1.1.4. 持久性

数据库系统本质上是提供一个安全可靠的地方来存储数据而不用担心数据丢失等。持久性就是这样的承诺，它保证一且事务提交成功，即使存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失。

对于单节点数据库，持久性通常意味着数据已被写入非易失性存储设备，如硬盘或 SSD。在写入执行过程中，通常还涉及预写日志等。这样万一磁盘数据损坏可以进行恢复。而对于支持远程复制的数据库，持久性则意味若数据已成功复制到多个节点。为了实现持久性的保证，数据库必须等到这些写入或复制完成之后才能报告事务成功提交。

## 1.2. 弱隔离级别

如果两个事务操作的是不同的数据，即不存在数据依赖关系，则它们可以安全地并行执行。只有出现某个事务修改数据而另一个事务同时要读取该数据，或者两个事务同时修改相同数据时，才会引发并发问题（引入了竞争条件）。

实现隔离绝不是想象的那么简单。可串行化的隔离会严重影响性能，而许多数据库却不愿意牺牲性能，因而更多倾向于采用较弱的隔离级别，它可以防止某些但并非全部的并发问题。这些弱隔离级别理解起来更为困难，甚至可能会带来一些难以捉摸的隐患，但在实践中还是被广泛使用。

### 1.2.1. 读提交

读提交是最基本的事务隔离级别，它只提供以下两个保证：

1. 读数据库时，只能看到已成功提交的数据（防止脏读)。

2. 写数据库时，只会覆盖已成功提交的数据（防止脏写)。

#### 1.2.1.1. 防止脏读

- 如果事务需要更新多个对象，脏读意味着另一个事务可能会看到部分更新，而非全部。
- 如果事务发生中止，则所有写入操作都需要回滚。如果发生了脏读，这意味着它可能会看到一些稍后被回滚的数据，而这些数据并未实际提交到数据库中。之后所引发的后果可能都会变得难以预测。

#### 1.2.1.2. 防止脏写

如果事务需要更新多个对象，脏写会带来非预期的错误结果。 

#### 1.2.1.3. 读提交的实现

1. 防止脏写的实现
	**数据库通常采用行级锁来防止脏写**：当事务想修改某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（或中止）。给定时刻，只有一个事务可以拿到特定对象的锁，如果有另一个事务尝试更新同一个对象，则必须等待，直到前面的事务完成了提交（或中止）后，才能获得锁并继续。这种锁定是由处于读－提交模式（或更强的隔离级别）数据库自动完成的。
2. 防止脏读的实现
	那如何防止脏读呢？ 一种选择是使用相同的锁，所有试图读取该对象的事务必须先申请锁，事务完成后释放锁。从而确保不会发生读取一个脏的、未提交的值（因为锁在那段期间一直由一个事务所持有）。

	然而，读锁的方式在实际中并不可行，因为运行时间较长的写事务会导致许多只读的事务等待太长时间，这会严重影响只读事务的响应延迟，且可操作性差：由于读锁，应用程序任何局部的性能问题会扩散进而影响整个应用，产生连锁反应。

	因此，大多数数据库以下做法来防止脏读： **对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本**。在事务提交之前，所有其他读操作都读取旧值。仅当写事务提交之后，才会切换到读取新值。

### 1.2.2. 快照隔离级别与可重复读

仅靠读提交级别是不够的，它会出现不可重复读取 (nonrepeatable read) 或者说 `读倾斜 (read skew)` 的问题，这里的倾斜则主要是指时间异常。

快照级别隔离这是解决上述问题最常见的手段。其总体想法是，**每个事务都从数据库的一致性快照中读取**，事务一开始所看到是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事务都只看到该特定时间点的旧数据。

#### 1.2.2.1. 快照隔离级别的实现

与读提交隔离类似，快照级别隔离的实现通常采用写锁来防止脏写，这意味着正在进行写操作的事务会阻止同一对象上的其他事务。但是，读取则不需要加锁。从性能角度看，快照级别隔离的一个关键点是读操作不会阻止写操作，反之亦然。这使得数据库可以在处理正常写入的同时，在一致性快照上执行长时间的只读查询，且两者之间没有任何锁的竞争。

当事务读数据库时，通过事务 ID 可以决定哪些对象可见，哪些不可见。要想对上层应用维护好快照的一致性，需要精心定义数据的可见性规则。例如：
1. 每笔事务开始时，数据库列出所有当时尚在进行中的其他事务（即尚未提交或中止），然后忽略这些事务完成的部分写入（尽管之后可能会被提交），即不可见。
2. 所有中止事务所做的修改全部不可见。
3. 较晚事务 ID (即晚于当前事务）所做的任何修改不可见，不管这些事务是否完成了提交。
4. 除此之外，其他所有的写入都对应用查询可见。

换句话说，仅当以下两个条件都成立，则该数据对象对事务可见：
1. 事务开始的时刻，创建该对象的事务已经完成了提交。
2. 对象没有被标记为删除，或者即使标记了，但删除事务在当前事务开始时还没有完成提交。

长时间运行的事务可能会使用快照很长时间，从其他事务的角度来看，它可能在持续访问正在被覆盖或删除的内容。由于没有就地更新，而是每次修改总创建一个新版本，因此数据库可以以较小的运行代价来维护一致性快照。

#### 1.2.2.2. 索引与快照隔离级别

接下来一个问题是，这种多版本数据库该如何支持索引呢？

1. 基于当前 B+树做控制
	一种方案是索引直接指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。当后台的垃圾回收进程决定删除某个旧对象版本时，对应的索引条目也需要随之删除。

	在实践中，有许多细节决定了多版本并发控制的实际性能表现。例如，可以把同一对象的不同版本放在一个内存页面上， PostgreSQL 采取这样的优化措施来避免更新索引。
2. 基于写时复制技术
	CouchDB 、 Datomic 和 LMDB 则使用另一种方法。它们主体结构是 B-tree , 但采用了一种追加／写时复制的技术，当需要更新时，不会修改现有的页面，而总是创建一个新的修改副本，拷贝必要的内容，然后让父结点，或者递归向上直到树的 root 结点都指向新创建的结点。那些不受更新影响的页面都不需要复制，保持不变并被父结点所指向。

	这种采用追加式的 B-tree, 每个写入事务（或一批事务）都会创建一个新的 B-tree root, 代表该时刻数据库的一致性快照。这时就没有必要根据事务 ID 再去过滤掉某些对象，每笔写入都会修改现有的 B-tree, 因为之后的查询可以直接作用于特定快照 B-tree (有利于查询性能）。采用这种方法依然需要后台进程来执行压缩和垃圾回收。

### 1.2.3. 防止更新丢失

我们所讨论的读－提交和快照级别隔离主要都是为了解决只读事务遇到并发写时可以看到什么（虽然中间也涉及脏写问题），总体而言我们还没有触及另一种情况，即两个写事务并发，而脏写只是写并发的一个特例。写事务并发还会带来其他一些值得关注的冲突问题，最著名的就是更新丢失问题。

更新丢失可能发生在这样一个操作场景中：应用程序从数据库读取某些值，根据应用逻辑做出修改，然后写回新值 (read-modift-write 过程）。当有两个事务在同样的数据对象上执行类似操作时，**由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失**。这种冲突还可能在其他不同的场景下发生，例如：

- 递增计数器，或更新账户余额（需要读取当前值，计算新值并写回更新后的值）。
- 对某复杂对象的一部分内容执行修改，例如对 JSON 文档中一个列表添加新元素 （需要读取并解析文档，执行更改并写回修改后的文档）。
- 两个用户同时编辑 wiki 页面，且每个用户都尝试将整个页面发送到服务器，覆盖数据库中现有内容以使更改生效。

#### 1.2.3.1. 原子写操作

**许多数据库提供了原子更新操作，以避免在应用层代码完成读－修改－写回操作**，如果支持的话，通常这就是最好的解决方案。

原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会其他事务可以读它，这种技术有时被称为游标稳定性。另一种实现方式是**强制所有的原子操作都在单线程上执行**。

#### 1.2.3.2. 显式加锁

如果数据库不支持内置原子操作，另一种防止更新丢失的方法是由应用程序显式锁定待更新的对象。然后，应用程序可以执行读－修改－写回这样的操作序列；此时如果有其他事务尝试同时读取对象，则必须等待当前正在执行的序列全部完成。

#### 1.2.3.3. 自动检测更新丢失

原子操作和锁都是通过强制读－修改－写回操作序列串行执行来防止丢失更新。另一种思路则是先让他们并发执行，但如果事务管理器检测到了更新丢失风险，则会中止当前事务，并强制回退到安全的读－修改－写回方式。

该方法的一个优点是数据库完全可以借助快照级别隔离来高效地执行检查，更新丢失检测是一个非常赞的功能，应用层代码因此不用依赖于某些特殊的数据库功能。开发者可能会不小心忘记使用锁或原子操作，但更新丢失检测会自动生效，有效地避免这类错误。

#### 1.2.3.4. 原子比较和设置

在不提供事务支持的数据库中，有时你会发现它们支持原子比较和设置操作。使用该操作可以避免更新丢失，即**只有在上次读取的数据没有发生变化时才允许更新**；如果已经发生了变化，则回退到读－修改－写回方式。

例如，为了防止两个用户同时更新同一个 wiki 页面，可以尝试下面的操作，这样只有当页面从上次读取之后没发生变化时，才会执行当前的更新：

```sql


# This may or may not be safe, depending on the database implementation
UPDATE wiki_pages SET content='new content' WHERE id= 1234 AND content='old content;

```

#### 1.2.3.5. 冲突解决与复制

对于支持多副本的数据库，防止丢失更新还需要考虑另一个维度： 由于多节点上的数据副本，不同的节点可能会并发修改数据，因此必须采取一些额外的措施来防止丢失更新。

多副本数据库通常支持多个并发写，然后保留多个冲突版本（互称为兄弟），之后由应用层逻辑或依靠特定的数据结构来解决、合并多版本。

如果操作可交换（顺序无关，在不同的副本上以不同的顺序执行时仍然得到相同的结果），则原子操作在多副本情况下也可以工作。

而最后写入获胜 (LWW) 冲突解决方法则容易丢失更新。不幸的是，目前 LWW 是许多多副本数据库的默认配置。

### 1.2.4. 写倾斜与幻读

首先，设想这样一个例子： 你正在开发一个应用程序来帮助医生管理医院的轮班。通常，医院会安排多个医生值班，医生也可以申请调整班次（例如他们自己生病了），但前提是确保至少一位医生还在该班次中值班。

现在情况是， Alice 和 Bob 是两位值班医生。两人碰巧都感到身体不适，因而都决定请假。不幸的是，他们几乎同一时刻点击了调班按钮。接下来发生的事情如图所示。每笔事务总是首先检查是否至少有两名医生目前在值班。如果是的话，则有一名医生可以安全的离开。由于数据库正在使用快照级别隔离，两个检查都返回有两名医生，所以两个事务都安全地进入到下一个阶段。接下来 Alice 更新自己的值班记录为离开，同样， Bob 也更新自己的记录。两个事务都成功提交，最后的结果却是没有任何医生在值班，显然这违背了至少一名医生值班的业务要求。

![](https://r2.129870.xyz/img/20220617005809.png)

#### 1.2.4.1. 定义写倾斜

这种异常情况称为 `写倾斜`。它既不是一种脏写，也不是更新丢失，两笔事务更新的是两个不同的对象（分别是 Alice 和 Bob 的值班记录）。这里的写冲突并不那么直接，但很显然这的确是某种竞争状态： 试想，如果两笔事务是串行执行，则第二个医生的申请肯定被拒绝；只有同时执行两个事务时才会引发该异常。

可以将写倾斜视为一种更广义的更新丢失问题。即**如果两个事务读取相同的一组对象，然后更新其中一部分： 不同的事务可能更新不同的对象，则可能发生写倾斜**；而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失（具体取决于时间窗口）.

我们已经给出了多种防范更新丢失的手段。然而对于写倾斜，可选的方案则有很多限制:

- 由于涉及多个对象，单对象的原子操作不起作用。

- 基于快照级别隔离来实现更新丢失自动检测也有问题： 目前所有的数据库实现，包括 PostgreSQL 的可重复读， MySQL/InnoDB 可重复读， Oracle 可串行化以及 SQL Server 的快照级别隔离级别都不支持检测写倾斜问题。自动防止写倾斜要求真正的可串行化隔离。

- 某些数据库支持自定义约束条件，然后由数据库代为检查、执行约束（例如，唯一性，外键约束或限制一些特定值）。但是，至少一名医生值班这样的要求涉及对多个对象进行约束，目前大多数数据库不支持这种类型约束，所以取决于具体的数据库，开发者可能可以采用触发器或物化视图来自己实现类似约束。

#### 1.2.4.2. 写倾斜例子

写倾斜可能看起来很晦涩拗口，可一且深刻意识到问题的本质，就会注意到还有更多可能发生的场景。下面就是一些例子：

- 会议室预订系统
	假设要求同一时间、同一个会议室不能被预订两次。当有人想要预订时，首先检查是否有冲突的预订（即对同一房间的预订存在时间范围冲突），如果没有，则提交申请。

	需要指出，快照级别隔离无法阻止并发用户预订同一个会议室。为了保证预订不会产生冲突，需要可串行化的隔离。
- 多人游戏
	对于棋盘游戏，我们使用加锁来防止更新丢失（即两个玩家不能同时移动同一个数字）。但是，锁并不能阻止玩家将两个不同的数字移动到棋盘上的同一个位置上，或者其他可能违反游戏规则的移动。这取决于具体的游戏规则，可能需要更多的条件约束，否则很容易发生写倾斜。

#### 1.2.4.3. 写倾斜产生原因

上述所有写倾斜的例子都遵循以下类似的模式：

1. 首先输入一些匹配条件，即采用 SELECT 查询所有满足条件的行。
	例如，至少有两名医生正在值班，同一时刻房间没有预订，棋盘的某位置没有出现数字，用户名还没有被占用，账户里还有余额等。
2. 根据查询的结果，应用层代码来决定下一步的操作（有可能继续，或者报告错误并中止）。
3. 如果应用程序决定继续执行，它将发起数据库写入 (INSERT, UPDATE 或 DELETE) 并提交事务。
	而**这个写操作会改变步骤 2 做出决定的前提条件**。换句话说，如果提交写入之后再重复执行步骤 1 的 SELECT 查询，就会返回完全不同的结果，原因是刚刚的写操作改变了决定的前提条件（现在只有一名医生在值班，现在会议室已被预订，现在棋盘位置已经出现了数字，现在用户名已袚占用，现在余额已经不足等）。

这种**在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读**。快照级别隔离可以避免只读查询时的幻读，但是对于我们上面所讨论那些读－写事务，它却无法解决棘手的写倾斜问题。

#### 1.2.4.4. 实体化冲突

如果问题的关键是查询结果中没有对象（空）可以加锁，或许可以人为引入一些可加锁的对象？

例如，对于会议室预订的例子，构造一个时间－房间表，表的每一行对应于特定时间段（例如最小 15 分钟间隔）的特定房间。我们提前，例如对接下来的 6 个月，创建好所有可能的房间与时间的组合。

这种方法称为实体化冲突（或物化冲突），它**把幻读问题转变为针对数据库中一组具体行的锁冲突问题**。然而，弄清楚如何实现实体化往往也具有挑战性，实现过程也容易出错，这种把一个并发控制机制降级为数据模型的思路总是不够优雅。出于这些原因，除非万不得已，没有其他可选方案，我们不推荐采用实体化冲突。而在大多数情况下，可串行化隔离方案更为可行。

## 1.3. 串行化

可串行化隔离通常被认为是最强的隔离级别。它保证即使事务可能会并行执行，但最终的结果与每次一个即串行执行结果相同。这意味着，如果事务在单独运行时表现正确，那么它们在并发运行时结果仍然正确，换句话说，数据库可以防止所有可能的竞争条件。

### 1.3.1. 实际串行化执行

解决并发问题最直接的方法是避免并发：即在一个线程上按顺序方式每次只执行一个事务。这样我们完全回避了诸如检测、防止事务冲突等间题，其对应的隔离级别一定是严格串行化的。

串行化意味着现在转向单线程执行，这意味着什么呢？ 有以下两方面的进展促使我们重新做出思考：

1. 内存越来越便宜，现在许多应用可以将整个活动数据集都加载到内存中。当事务所需的所有数据都在内存中时，事务的执行速度要比等待磁盘 I/O 快得多。

2. 数据库设计人员意识到 OLTP 事务通常执行很快，只产生少量的读写操作。相比之下，运行时间较长的分析查询则通常是只读的，可以在一致性快照（使用快照隔离）上运行，而不需要运行在串行主循环里。

#### 1.3.1.1. 存储过程

对于交互式的事务处理，大量时间花费在应用程序与数据库之间的网络通信。如果不允许事务并发，而是一次仅处理一个，那么吞吐量非常低，数据库总是在等待应用提交下一个请求。

在这种类型的数据库中，为了获得足够的吞吐性能，需要能够同时处理多个事务。出于这个原因，**采用单线程串行执行的系统往往不支持交互式的多语句事务**。**应用程序必须[[Redis大纲#6.4. Redis 的事务|提交整个事务代码]]作为存储过程打包发送到数据库**。这之间的差异如图所示。把事务所需的所有数据全部加载在内存中，使存储过程高效执行，而无需等待网络或磁盘 I/O。

![](https://r2.129870.xyz/img/20220617011349.png)

#### 1.3.1.2. 分区

串行执行所有事务使得并发控制更加简单，但是数据库的吞吐量被限制在单机单个 CPU 核。虽然只读事务可以在单独的快照上执行，但是对于那些高写入需求的应用程序，单线程事务处理很容易成为严重的瓶颈。

为了扩展到多个 CPU 核和多节点，可以对数据进行分区， VoltDB 支持这种配置模式。如果你能找到一个方法来对数据集进行分区，使得每个事务只在单个分区内读写数据，这样每个分区都可以有自己的事务处理线程且独立运行。此时为每个 CPU 核分配一个分区，则数据库的总体事务吞吐量可以到达与 CPU 核的数量成线性比例关系。

但是，对于跨分区的事务，数据库必须在涉及的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行化。

#### 1.3.1.3. 串行执行小结

当满足以下约束条件时，串行执行事务可以实现串行化隔离：

- 事务必须简短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能。

- 仅限于活动数据集完全可以加载到内存的场景。有些很少访问的数据可能会被移到磁盘，但万一单线程事务需要访问它，就会严重拖累性能。

- 写入吞吐量必须足够低，才能在单个 CPU 核上处理；否则就需要采用分区，最好没有跨分区事务。

- 跨分区事务虽然也可以支持，但是占比必须很小。

### 1.3.2. 两阶段加锁

近三十年来，可以说数据库只有一种被广泛使用的串行化算法，那就是两阶段加锁 (two-phase locking, 2PL)。

两阶段加锁方法类似，但锁的强制性更高。多个事务可以同时读取同一对象，但只要出现任何写操作（包括修改或删除），则必须加锁以独占访问：

- 如果事务 A 已经读取了某个对象，此时事务 B 想要写入该对象，那么 B 必须等到 A 提交或中止之才能继续。以确保 B 不会在事务 A 执行的过程中间去修改对象。

- 如果事务 A 已经修改了对象，此时事务 B 想要读取该对象，则 B 必须等到 A 提交或中止之后才能继续。对于 2PL, 不会出现读到旧值的情况。

因此 2PL 不仅在并发写操作之间互斥，读取也会和修改产生互斥。快照级别隔离的口号“读写互不干扰”非常准确地点明了它，这是和两阶段加锁的关键区别。另一方面，因为 2PL 提供了串行化，所以它可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜。

#### 1.3.2.1. 两阶段加锁实现

此时数据库的每个对象都有一个读写锁来隔离读写操作。即锁可以处于共享模式或独占模式。基本用法如下：

1. 如果事务要读取对象，必须先以共享模式获得锁。可以有多个事务同时获得一个对象的共享锁，但是如果某个事务已经获得了对象的独占锁，则所有其他事务必须等待。

2. 如果事务要修改对象，必须以独占模式获取锁。不允许多个事务同时持有该锁 （包括共享或独占模式），换言之，如果对象上已被加锁，则修改事务必须等待。

3. 如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。升级锁的流程等价于直接获得独占锁。

4. 事务获得锁之后，一直持有锁直到事务结束（包括提交或中止）。这也是名字两阶段的来由，在第一阶段即事务执行之前要获取锁，第二阶段（即事务结束时）则释放锁。

由于使用了这么多的锁机制，所以很容易出现死锁现象，例如事务 A 可能在等待事务 B 释放它的锁，而事务 B 在等待事务 A 释放所持有的锁。数据库系统会自动检测事务之间的死锁情况，并强行中止其中的一个以打破僵局，这样另一个可以继续向前执行，而被中止的事务需要由应用层来重试。

#### 1.3.2.2. 两阶段加锁的性能

两阶段加锁的主要缺点，或者说自 1970 年以来并不被所有入接纳的主要原因在于性能：其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多。部分原因在于锁的获取和释放本身的开销，但更重要的是其降低了事务的并发性。按 2PL 的设计，两个并发事务如果试图做任何可能导致竞争条件的事情，其中一个必须等待对方完成。

因此，在 2PL 模式下数据库的访问延迟具有非常大的不确定性，如果工作负载存在严重竞争，以百分比方式观察延迟指标会发现非常缓慢。试想这种情况，某个事务本身很慢，或者是由于需要访问大批数据而获得了许多锁，则它还会导致系统的其他部分都停顿下来。如果应用需要稳定如一的性能，这种不确定性就是致命的。

#### 1.3.2.3. 谓词锁

对于加锁，我们还忽略了一个微妙但重要的细节。如前面[[数据密集系统设计/数据密集型系统设计3：事务#写倾斜与幻读|写倾斜与幻读]]中的幻读问题，即一个事务改变另一个事务的查询结果。可串行化隔离也必须防止幻读问题。

如何实现呢？技术上讲，我们需要引入一种谓词锁（或者属性谓词锁）。它的作用类似于之前描述的共享/独占锁，而区别在于，它并不属于某个特定的对象（如表的某一行），而是作用于满足某些搜索条件的所有查询对象。

谓词锁会限制如下访问：

1. 如果事务 A 想要读取某些满足匹配条件的对象，例如采用 SELECT 查询，它必须以共享模式获得查询条件的谓词锁。 

2. 如果另一个事务 B 正持有任何一个匹配对象的互斥锁，那么 A 必须等到 B 释放锁之后才能继续执行查询。

3. 如果事务 A 想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁匹配（即冲突）。如果事务 B 持有这样的谓词锁，那么 A 必须等到 B 完成提交（或中止）后才能继续。

这里的关键点在于，谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象（幻读）。将两阶段加锁与谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，隔离变得真正可串行化。

#### 1.3.2.4. 索引区间锁

不幸的是，谓词锁性能不佳：如果活动事务中存在许多锁，那么检查匹配这些锁就变得非常耗时。因此，**大多数使用 2PL 的数据库实际上实现的是索引区间锁**（或者 nextkey locking), 本质上它是对谓词锁的简化或者近似。

**简化谓词锁的方式是将其保护的对象扩大化**，首先这肯定是安全的。例如，如果一个谓词锁保护的是查询条件是：房间 123, 时间段是中午至下午 1 点，则一种方式是通过扩大时间段来简化，即保护 123 房间的所有时间段；或者另一种方式是扩大房间，即保护中午至下午 1 点之间的所有房间（而不仅是 123 号房间）。这样，任何与原始谓词锁冲突的操作肯定也和近似之后的区间锁相冲突。

的确，索引区间锁不像谓词锁那么精确（会锁定更大范围的对象，而超出了串行化所要求的部分），但由于开销低得多，可以认为是一种很好的折衷方案。

如果没有合适的索引可以施加区间锁，则数据库可以回退到对整个表施加共享锁。这种方式的性能肯定不好，它甚至会阻止所有其他事务的写操作，但的确可以保证安全性。

### 1.3.3. 可串行化的快照隔离

本章巳经给大家展示了数据库并发方面很多让入纠结、黯淡的一面。两阶段加锁虽然可以保证串行化，但性能差强入意且无法扩展（由于串行执行）；弱级别隔离虽然性能不错，但容易引发各种边界条件（如更新丢失，写倾斜，幻读等）。那么，串行化隔离与性能是不是从根本上就是互相冲突而无法兼得吗？

或许并非如此。最近一种称为可串行化的快照隔离 (Serializable Snapshot Isolation, SSI) 算法看起来让入眼前一亮。它提供了完整的可串行性保证，而性能相比于快照隔离损失很小。

#### 1.3.3.1. 悲观与乐观的并发控制

两阶段加锁是一种典型的悲观并发控制机制。它基于这样的设计原则：如果某些操作可能出错（例如与其他并发事务发生了锁冲突），那么直接放弃，采用等待方式直到绝对安全。这和多线程编程中互斥锁是一致的。

某种意义上讲，**串行执行是种极端悲观的选择**：事务执行期间，等价于事务对整个数据库（或数据库的一个分区）持有互斥锁。而我们只能假定事务执行得足够快、持锁时间足够短，来稍稍弥补这种悲观色彩。

相比之下，**可串行化的快照隔离则是一种乐观并发控制。在这种情况下，如果可能发生潜在冲突，事务会继续执行而不是中止，寄希望一切相安无事；而当事务提交时 （只有可串行化的事务被允许提交），数据库会检查是否确实发生了冲突（即违反了隔离性原则），如果是的话，中止事务并接下来重试**。

乐观并发控制其实是一个古老的想法, 关于其优点和缺点已经争论了很长时间。如果冲突很多，则性能不佳（许多事务试图访问相同的对象），大量的事务必须中止。如果系统已接近其最大吞吐最，反复重试事务会使系统性能变得更差。

但是，如果系统还有足够的性能提升空间，且如果事务之间的竞争不大，乐观并发控制会比悲观方式高效很多。通过可交换的原子操作还可以减少一些竞争情况。例如，如果多个事务同时试图增加某个计数器，那么不管以什么样的顺序去增加（只要同一事务不去读计数器），最后的结果总是等价的，并发提交多个增量操作是可行的。

顾名思义， SSI 基于快照隔离，也就是说，事务中的所有读取操作都是基于数据库的一致性快照。这是与早期的乐观并发控制主要区别。在快照隔离的基础上， SSI 新增加了相关算法来检测写入之间的串行化冲突从而决定中止哪些事务。

#### 1.3.3.2. 基于过期的条件做决定


我们在讨论写倾斜时，介绍了这样一种使用场景：事务首先查询某些数据，根据查询的结果来决定采取后续操作，例如修改数据。而在快照隔离情况下，数据可能在查询期间就已经被其他事务修改，导致原事务在提交时决策的依据信息已出现变化。

换句话说，**事务是基于某些前提条件而决定采取行动，在事务开始时条件成立，而当事务要提交时，数据可能已经发生改变，条件已不再成立**。例如事务开始时有两名医生值班，而提交时只有一名医生了。

当应用程序执行查询时（例如当前有多少医生在值班? ) 数据库本身无法预知应用层逻辑如何使用这些查询结果。安全起见，**数据库假定对查询结果（决策的前提条件）的任何变化都应使写事务失效**。换言之，查询与写事务之间可能存在因果依赖关系。为了提供可串行化的隔离，**数据库必须检测事务是否会修改其他事务的查询结果，并在此情况下中止写事务**。

数据库如何知道查询结果是否发生了改变呢？可以分以下两种情况：

1. 读取是否作用于一个（即将）过期的 MVCC 对象（读取之前已经有未提交的写入）。

2. 检查写入是否影响即将完成的读取（读取之后，又有新的写入）。

##### 1.3.3.2.1. 检测是否读取了过期的 MVCC 对象

快照隔离通常采用多版本并发控制技术 (MVCC) 来实现。当事务从 MVCC 数据库一致性快照读取时，它会忽略那些在创建快照时尚未提交的事务写入。例如图中，事务 42 (修改 Alice 的值班状态）未被提交，因此事务 43 中 Alice 查询到的 on_call 是 true; 当事务 43 提交时，事务 42 巳经完成了提交。换言之，从快照读取时被忽略的写入已经生效，并且直接导致事务 43 做决定的前提已不再成止。

![](https://r2.129870.xyz/img/20220617013411.png)

为防止这种异常，**数据库需要跟踪那些由于 MVCC 可见性规则而被忽略的写操作。当事务提交时，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须中止当前事务**。

为什么要等到提交？当检测到读旧值，为何不立即中止事务 43 呢？可以考虑这些情况：

1. 首先，如果事务 43 是个只读事务，没有任何写倾斜风险，就不需要中止；而事务 43 读取数据库时，数据库还不知道事务是否稍后有任何写操作。

2. 此外，事务 43 提交时，有可能事务 42 发生了中止或者还处于未提交状态，因此读取的并非是过期值。**通过减少不必要的中止， SSI 可以高效支持那些需要在一致性快照中运行很长时间的读事务**。

##### 1.3.3.2.2. 检测写是否影响了之前的读

第二种要考虑的情况是，在读取数据之后，另一个事务修改了数据。

![](https://r2.129870.xyz/img/20220617013724.png)

在[[数据密集系统设计/数据密集型系统设计3：事务#两阶段加锁|两阶段加锁]]中，我们讨论了索引区间锁它可以锁定与某个查询条件匹配的所有行，例如 WHERE shift_id = 1234。这里使用了类似的技术，只有一点差异： SSI 锁不会阻塞其他事务。

在上图中，事务 42 和事务 43 都在查询轮班 1234 期间的值班医生。如果在 shift_id 上建有索引，数据库可以通过索引条目 1234 来记录事务 42 和事务 43 都查询了相同的结果。如果没有索引，可以在表级别跟踪此信息。该额外记录只需保留很小一段时间，当并发的所有事务都处理完成（提交或中止）之后，就可以丢弃。

**当另一个事务尝试修改时，它首先检查索引，从而确定是否最近存在一些读目标数据的其他事务**。这个过程类似于在受影响的字段范围上获取写锁，但**它并不会阻塞读取，而是直到读事务提交时才进一步通知他们：所读到的数据现在已经发生了变化**。

图中，事务 43 和事务 42 会互相通知对方先前的读已经过期。虽然事务 43 的修改的确影响了事务 42, 但事务 43 当时并未提交（修改未生效），而事务 42 首先尝试提交，所以可以成功；随后当事务 43 试图提交时，来自 42 的冲突写已经提交生效，事务 43 不得不中止。

#### 1.3.3.3. 可串行化快照隔离的性能

有许多工程方面的细节会直接影响算法在实践中的效果。例如，一个**需要权衡考虑的是关于跟踪事务读、写的粒度**。如果非常详细地跟踪每个事务的操作，确实可以准确推测有哪些事务受到影响、需要中止，但是记录元数据的开销可能很大；而粗粒度的记录则速度占优，但可能会扩大受影响的事务范围。

有时，读取过期的数据并不会造成太大影响，这完全取决于所处的具体场景。有时可以确信执行的最终结果是可串行化的， PostgreSQL 采用这样的信条来减少不必要的中止。

与两阶段加锁相比，**可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁**。这一点和快照隔离一样，读写通常不会互相阻塞。这样的设计使得查询延迟更加稳定、可预测。特别是，在一致性快照上执行只读查询不需要任何锁，这对于读密集的负载非常有吸引力。

与串行执行相比，可串行化快照隔离可以突破单个 CPU 核的限制。 FoundationDB 将冲突检测分布在多台机器上，从而提高总体吞吐量。即使数据可能跨多台机器进行分区，事务也可以在多个分区上读、写数据并保证可串行化隔离。

需要指出，**事务中止的比例会显著影响 SSI 的性能表现**。例如，一个运行很长时间的事务，读取和写入了大量数据，因而产生冲突并中止的概率就会增大，所以 **SSI 要求读－写型事务要简短**（而长时间执行的只读事务则没有此限制）。但总体讲，相比于两阶段加锁与串行执行， SSI 更能容忍那些执行缓慢的事务。

