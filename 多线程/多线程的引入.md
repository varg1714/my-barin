#多线程 

# 1. 多线程大纲

## 1.1. JAVA 中线程的状态

1. 在 JAVA 中线程有六种状态。
	其中能进入 blocked 的只有 synchronized 触发，经过 ReentrantLock 触发是进入到 time waiting 状态。
	- 可以通过 jps 命令查看当前运行的 java 应用
	- 通过 jstack "pid" 查看堆栈信息
	- 通过 javap -v xx. Class 查看字节码文件

	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220421224339.png)

2. JAVA 中线程中断的方式
	对于线程接受到 interrupt 信号后，可以选择响应中断或者忽略中断信号。当选择响应中断时，此时线程会被中断，这是一种友好的处理方式。但若是忽略中断的话，线程的中断标记会被复位，以后续响应中断。如以下的代码若选择第二种处理方式，则线程会一直运行，不会停止。
	```java
	public class ThreadInterruptTest implements Runnable {  
	  
	  
	    @Override  
	    public void run() {  
	        while (!Thread.currentThread().isInterrupted()) {  
	            try {  
	                System.out.println("hi");  
	                TimeUnit.SECONDS.sleep(1);  
	            } catch (InterruptedException e) {  
	                // 处理中断信号，由线程本身决定是否响应中断  
	  
	                // 1. 处理1，响应中断，退出循环  
	                //Thread.currentThread().interrupt();  
	  
	                // 2. 忽略中断,当按照此种方式处理后，线程并不会退出。当异常抛出后，操作系统会将线程状态复位。  
	                // 此时当前线程的Interrupt标记仍然为false  
	                continue;  
	            }  
	        }    }  
	    public static void main(String[] args) throws InterruptedException {  
	        Thread threadInterruptTester = new Thread(new ThreadInterruptTest(), "threadInterruptTester");  
	        threadInterruptTester.start();  
	  
	        TimeUnit.MICROSECONDS.sleep(200);  
	  
	        // 触发中断  
	        threadInterruptTester.interrupt();  
	  
	    }  
	  
	}
	```

## 1.2. JAVA 中锁的存放

在 JAVA 中，锁存放在实例对象的对象头中。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220422223212.png)

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220422223237.png)

## 1.3. JAVA 中锁膨胀的过程

当多个线程争夺锁时，获得锁的线程执行代码，未获得锁的线程将会阻塞，阻塞的线程将会被挂起并等待操作系统的重新调度。线程的阻塞与调度是消耗资源的，**有没有可能在线程不挂起的状态下获得锁呢？**这就是锁膨胀进而优化锁获取这一块的目的。

锁升级是单向的: 无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220423000737.png)

## 1.4. 线程的 wait 与 notify

Wait 与 notify 可以起到线程等待与通知线程的效果，可用于线程间通信。如以下例子利用 wait 与 notify 实现了一个生产者与消费者模型：

```java
@Slf4j  
public class ThreadNotifyDemo {  
  
    private static Queue<String> queue = new LinkedList<>();  
    private static int msgSize = 5;  
  
    public static void main(String[] args) {  
  
        Thread producer = new Thread(() -> {  
  
            int i = 0;  
  
            while (true) {  
                synchronized (queue) {  
  
                    while (queue.size() == msgSize) {  
                        try {  
                            queue.wait();  
                        } catch (InterruptedException e) {  
                            throw new RuntimeException(e);  
                        }  
                    }  
  
                    log.info("product msg:" + i);  
                    queue.add("msg:" + i);  
                    i++;  
                    queue.notify();  
  
                    try {  
                        TimeUnit.SECONDS.sleep(1L);  
                    } catch (InterruptedException e) {  
                        throw new RuntimeException(e);  
                    }  
  
                }            }  
  
        }, "producer");  
  
        Thread consumer = new Thread(() -> {  
  
            while (true) {  
                synchronized (queue) {  
  
                    while (queue.size() == 0) {  
                        try {  
                            queue.wait();  
                        } catch (InterruptedException e) {  
                            throw new RuntimeException(e);  
                        }  
                    }  
                    log.info("consume msg:" + queue.remove());  
                    queue.notify();  
  
                    try {  
                        TimeUnit.SECONDS.sleep(1L);  
                    } catch (InterruptedException e) {  
                        throw new RuntimeException(e);  
                    }  
  
                }            }  
        }, "consumer");  
  
        producer.start();  
        consumer.start();  
  
    }  
  
  
}
```

> [!warning] wait/notify 的使用
> 需要注意的是，当将 wait/notify 用在有锁竞争的地方时，需要格外的注意。由于 wait/notify 会释放锁，从而导致原子性操作被破坏的风险。

如以下的例子，两个线程争夺一把锁执行原子操作，线程 1 因为 wait 而导致原子操作被破坏：

```java

@Slf4j  
public class ThreadNotifyDemo2 {  
  
    private static final Queue<String> QUEUE = new LinkedList<>();  
    private static int msgSize = 5;  
  
    public static void main(String[] args) {  
  
        Thread producer = new Thread(() -> {  
  
            synchronized (QUEUE) {  
  
                int temp = msgSize;  
                log.info("读取临时变量 : {}", temp);  
                try {  
                    QUEUE.wait();  
                    // TimeUnit.SECONDS.sleep(2L);  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
  
                msgSize = temp + 1;  
                log.info("temp + 1: {}", msgSize);  
  
                QUEUE.notify();  
  
                try {  
                    TimeUnit.SECONDS.sleep(1L);  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
  
            }  
        }, "producer");  
  
        Thread consumer = new Thread(() -> {  
  
            synchronized (QUEUE) {  
                try {  
                    TimeUnit.SECONDS.sleep(1L);  
                    msgSize = 10;  
                    log.info("修改同步代码块中变量到10");  
                    QUEUE.notify();  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
            }  
  
        }, "consumer");  
  
        producer.start();  
        consumer.start();  
  
    }  
  
  
}

```

以上代码的执行为结果体现出线程 1 的原子操作因为 wait 而失败：

```text

15:56:18.832 [producer] INFO thread.threadnotify.ThreadNotifyDemo2 - 读取临时变量 : 5
15:56:19.848 [consumer] INFO thread.threadnotify.ThreadNotifyDemo2 - 修改同步代码块中变量到10
15:56:19.848 [producer] INFO thread.threadnotify.ThreadNotifyDemo2 - temp + 1: 6

```

## 1.5. 可见性问题

在单线程的环境下，如果向一个变量先写入一个值，然后在没有写干涉的情况下读取这个变量的值，那这个时候读取到的这个变量的值应该是之前写入的那个值。这本来是一个很正常的事情。但是在多线程环境下，读和写发生在不同的线程中的时候，可能会出现：读线程不能及时的读取到其他线程写入的最新的值。这就是所谓的可见性。

如以下的例子，当不进行任何额外操作时，flag 标记的更新并不会影响到上面线程的执行。这是因为 flag 变量的可见性问题导致的。

```java
@Slf4j  
public class VariableVisibilityDemo {  
  
  
    private  static boolean flag = false;  
  
    public static void main(String[] args) throws InterruptedException {  
  
        Thread thread = new Thread(() -> {  
            int i = 0;  
            while (!flag) {  
                i++;  
                // 可以刷新变量的三种方法  
                // 1. 将flag声明为volatile类型  
  
                // 2. synchronized同步块  
                // synchronized (VariableVisibilityDemo.class){}  
  
                // 3. IO操作  
                // new File("xx.txt");  
  
                // 4. 线程切换  
                // Thread.sleep();  
                // Thread.yield();  
            }  
            ;  
            log.info("i = {}", i);  
  
        });  
  
        thread.start();  
        // 这里更改不会生效  
        Thread.sleep(1000);  
        flag = true;  
  
    }  
  
}
```

- CPU 层面增加了高速缓存
- 操作系统，进程、线程、CPU 时间片来切换
- 编译器的优化，更合理的利用 CPU 的高速缓存

CPU 缓存的存在，编译器的深度优化，都会导致出现上面的现象。CPU 缓存会导致变量的更改不会刷新到主存中，而编译器的优化会导致指令重排，当使用 client 版本的 jvm 就不会有上面的问题。

上述现象其实是 Server 端的 jvm 进行的 `JIT 优化`，`JIT` 判断一段代码执行一定次数后成为热点代码就会进行优化，进而会将 `!flag` 直接替换为 true 。这样的话若关闭 `JIT 优化` 或者注释掉 `Thread.sleep(1000)` ，线程 t1 中的 while 循环次数还未被 `JIT` 判定为热点代码前，由于 t2 修改了 flag 为 true，由于缓存一致性协议，会将 flag 值同步到 t1 中，所以循环也能正常退出。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220423214548.png)

### 1.5.1. 总线锁和缓存锁

总线锁，简单来说就是，在多 cpu 下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个 LOCK 信号，这个信号使得其他处理器无法通过总线来访问到共享内存中的数据，总线锁定把 CPU 和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，这种机制显然是不合适的。

如何优化呢？最好的方法就是控制锁的保护粒度，我们只需要保证对于被多个 CPU 缓存的同一份数据是一致的就行。在 P6 架构的 CPU 后，引入了缓存锁，如果当前数据已经被 CPU 缓存了，并且是要写会到主内存中的，就可以采用缓存锁来解决问题。

所谓的缓存锁，就是指内存区域如果被缓存在处理器的缓存行中，并且在 Lock 期间被锁定，那么当它执行锁操作回写到内存时，不再总线上加锁，而是修改内部的内存地址，基于缓存一致性协议来保证操作的原子性。

总线锁和缓存锁怎么选择，取决于很多因素，比如 CPU 是否支持、以及存在无法缓存的数据时（比较大或者快约多个缓存行的数据），必然还是会使用总线锁。

### 1.5.2. 缓存一致性协议

为了达到数据访问的一致，需要各个处理器在访问缓存时遵循一些协议，在读写时根据协议来操作，常见的协议有 MSI，MESI，MOSI 等。最常见的就是 MESI 协议。接下来给大家简单讲解一下 MESI。

CPU 以缓存行为单位来读写数据，MESI 协议处理的对象也是缓存行，MESI 定义了 4 种不同的缓存行状态，如下
- M（Modified）: 缓存行中的数据被修改，但未同步到主内存中。
- E（Exclusive）：当前 CPU 有此缓存行中的数据，其他 CPU 没有。
- S（Shared）：当前 CPU 和其他 CPU 缓存行中都有此数据。
- I（Invalid）：当前 CPU 中的缓存行数据无效，这往往是由于其他 CPU 对缓存行中的数据进行修改导致的，当前 CPU 如果去缓存中读数据的话，由于数据已经无效，会重新从内存中加载缓存行。

接下来我们来举例看看 MESI 协议如何让 CPU 间的缓存保持一致，我们假设有两个 CPU ，CPU0 和 CPU 1，然后来看看当对这两个 CPU 执行一系列的读写操作时：

1. CPU0 执行读操作
	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202210310011180.png)

	由于其它 CPU 无 a=0 的缓存行，所以其缓存行状态为 E。
2. CPU0 将数据 a=1 写入 cache 中
	此时缓存块被修改了，但由于其他 CPU 无此缓存块，所以修改后的数据无需同步至内存中，所以 CPU0 中缓存行的状态为 M。

	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202210310012238.png)
3. CPU1 读取数据 a
	CPU1 读取 a 时，首先会通过总线向其他 CPU 广播一下读请求，然后 CPU0 发现自己的缓存块为 M，于是首先会将 a=1 刷新至内存，并将自己的缓存块标志位置为 S，然后才允许 CPU1 从内存中读数据，读取后由于 CPU0 也有此数据，所以会将其缓存行状态置为 S。

	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202210310013228.png)

4. CPU1 写数据 a=2
	由于 CPU1 中的缓存行状态为 S，所以它首先会往总线上广播一条 invalidate 消息，其他 CPU 收到消息后，会将其缓存行置为 I，然后发一个 invalidate ack 消息给 CPU1，CPU1 收到此消息后会将 a=2 写入缓存行中，然后再同步到内存，最后会将缓存行状态置为 E（因为其它 CPU 缓存行都失效了，所以缓存行为此 CPU 独有）。
	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202210310013670.png)

5. CPU0 读数据
	由于 CPU0 的缓存块为 I，为已失效，所以它会广播一个读请求，CPU1 的缓存行状态为 E，所以它会将缓存行状态置为 S，并且将缓存行同步到 CPU0 中，注意这里是 CPU 间的缓存行传输，这样比起从内存读显然传输更快。

MESI 协议很复杂，以上只是列表了 MESI 协议的一部分，实际上 MESI 协议的状态有几十种，转换状态也很复杂，完全列举是不可能的，大家知道其基本思想即可。

### 1.5.3. Store Buﬀeres

如果 CPU 之间严格遵循 MESI 协议，那其实也没 volatile 什么事了，但问题是**如果严格遵循 MESI 协议的话，CPU 的执行效率会受到严重影响**，因为每次要修改缓存，如果缓存行状态为 S 的话都要先发一个 invalidate 的广播，再等其他 CPU 将缓存行设置为无效后返回 invalidate ack 才能写到 Cache 中，那如果 CPU 频繁地修改数据，就会不断地发送广播消息，CPU 只能被动同步地等待其他 CPU 的消息，显然会对执行效率产生影响，为了解决此问题，工程师在 CPU 和 cache 之间又加了一个 store buffer。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202210310016015.png)

这样的话 CPU 要修改数据，先写入 store buffer 中，然后马上返回，之后再由 store buffer 异步执行发送广播消息和写入 cache 的操作，于是 CPU 执行写的效率就得到了极大的提升，另外为了确保 CPU 读取数据的正确性，它问题会先从 store buffer 中读取，然后再从 cache 中读取。

这里需要注意一下 Cache 和 store buffer 的区别，Cache 一般指数据的副本，如果 Cache 中的数据没了，还可以从 Memory 中加载，但 store buffer 则不是，它更像是蓄水池的作用，先存储一堆数据，然后再异步执行操作，我们可以把它想像成课代表，先把所有同学的作业收集好再一次性交给老师，如果 store buffer 中的数据丢了，那就彻底丢失了。

store buffer 的存储容量是有限的，前面我们介绍了，由 store buffer 来发送 invalidate 广播消息，然后其它 CPU 收到消息后，先将缓存行状态置为 I，然后再回复 invalidate ack 消息，但很有可能其他 CPU 在收到 invalidate 消息时正在忙其他事，还来不及将缓存行状态置为 I，这样就会造成 store buffer 不断堆积，直至溢出。

针对此问题，科学家们又设计了 Invalidate Queue。

### 1.5.4. Invalidate Queue

如图下，在 Cache 和总线间又加入了一个 Invalidate Queue，这样的话一旦 CPU 收到 invalidate 广播消息，就将此消息存储在 invalidate queue 中，然后立即回复 invalidate ack 消息给发出广播的那个 CPU，之后 invalidate queue 再异步执行将缓存行失效（设置状态为 I）的操作。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202210310017474.png)

这样的话 store buffer 就能节省写操作的时间，可以及时清空。

store buffer 和 Invalidate Queue 的引入相当于对 MESI 缓存一致性协议进行了改造，这样的改造本质上是为了提高 CPU 的执行效率（尤其是写的效率），但天下没有免费的午餐，这样的方式又造成了数据的短暂不一致，举个例子，假设 CPU0 和 CPU1 的状态如下：

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/202210310018553.png)

此时 CPU0 执行了对 a 的写操作 a = 2，由于此操作会先写入 store buffer，然后再由 store buffer 执行异步的操作，那么从 store buffer 发送 invalidate 广播到 invalidate queue 让缓存行失效期间，CPU 1 读取 a 的值都是老值（即 a = 1），这就造成了**短暂的不一致**，当然**最终还是会一致**的，我们把这种协议称为**弱一致性**或者说**最终一致性**协议。

### 1.5.5. 指令重排序

我们来关注下面这段代码，假设分别有两个线程，分别执行 executeToCPU0 和 executeToCPU1，分别由两个不同的 CPU 来执行。

引入 store buﬀer 之后，就可能出现 b \=\= 1 返回 true ，但是 assert (a \=\= 1) 返回 false。很多人肯定会表示不理解，这种情况怎么可能成立？那接下来我们去分析一下。

```java
// CPU0
void foo() {
    a = 1;    // ①
    b = 1;    // ②
}

// CPU1
void bar() {
    while (b == 0) continue;    // ③
    assert(a == 1);                         // ④
```

但实际上由于以下两个原因 b = 1 有可能会先于 a = 1 先写入缓存：
1. 由于指令重排序
2. 由于异步写入 store buffer 导致的 invalid cache 更新顺序发生变化

### 1.5.6. 通过内存屏障禁止了指令重排序

怎么解决这个问题呢，答案是使用**内存屏障**：

```java
// CPU0
void foo() {
    a = 1;          // ①
    smp_wb();       // 插入写屏障，wb 代表 write barrier，即写屏障
    b = 1;          // ②
}

// CPU1
void bar() {
    while (b == 0) continue; // ③
    assert(a == 1);                  // ④
}
```

如上代码所示，在 ① 和 ② 之间插入了一个内存屏障，smp_wb 代表多核体系结构下的内存写屏障，它的主要作用是保证 ① 和 ② 不会乱序，同时也按我们看到的顺序将 ① 和 ② 依次写入缓存再同步到内存中，也就是说**内存屏障的主要作用是能让其他 CPU 能依次观察到 CPU0 按我们期望的顺序更新变量**。

以上我们在 foo 中的两个赋值语句中插入了一个屏障，我们称其为**写屏障**，写屏障的主要是为了解决 CPU 乱序执行和 store buffer 异步写导致的数据更新与我们观察到的不一致的问题。

那么以上在 foo 中插入写屏障后，bar 中在执行 ④ 时 a 的值就能正确读到 1 的值了吗，答案是也不一定。这主要是因为 CPU1 在收到 Invalidate 消息后是先把消息存在 Invalidate Queue 中，然后 Invalidate Queue 再异步执行让缓存行失败的操作，如果在执行 ④ 时，Invalidate Queue 还未将 a 所在的缓存行置为失效状态，那么 CPU1 就会从缓存行中读取 a=0 这个未更新的值，为了保证能正常读取到 a=1，我们需要在 ③ 和 ④ 之间插入读屏障，如下所示：

```java
// CPU0
void foo() {
    a = 1;          // ①
    smp_wb();       // 插入写屏障，wb 代表 write barrier，即写屏障
    b = 1;          // ②
}

// CPU1
void bar() {
    while (b == 0) continue; // ③
        smp_rb();       // 插入读屏障，rb 代表 read barrier，即读屏障
    assert(a == 1);                  // ④
}
```

通过插入读屏障，首先保证了 ③ 和 ④ 不会乱序，其次 CPU1 会保证 Invalidate Queue 中的失效消息处理完之后（此例中即将 a 对应的缓存行设置为失效状态）会执行步骤 ④，这样的话可以确保 a 能从内在中读到最新的值 1 了。

Store Memory Barrier (写屏障) ，告诉处理器在写屏障之前的所有已经存储在存储缓存 (storebuﬀeres) 中的数据同步到主内存，简单来说就是使得写屏障之前的指令的结果对屏障之后的读或者写是可见的。

Load Memory Barrier (读屏障) ，处理器在读屏障之后的读操作, 都在读屏障之后执行。配合写屏障，使得写屏障之前的内存更新对于读屏障之后的读操作是可见的。

Full Memory Barrier (全屏障) ，确保屏障前的内存读写操作的结果提交到内存之后，再执行屏障后的读写操作。

### 1.5.7. JMM

简单来说，JMM 定义了共享内存中多线程程序读写操作的行为规范：在虚拟机中把共享变量存储到内存以及从内存中取出共享变量的底层实现细节。通过这些规则来规范对内存的读写操作从而保证指令的正确性，它解决了 CPU 多级缓存、处理器优化、指令重排序导致的内存访问问题，保证了并发场景下的可见性。

需要注意的是，JMM 并没有主动限制执行引擎使用处理器的寄存器和高速缓存来提升指令执行速度，也没主动限制编译器对于指令的重排序，也就是说在 JMM 这个模型之上，仍然会存在缓存一致性问题和指令重排序问题。JMM 是一个抽象模型，它是建立在不同的操作系统和硬件层面之上对问题进行了统一的抽象，然后再 Java 层面提供了一些高级指令，让用户选择在合适的时候去引入这些高级指令来解决可见性问题。

### 1.5.8. JMM 是如何解决可见性和有序性问题的

其实通过前面的内容分析我们发现，导致可见性问题有两个因素，一个是高速缓存导致的可见性问题，另一个是指令重排序。那 JMM 是如何解决可见性和有序性问题的呢？

其实前面在分析硬件层面的内容时，已经提到过了，对于缓存一致性问题，有总线锁和缓存锁，缓存锁是基于 MESI 协议。而对于指令重排序，硬件层面提供了内存屏障指令。而 JMM 在这个基础上提供了 volatile、ﬁnal 等关键字，使得开发者可以在合适的时候增加相应相应的关键字来禁止高速缓存和禁止指令重排序来解决可见性和有序性问题。

### 1.5.9. Volatile 的原理

```java

private int a = 0;
volatile int b = 0;

// CPU0
void foo() {
    a = 1;          // ①
    b = 1;          // ②
}we

// CPU1
void bar() {
    while (b == 0) continue; // ③
    assert(a == 1);                  // ④
}

```

至此我相信你应该能猜到 volatile 的作用了，没错，被 volatile 修饰的变量其实就相当于在变量写的时候添加了写屏障，避免了 volatile 变量写与在其**之前**其它变量写的排序，在变量读的时候添加了读屏障，避免了 volatile 读与在其**之后**的变量读的排序（在上面的例子中 b 是被 volatile 修饰的）。

不过 volatile 在实现上和我们认识的稍有区别，用 volatile 修饰的变量，在编译成机器指令时会在写操作后面，加上一条特殊的指令：`lock addl #0x0 , (%rsp)`，这条指令会将 CPU 对此变量的修改，**立即写入内存，并通知其他 CPU 将缓存行置为无效状态**，这里的 lock 主要是用来锁总线的，锁总线期间其他 CPU 的读写请求都会被阻塞，直到锁释放。

通过 `javap -v VolatileDemo. class` 命令可以看到对应的字节码文件：

```C
public static volatile boolean stop;
descriptor: Z
flags: ACC_PUBLIC, ACC_STATIC, ACC_VOLATILE

int field_offset = cache->f2_as_index();

if (cache->is_volatile()) {
	if (tos_type == itos) {
		obj->release_int_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == atos) {
		VERIFY_OOP(STACK_OBJECT(-1));
		obj->release_obj_field_put(field_offset, STACK_OBJECT(-1));
		OrderAccess::release
		CardTableModRefBS::card
	} else if (tos_type == btos) {
		obj->release_byte_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == ltos) {
		obj->release_long_field_put(field_offset, STACK_LONG(-1));
	} else if (tos_type == ctos) {
		obj->release_char_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == stos) {
		obj->release_short_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == ftos) {
		obj->release_float_field_put(field_offset, STACK_FLOAT(-1));
	} else {
		obj->release_double_field_put (field_offset, STACK_DOUBLE (-1));
	}
	OrderAccess :: storeload ();
}
```

### 1.5.10. Happens-Before 模型

除了显示引用 volatile 关键字能够保证可见性以外，在 Java 中，还有很多的可见性保障的规则。从 JDK1.5 开始，引入了一个 happens-before 的概念来阐述多个线程操作共享变量的可见性问题。所以我们可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在 happens-before 关系。这两个操作可以是同一个线程，也可以是不同的线程。

#### 1.5.10.1. 程序顺序规则（as-if-serial 语义）

- 不能改变程序的执行结果 (在单线程环境下，执行的结果不变)。
- 依赖问题，如果两个指令存在依赖关系，是不允许重排序。

```java
int a=0;
int b=0;
void test(){
	int a=1; a
	int b=1; b
	//int b=1;
	//int a=1;
	int c=a*b; c
}

// a happens -before b ; b happens before c
```

#### 1.5.10.2. 传递性规则

A happens-before b , b happens- before c, a happens-before c

#### 1.5.10.3. Volatile 变量规则

volatile 修饰的变量的写操作，一定 happens-before 后续对于 volatile 变量的读操作.
内存屏障机制来防止指令重排。

```java
public class VolatileExample{

	int a=0;
	volatile boolean flag=false;
	
	public void writer(){
		a=1; //1
		flag=true; //修改 2
	}
	public void reader(){
		if(flag){ //true  3
			int i=a; // i == 1, 4
		}
	}
}
```

1 happens-before 2 是否成立？是 -> ?
3 happens-before 4 是否成立? 是
2 happens -before 3 ->volatile 规则
1 happens-before 4 ; i=1 成立

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220423232526.png)

#### 1.5.10.4. 监视器锁规则

```java
int x=10;
synchronized(this){
	//后续线程读取到的x的值一定12
	if (x<12){
		x=12;
	}
}
```

#### 1.5.10.5. Start 规则

```java
public class StartDemo{
	int x=0;
	Thread t1=new Thread(()->{
		//读取x的值 一定是20
		if(x==20){
		}
	});
	x=20;
	t1. start ();
}
```

#### 1.5.10.6. Join 规则

```java
public class Test{
	int x=0;
	Thread t1=new Thread(()->{
		x=200;
	});
	
	t1. start ();
	t1. join (); //保证结果的可见性。
	//在此处读取到的x的值一定是200.
}
```

#### 1.5.10.7. ﬁnal 关键字提供了内存屏障的规则