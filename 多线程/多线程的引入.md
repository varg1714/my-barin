#多线程 

# 1. 多线程大纲

## 1.1. JAVA 中线程的状态

1. 在 JAVA 中线程有六种状态。
	其中能进入 blocked 的只有 synchronized 触发，经过 ReentrantLock 触发是进入到 time waiting 状态。
	- 可以通过 jps 命令查看当前运行的 java 应用
	- 通过 jstack "pid" 查看堆栈信息
	- 通过 javap -v xx. Class 查看字节码文件

	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220421224339.png)

2. JAVA 中线程中断的方式
	对于线程接受到 interrupt 信号后，可以选择响应中断或者忽略中断信号。当选择响应中断时，此时线程会被中断，这是一种友好的处理方式。但若是忽略中断的话，线程的中断标记会被复位，以后续响应中断。如以下的代码若选择第二种处理方式，则线程会一直运行，不会停止。
	```java
	public class ThreadInterruptTest implements Runnable {  
	  
	  
	    @Override  
	    public void run() {  
	        while (!Thread.currentThread().isInterrupted()) {  
	            try {  
	                System.out.println("hi");  
	                TimeUnit.SECONDS.sleep(1);  
	            } catch (InterruptedException e) {  
	                // 处理中断信号，由线程本身决定是否响应中断  
	  
	                // 1. 处理1，响应中断，退出循环  
	                //Thread.currentThread().interrupt();  
	  
	                // 2. 忽略中断,当按照此种方式处理后，线程并不会退出。当异常抛出后，操作系统会将线程状态复位。  
	                // 此时当前线程的Interrupt标记仍然为false  
	                continue;  
	            }  
	        }    }  
	    public static void main(String[] args) throws InterruptedException {  
	        Thread threadInterruptTester = new Thread(new ThreadInterruptTest(), "threadInterruptTester");  
	        threadInterruptTester.start();  
	  
	        TimeUnit.MICROSECONDS.sleep(200);  
	  
	        // 触发中断  
	        threadInterruptTester.interrupt();  
	  
	    }  
	  
	}
	```

## 1.2. JAVA 中锁的存放

在 JAVA 中，锁存放在实例对象的对象头中。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220422223212.png)

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220422223237.png)

## 1.3. JAVA 中锁膨胀的过程

当多个线程争夺锁时，获得锁的线程执行代码，未获得锁的线程将会阻塞，阻塞的线程将会被挂起并等待操作系统的重新调度。线程的阻塞与调度是消耗资源的，**有没有可能在线程不挂起的状态下获得锁呢？**这就是锁膨胀进而优化锁获取这一块的目的。

锁升级是单向的: 无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220423000737.png)

## 1.4. 线程的 wait 与 notify

Wait 与 notify 可以起到线程等待与通知线程的效果，可用于线程间通信。如以下例子利用 wait 与 notify 实现了一个生产者与消费者模型：

```java
@Slf4j  
public class ThreadNotifyDemo {  
  
    private static Queue<String> queue = new LinkedList<>();  
    private static int msgSize = 5;  
  
    public static void main(String[] args) {  
  
        Thread producer = new Thread(() -> {  
  
            int i = 0;  
  
            while (true) {  
                synchronized (queue) {  
  
                    while (queue.size() == msgSize) {  
                        try {  
                            queue.wait();  
                        } catch (InterruptedException e) {  
                            throw new RuntimeException(e);  
                        }  
                    }  
  
                    log.info("product msg:" + i);  
                    queue.add("msg:" + i);  
                    i++;  
                    queue.notify();  
  
                    try {  
                        TimeUnit.SECONDS.sleep(1L);  
                    } catch (InterruptedException e) {  
                        throw new RuntimeException(e);  
                    }  
  
                }            }  
  
        }, "producer");  
  
        Thread consumer = new Thread(() -> {  
  
            while (true) {  
                synchronized (queue) {  
  
                    while (queue.size() == 0) {  
                        try {  
                            queue.wait();  
                        } catch (InterruptedException e) {  
                            throw new RuntimeException(e);  
                        }  
                    }  
                    log.info("consume msg:" + queue.remove());  
                    queue.notify();  
  
                    try {  
                        TimeUnit.SECONDS.sleep(1L);  
                    } catch (InterruptedException e) {  
                        throw new RuntimeException(e);  
                    }  
  
                }            }  
        }, "consumer");  
  
        producer.start();  
        consumer.start();  
  
    }  
  
  
}
```

> [!warning] wait/notify 的使用
> 需要注意的是，当将 wait/notify 用在有锁竞争的地方时，需要格外的注意。由于 wait/notify 会释放锁，从而导致原子性操作被破坏的风险。
> 
> 同时需要注意的是，wait/notify 必须包裹在 synchronized 代码块中，这是因为 wait/notify 用于临界区资源的访问，必须保证并发的安全性。试想这样一种场景，基于某个条件判断做出 wait 的操作，如果没有并发控制，条件判断开始时条件成立，条件判断结束时条件不成立了（被并发修改了），若此时继续进行 wait 操作，则可能陷入死锁。因此需要并发访问的控制。

如以下的例子，两个线程争夺一把锁执行原子操作，线程 1 因为 wait 而导致原子操作被破坏：

```java

@Slf4j  
public class ThreadNotifyDemo2 {  
  
    private static final Queue<String> QUEUE = new LinkedList<>();  
    private static int msgSize = 5;  
  
    public static void main(String[] args) {  
  
        Thread producer = new Thread(() -> {  
  
            synchronized (QUEUE) {  
  
                int temp = msgSize;  
                log.info("读取临时变量 : {}", temp);  
                try {  
                    QUEUE.wait();  
                    // TimeUnit.SECONDS.sleep(2L);  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
  
                msgSize = temp + 1;  
                log.info("temp + 1: {}", msgSize);  
  
                QUEUE.notify();  
  
                try {  
                    TimeUnit.SECONDS.sleep(1L);  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
  
            }  
        }, "producer");  
  
        Thread consumer = new Thread(() -> {  
  
            synchronized (QUEUE) {  
                try {  
                    TimeUnit.SECONDS.sleep(1L);  
                    msgSize = 10;  
                    log.info("修改同步代码块中变量到10");  
                    QUEUE.notify();  
                } catch (InterruptedException e) {  
                    throw new RuntimeException(e);  
                }  
            }  
  
        }, "consumer");  
  
        producer.start();  
        consumer.start();  
  
    }  
  
  
}

```

以上代码的执行为结果体现出线程 1 的原子操作因为 wait 而失败：

```text

15:56:18.832 [producer] INFO thread.threadnotify.ThreadNotifyDemo2 - 读取临时变量 : 5
15:56:19.848 [consumer] INFO thread.threadnotify.ThreadNotifyDemo2 - 修改同步代码块中变量到10
15:56:19.848 [producer] INFO thread.threadnotify.ThreadNotifyDemo2 - temp + 1: 6

```

## 1.5. 可见性问题

在单线程的环境下，如果向一个变量先写入一个值，然后在没有写干涉的情况下读取这个变量的值，那这个时候读取到的这个变量的值应该是之前写入的那个值。这本来是一个很正常的事情。但是在多线程环境下，读和写发生在不同的线程中的时候，可能会出现：读线程不能及时的读取到其他线程写入的最新的值。这就是所谓的可见性。

如以下的例子，当不进行任何额外操作时，flag 标记的更新并不会影响到上面线程的执行。这是因为 flag 变量的可见性问题导致的。

```java
@Slf4j  
public class VariableVisibilityDemo {  
  
  
    private  static boolean flag = false;  
  
    public static void main(String[] args) throws InterruptedException {  
  
        Thread thread = new Thread(() -> {  
            int i = 0;  
            while (!flag) {  
                i++;  
                // 可以刷新变量的三种方法  
                // 1. 将flag声明为volatile类型  
  
                // 2. synchronized同步块  
                // synchronized (VariableVisibilityDemo.class){}  
  
                // 3. IO操作  
                // new File("xx.txt");  
  
                // 4. 线程切换  
                // Thread.sleep();  
                // Thread.yield();  
            }  
            ;  
            log.info("i = {}", i);  
  
        });  
  
        thread.start();  
        // 这里更改不会生效  
        Thread.sleep(1000);  
        flag = true;  
  
    }  
  
}
```

- CPU 层面增加了高速缓存
- 操作系统，进程、线程、CPU 时间片来切换
- 编译器的优化，更合理的利用 CPU 的高速缓存

CPU 缓存的存在，编译器的深度优化，都会导致出现上面的现象。CPU 缓存会导致变量的更改不会刷新到主存中，而编译器的优化会导致指令重排，当使用 client 版本的 jvm 就不会有上面的问题。

上述现象其实是 Server 端的 jvm 进行的 `JIT 优化`，`JIT` 判断一段代码执行一定次数后成为热点代码就会进行优化，进而会将 `!flag` 直接替换为 true 。这样的话若关闭 `JIT 优化` 或者注释掉 `Thread.sleep(1000)` ，线程 t1 中的 while 循环次数还未被 `JIT` 判定为热点代码前，由于 t2 修改了 flag 为 true，由于缓存一致性协议，会将 flag 值同步到 t1 中，所以循环也能正常退出。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220423214548.png)

### 1.5.1. 指令重排序

我们来关注下面这段代码，假设分别有两个线程，分别执行 executeToCPU0 和 executeToCPU1，分别由两个不同的 CPU 来执行。

引入 store buﬀer 之后，就可能出现 b \=\= 1 返回 true ，但是 assert (a \=\= 1) 返回 false。很多人肯定会表示不理解，这种情况怎么可能成立？那接下来我们去分析一下。

```java
// CPU0
void foo() {
    a = 1;    // ①
    b = 1;    // ②
}

// CPU1
void bar() {
    while (b == 0) continue;    // ③
    assert(a == 1);                         // ④
```

但实际上由于以下两个原因 b = 1 有可能会先于 a = 1 先写入缓存：
1. 由于指令重排序
2. 由于异步写入 store buffer 导致的 invalid cache 更新顺序发生变化

### 1.5.2. 通过内存屏障禁止了指令重排序

怎么解决这个问题呢，答案是使用**内存屏障**：

```java
// CPU0
void foo() {
    a = 1;          // ①
    smp_wb();       // 插入写屏障，wb 代表 write barrier，即写屏障
    b = 1;          // ②
}

// CPU1
void bar() {
    while (b == 0) continue; // ③
    assert(a == 1);                  // ④
}
```

如上代码所示，在 ① 和 ② 之间插入了一个内存屏障，smp_wb 代表多核体系结构下的内存写屏障，它的主要作用是保证 ① 和 ② 不会乱序，同时也按我们看到的顺序将 ① 和 ② 依次写入缓存再同步到内存中，也就是说**内存屏障的主要作用是能让其他 CPU 能依次观察到 CPU0 按我们期望的顺序更新变量**。

以上我们在 foo 中的两个赋值语句中插入了一个屏障，我们称其为**写屏障**，写屏障的主要是为了解决 CPU 乱序执行和 store buffer 异步写导致的数据更新与我们观察到的不一致的问题。

那么以上在 foo 中插入写屏障后，bar 中在执行 ④ 时 a 的值就能正确读到 1 的值了吗，答案是也不一定。这主要是因为 CPU1 在收到 Invalidate 消息后是先把消息存在 Invalidate Queue 中，然后 Invalidate Queue 再异步执行让缓存行失败的操作，如果在执行 ④ 时，Invalidate Queue 还未将 a 所在的缓存行置为失效状态，那么 CPU1 就会从缓存行中读取 a=0 这个未更新的值，为了保证能正常读取到 a=1，我们需要在 ③ 和 ④ 之间插入读屏障，如下所示：

```java
// CPU0
void foo() {
    a = 1;          // ①
    smp_wb();       // 插入写屏障，wb 代表 write barrier，即写屏障
    b = 1;          // ②
}

// CPU1
void bar() {
    while (b == 0) continue; // ③
        smp_rb();       // 插入读屏障，rb 代表 read barrier，即读屏障
    assert(a == 1);                  // ④
}
```

通过插入读屏障，首先保证了 ③ 和 ④ 不会乱序，其次 CPU1 会保证 Invalidate Queue 中的失效消息处理完之后（此例中即将 a 对应的缓存行设置为失效状态）会执行步骤 ④，这样的话可以确保 a 能从内在中读到最新的值 1 了。

Store Memory Barrier (写屏障) ，告诉处理器在写屏障之前的所有已经存储在存储缓存 (storebuﬀeres) 中的数据同步到主内存，简单来说就是使得写屏障之前的指令的结果对屏障之后的读或者写是可见的。

Load Memory Barrier (读屏障) ，处理器在读屏障之后的读操作, 都在读屏障之后执行。配合写屏障，使得写屏障之前的内存更新对于读屏障之后的读操作是可见的。

Full Memory Barrier (全屏障) ，确保屏障前的内存读写操作的结果提交到内存之后，再执行屏障后的读写操作。

### 1.5.3. JMM

简单来说，JMM 定义了共享内存中多线程程序读写操作的行为规范：在虚拟机中把共享变量存储到内存以及从内存中取出共享变量的底层实现细节。通过这些规则来规范对内存的读写操作从而保证指令的正确性，它解决了 CPU 多级缓存、处理器优化、指令重排序导致的内存访问问题，保证了并发场景下的可见性。

需要注意的是，JMM 并没有主动限制执行引擎使用处理器的寄存器和高速缓存来提升指令执行速度，也没主动限制编译器对于指令的重排序，也就是说在 JMM 这个模型之上，仍然会存在缓存一致性问题和指令重排序问题。JMM 是一个抽象模型，它是建立在不同的操作系统和硬件层面之上对问题进行了统一的抽象，然后再 Java 层面提供了一些高级指令，让用户选择在合适的时候去引入这些高级指令来解决可见性问题。

### 1.5.4. JMM 是如何解决可见性和有序性问题的

其实通过前面的内容分析我们发现，导致可见性问题有两个因素，一个是高速缓存导致的可见性问题，另一个是指令重排序。那 JMM 是如何解决可见性和有序性问题的呢？

其实前面在分析硬件层面的内容时，已经提到过了，对于缓存一致性问题，有总线锁和缓存锁，缓存锁是基于 MESI 协议。而对于指令重排序，硬件层面提供了内存屏障指令。而 JMM 在这个基础上提供了 volatile、ﬁnal 等关键字，使得开发者可以在合适的时候增加相应相应的关键字来禁止高速缓存和禁止指令重排序来解决可见性和有序性问题。

### 1.5.5. Volatile 的原理

```java

private int a = 0;
volatile int b = 0;

// CPU0
void foo() {
    a = 1;          // ①
    b = 1;          // ②
}we

// CPU1
void bar() {
    while (b == 0) continue; // ③
    assert(a == 1);                  // ④
}

```

至此我相信你应该能猜到 volatile 的作用了，没错，被 volatile 修饰的变量其实就相当于在变量写的时候添加了写屏障，避免了 volatile 变量写与在其**之前**其它变量写的排序，在变量读的时候添加了读屏障，避免了 volatile 读与在其**之后**的变量读的排序（在上面的例子中 b 是被 volatile 修饰的）。

不过 volatile 在实现上和我们认识的稍有区别，用 volatile 修饰的变量，在编译成机器指令时会在写操作后面，加上一条特殊的指令：`lock addl #0x0 , (%rsp)`，这条指令会将 CPU 对此变量的修改，**立即写入内存，并通知其他 CPU 将缓存行置为无效状态**，这里的 lock 主要是用来锁总线的，锁总线期间其他 CPU 的读写请求都会被阻塞，直到锁释放。

通过 `javap -v VolatileDemo. class` 命令可以看到对应的字节码文件：

```C
public static volatile boolean stop;
descriptor: Z
flags: ACC_PUBLIC, ACC_STATIC, ACC_VOLATILE

int field_offset = cache->f2_as_index();

if (cache->is_volatile()) {
	if (tos_type == itos) {
		obj->release_int_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == atos) {
		VERIFY_OOP(STACK_OBJECT(-1));
		obj->release_obj_field_put(field_offset, STACK_OBJECT(-1));
		OrderAccess::release
		CardTableModRefBS::card
	} else if (tos_type == btos) {
		obj->release_byte_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == ltos) {
		obj->release_long_field_put(field_offset, STACK_LONG(-1));
	} else if (tos_type == ctos) {
		obj->release_char_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == stos) {
		obj->release_short_field_put(field_offset, STACK_INT(-1));
	} else if (tos_type == ftos) {
		obj->release_float_field_put(field_offset, STACK_FLOAT(-1));
	} else {
		obj->release_double_field_put (field_offset, STACK_DOUBLE (-1));
	}
	OrderAccess :: storeload ();
}
```

### 1.5.6. Happens-Before 模型

除了显示引用 volatile 关键字能够保证可见性以外，在 Java 中，还有很多的可见性保障的规则。从 JDK1.5 开始，引入了一个 happens-before 的概念来阐述多个线程操作共享变量的可见性问题。所以我们可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在 happens-before 关系。这两个操作可以是同一个线程，也可以是不同的线程。

#### 1.5.6.1. 程序顺序规则（as-if-serial 语义）

- 不能改变程序的执行结果 (在单线程环境下，执行的结果不变)。
- 依赖问题，如果两个指令存在依赖关系，是不允许重排序。

```java
int a=0;
int b=0;
void test(){
	int a=1; a
	int b=1; b
	//int b=1;
	//int a=1;
	int c=a*b; c
}

// a happens -before b ; b happens before c
```

#### 1.5.6.2. 传递性规则

A happens-before b , b happens- before c, a happens-before c

#### 1.5.6.3. Volatile 变量规则

volatile 修饰的变量的写操作，一定 happens-before 后续对于 volatile 变量的读操作.
内存屏障机制来防止指令重排。

```java
public class VolatileExample{

	int a=0;
	volatile boolean flag=false;
	
	public void writer(){
		a=1; //1
		flag=true; //修改 2
	}
	public void reader(){
		if(flag){ //true  3
			int i=a; // i == 1, 4
		}
	}
}
```

1 happens-before 2 是否成立？是 -> ?
3 happens-before 4 是否成立? 是
2 happens -before 3 ->volatile 规则
1 happens-before 4 ; i=1 成立

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220423232526.png)

#### 1.5.6.4. 监视器锁规则

```java
int x=10;
synchronized(this){
	//后续线程读取到的x的值一定12
	if (x<12){
		x=12;
	}
}
```

#### 1.5.6.5. Start 规则

```java
public class StartDemo{
	int x=0;
	Thread t1=new Thread(()->{
		//读取x的值 一定是20
		if(x==20){
		}
	});
	x=20;
	t1. start ();
}
```

#### 1.5.6.6. Join 规则

```java
public class Test{
	int x=0;
	Thread t1=new Thread(()->{
		x=200;
	});
	
	t1. start ();
	t1. join (); //保证结果的可见性。
	//在此处读取到的x的值一定是200.
}
```

#### 1.5.6.7. ﬁnal 关键字提供了内存屏障的规则

## 多线程使用

### 两个线程交叉打印数字

```java
public static void main(String[] args) {  
  
    Runnable task1 = () -> {  
  
        while (i < 100) {  
  
            synchronized (lock) {  
                while (i % 2 == 0) {  
                    try {  
                        lock.wait();  
                    } catch (InterruptedException e) {  
                        throw new RuntimeException(e);  
                    }  
                }  
  
                System.out.println(Thread.currentThread().getName() + ":" + i++);  
                lock.notify();  
            }  
  
        }  
  
    };  
  
    Runnable task2 = () -> {  
  
        while (i < 100) {  
  
            synchronized (lock) {  
                while (i % 2 == 1) {  
                    try {  
                        lock.wait();  
                    } catch (InterruptedException e) {  
                        throw new RuntimeException(e);  
                    }  
                }  
  
                System.out.println(Thread.currentThread().getName() + ":" + i++);  
                lock.notify();  
            }  
  
        }  
  
    };  
  
    new Thread(task1).start();  
    new Thread(task2).start();  
  
}
```