---
source:
  - "[[太变态了，每秒 10W 并发的无锁缓存，你敢信？（第 57 讲）]]"
create: 2025-10-27
---

## 1. 核心问题：特定场景下的性能瓶颈

本文旨在解决一个特定的业务场景下的性能问题，该场景具备以下三个典型特征：

1. **超高并发吞吐量**：每秒需要处理海量请求（例如 10W+）。
2. **写多读少**：大部分请求是修改数据，少部分是读取数据。
3. **Value 定长**：缓存的数据值（Value）大小是固定的，例如序列化后的对象。

**典型案例**：网约车场景中，大量司机高频上报自己的位置信息（写操作），而用户查询某个特定司机位置的频率相对较低（读操作）。

## 2. 性能优化方案的演进之路

文章通过一个层层递进的思路，展示了如何从最基础的方案逐步优化到最终的无锁方案。

### Level 1: 全局锁 (Global Lock)

最简单的实现方式，即对整个缓存（如一个 `Map`）使用一把全局读写锁。

- **优点**：实现简单，能保证数据绝对一致。
- **缺点**：在超高并发下，这把锁会成为系统瓶颈，所有线程串行执行，性能极差。

### Level 2: 分段锁 (Segmented Lock)

为了降低锁的冲突，将一个大的 `Map` 水平拆分成 N 个小的 `Map`，每个小 `Map` 对应一把独立的锁。通过 `hash(key) % N` 来决定操作哪个 `Map` 和哪把锁。

- **优点**：锁的粒度变小，并发能力提升为原来的 N 倍，冲突概率大大降低。这类似于早期 `ConcurrentHashMap` 的设计。
- **缺点**：锁依然存在，当单一段（Segment）的并发量过高时，该段的锁依然会成为瓶颈。

### Level 3: 行级锁 (Row-level Lock)

将锁的粒度进一步细化到极致，为每一条记录（每一个 Key）都分配一把锁。

- **优点**：锁冲突降到最低，不同 Key 的操作完全互不影响。
- **缺点**：锁的数量与数据量成正比，如果数据量巨大（如百万级司机），会消耗海量的内存来存储锁对象，不现实。

## 3. 终极方案：无锁缓存 (No-Lock Cache)

这是本文的核心，它通过一种巧妙的权衡，实现了极致的并发性能。

### 核心思想

**放弃使用锁来“预防”并发冲突，转而通过“签名校验”机制在读取时“检测”数据是否损坏，从而保证数据完整性。**

### 设计详解

1. **面临的挑战：脏数据 (Dirty Data)**
    如果不加锁，两个线程同时写入同一个 Key，可能会导致内存数据被交叉写入，最终形成一个既不是 `value1` 也不是 `value2` 的损坏数据。

2. **解决方案：签名机制 (Signature Mechanism)**
    - **写入时**：不仅写入定长的 `value`，还要额外写入一个根据 `value` 计算出的**定长签名**（如 16/32bit CRC 校验码）。实际存入的是一个数据对 `(value, signature)`。
    - **读取时**：
        1. 从缓存中读出 `(value, signature)`。
        2. 程序根据读到的 `value` **重新计算**一遍签名，得到 `new_signature`。
        3. 比较 `signature` 与 `new_signature`：
            - **若相等**：说明 `value` 是完整的，数据可信，返回给调用方。
            - **若不相等**：说明 `value` 是一个在并发写入中被破坏的脏数据。此时，缓存应主动返回 **`cache miss` (缓存未命中)**，绝不能返回脏数据。

3. **关键假设**
    这个方案成立的一个关键前提是：**对签名（一个较小的数据块，如 16/32 位整数）的写入操作是原子的**。这意味着即使 `value` 的写入被破坏，`signature` 本身是完整的（要么是线程 A 的，要么是线程 B 的），这就保证了校验机制的可靠性。

## 4. 深入探讨与实践考量 (Q&A 总结)

### Q1: 脏数据导致 Cache Miss，那正确数据从哪来？

这个方案通常配合 **Cache-Aside (旁路缓存)** 模式使用。

- **数据源**：**数据库**是最终的数据权威来源 (Source of Truth)。
- **写流程**：`先更新数据库 -> 再更新缓存`。
- **读流程**：`读缓存 -> 校验签名 -> 若失败 (cache miss) -> 则读数据库 -> 将正确数据写回缓存 -> 返回数据`。
所以，当缓存因为并发冲突出现临时脏数据时，读取请求会通过回源数据库来获取正确数据，并“修复”缓存。

### Q2: 冲突频繁是否会导致缓存一直无效？

这种情况**几乎不会**发生。

- **冲突窗口极小**：并发写导致数据损坏的时间窗口在纳秒级，概率很低。
- **系统自愈能力强**：缓存的状态是不断被新数据覆盖的。即使某次写入产生了脏数据，下一次“干净”的写入会立刻将其覆盖为正确状态。系统总会趋向于最新的、被成功写入的数据，实现了**最终一致性**。

### Q3: 为什么不直接用 Redis？

在 99% 的场景下，Redis 都是更好的选择。但此方案在追求极致性能的 1% 场景下有其不可替代的优势。

| 特性 / 方面 | 无锁缓存 (文章方案) | Redis |
| :--- | :--- | :--- |
| **访问模型** | **进程内 (In-Process)**，直接内存访问 | **客户端-服务器 (C/S)**，需经过网络协议栈 |
| **访问延迟** | **纳秒级 (ns)** | **微秒/毫秒级 (μs/ms)**，网络是主要开销 |
| **并发模型** | **真·多线程并行**，充分利用多核 CPU | **单线程事件循环**，命令串行执行 |
| **性能瓶颈** | CPU 和内存总线速度 | **网络 I/O** 和 Redis 单线程处理上限 |
| **适用场景** | 性能压榨到极致的单一应用，对延迟极度敏感 | 通用、分布式、功能丰富的缓存解决方案 |

**结论**：当业务 QPS 达到几十万甚至更高，网络延迟和 Redis 单线程模型成为压垮系统的最后瓶颈时，这种进程内无锁缓存方案就成了突破性能极限的“核武器”。它用**极低的延迟**和**更高的 CPU 利用率**换取了极致的吞吐能力。

## 5. 最终总结

- **核心权衡 (Trade-off)**：该方案牺牲了“强一致性”和“每次写入都成功”，换取了“极高的并发吞吐能力”和“读取时的数据完整性保证”。
- **设计精髓**：思路比结论更重要。这个方案展示了在遇到性能瓶颈时，如何通过转换思路（从“预防”到“检测”），并利用底层硬件特性（原子写），来设计出满足特定需求的创新解决方案。
- **适用边界**：这是一个高度特化的“尖端”方案，适用于对成本和性能要求极度苛刻的场景。对于绝大多数应用，成熟的通用组件（如 Redis）仍然是首选。