---
source:
  - "[[虚拟线程原理及性能分析｜得物技术]]"
create: 2025-10-30
---

## 1. 核心思想

虚拟线程是 JDK 21 引入的重大特性，其核心目标是：**在不改变传统“一请求一线程”同步阻塞式编程模型的前提下，以极低的成本实现大规模并发，大幅提升 I/O 密集型应用的吞吐量。** 它让开发者可以用最熟悉的方式，编写出媲美复杂响应式编程的高性能代码。

## 2. 问题背景：为什么需要虚拟线程？

在虚拟线程出现之前，为了提升服务吞吐量，我们经历了以下演进，但都存在瓶颈：

1. **串行模式**：
    * **描述**：按顺序执行所有 I/O 操作（如 RPC 调用、DB 查询）。
    * **缺点**：性能极差，总耗时等于所有操作耗时之和。

2. **线程池 + `Future` 异步调用**：
    * **描述**：使用线程池并行执行多个任务。
    * **缺点**：当任务间存在依赖时，主线程需要通过 `future.get()` 阻塞等待结果，依然会浪费宝贵的平台线程资源。

3. **线程池 + `CompletableFuture` 异步调用**：
    * **描述**：通过回调和链式调用编排异步任务，减少主线程的直接阻塞。
    * **缺点**：虽然有所缓解，但并未根治问题。执行 I/O 操作的线程本身仍然会被阻塞，导致 CPU 资源在等待期间被闲置。

**根本瓶颈：平台线程 (Platform Thread) 的局限**

* **昂贵且有限**：Java 的 `Thread` 是对操作系统内核线程的 1:1 包装。创建成本高（通常需要分配约 1MB 的栈内存），且数量受操作系统限制。
* **上下文切换开销**：大量平台线程会导致 CPU 频繁进行上下文切换，消耗大量资源。
* **结论**：我们无法通过无限增加平台线程来提升并发能力。

**替代方案：响应式编程 (如 WebFlux)**

* **优点**：采用事件循环和非阻塞 I/O，能用极少的线程处理海量请求，性能优异。
* **缺点**：
    * **学习成本高**：编程模型与传统同步模型差异巨大。
    * **代码可读性差**：容易产生“回调地狱”。
    * **调试困难**：调用栈不直观。
    * **生态兼容性问题**：许多现有库（如 JDBC）不支持非阻塞 I/O。
    * **迁移成本巨大**：几乎需要重写所有代码。

## 3. 深入原理：虚拟线程如何工作

虚拟线程通过 **M:N 调度模型** 解决上述问题，即 M 个虚拟线程在 N 个平台线程上运行（N 通常等于 CPU 核心数）。

其实现可以概括为：`virtual thread = continuation + scheduler + runnable`

1. **Continuation (执行状态的“书签”)**
    * **核心作用**：实现虚拟线程的**暂停 (挂起)** 和 **恢复**。它能捕获并保存代码的完整执行状态（调用栈和局部变量）。
    * **工作流程**：
        1. **挂起 (Yield / Unmount)**：当虚拟线程中的代码执行到阻塞 I/O 操作时（如 `InputStream.read()`），JVM 会：
            * 调用 `Continuation.yield()`，将当前虚拟线程的**调用栈数据从平台线程的栈内存复制到 Java 的堆内存**中保存。
            * 将虚拟线程从平台线程上**卸载 (unmount)**。
            * 此时，平台线程被释放，可以立即去执行另一个就绪的虚拟线程。
        2. **恢复 (Run / Mount)**：当 I/O 操作完成，数据准备就绪后：
            * 虚拟线程被唤醒，变为“可运行”状态，并被调度器重新提交。
            * 调度器为其分配一个空闲的平台线程，并**挂载 (mount)** 上去。
            * 之前保存在堆内存中的调用栈数据被**复制回平台线程的栈内存**。
            * 调用 `Continuation.run()`，代码从上次中断的地方无缝地继续执行。

2. **Scheduler (调度器)**
    * **默认实现**：一个 `ForkJoinPool`。
    * **职责**：管理一个平台线程池（称为**载体线程 Carrier Threads**），并将“可运行”的虚拟线程任务分配给它们执行。它通过工作窃取机制，最大化所有平台线程的利用率。

3. **Runnable (用户任务)**
    * 你提供的业务逻辑代码，被包装在 `Continuation` 中，由调度器进行管理。

## 4. 实践、局限与使用建议

* **适用场景**：
    * **高并发 I/O 密集型应用**：绝佳场景，如微服务网关、大量数据库/缓存/RPC 调用的业务服务。
    * 处理大量短时任务。
* **局限性 (线程“钉住” Pinning)**：在某些情况下，虚拟线程无法被卸载，会“钉住”平台线程并阻塞它。
    1. **`synchronized` 同步块/方法**：因为监视器锁（monitor lock）与平台线程绑定，JVM 无法安全卸载。**推荐使用 `java.util.concurrent.ReentrantLock` 替代**。
    2. **`native` 方法或外部函数调用**：JVM 无法控制本地代码的执行，也无法保存其状态。

* **`ThreadLocal` 问题**：
    * 虚拟线程支持 `ThreadLocal`，但由于虚拟线程数量可能非常庞大（百万级别），会导致 `ThreadLocal` 中存储大量数据，增加内存压力和 GC 负担。
    * **建议**：谨慎使用，不要在其中存放大量数据。未来可能会被 `Scoped Values` (JEP 446) 替代。
* **核心使用建议**：
    * **无需池化 (No Pooling)**：虚拟线程创建成本极低，应该**“用时创建，用完即扔”**，而不是像平台线程那样进行池化复用。池化反而会带来不必要的开销。

## 5. 性能压测对比 (源自文章)

测试场景：500 并发请求一个平均响应 500ms 的慢服务。

| 方案 | 吞吐量 (req/sec) | 平均响应时间 (ms) | 核心点 |
| :--- | :--- | :--- | :--- |
| Tomcat + 默认线程池 (200) | 388 | 1286 | 性能受限于线程池大小，请求在队列中等待。 |
| Tomcat + 扩大线程池 (500) | 962 | 518 | 性能提升，但受限于系统资源，不能无限扩大。 |
| WebFlux (响应式) | 964 | 517 | 性能极好，但编程模型复杂，迁移成本高。 |
| **Tomcat + 虚拟线程** | **963** | **518** | **性能与 WebFlux 相当，但无需修改业务代码，仅替换执行器。** |

**结论**：虚拟线程以最小的改动成本，获得了与复杂响应式框架同等级的性能提升。

## 6. 对比：Java 虚拟线程 vs. Go Goroutine

两者都是轻量级并发的实现，但实现哲学和技术细节不同。

| 特性 | Java 虚拟线程 (Virtual Thread) | Go Goroutine |
| :--- | :--- | :--- |
| **实现层面** | **JVM 层面实现**，作为库引入，兼容现有生态。 | **语言和运行时原生支持**，是 Go 的核心部分。 |
| **栈管理** | **栈数据在堆栈间复制**。 | **动态可伸缩栈**，启动时很小 (2KB)，按需增长。 |
| **阻塞处理** | **JVM 拦截**已知的阻塞方法。但对 `synchronized` 等无能为力。 | **运行时和编译器协作**，能处理几乎所有阻塞，更彻底。 |
| **与语言集成** | **向后兼容**，但存在与旧机制的“摩擦”。 | **原生、无缝集成**，没有历史包袱。 |
| **通信/同步** | 依赖 `java.util.concurrent` 包（锁、信号量等）。 | 提倡使用 **Channels** 进行通信。 |

**总结对比**：Goroutine 是 Go 语言的“原住民”，设计更纯粹、原生。虚拟线程是 Java 生态的“新移民”，首要任务是兼容并赋能庞大的现有生态，虽然存在一些历史包袱带来的妥协，但它为 Java 带来了革命性的并发能力提升。