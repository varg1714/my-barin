---
source:
  - "[[MySQL，100 亿数据，如何不停服平滑迁移？（第 104 讲，万字收藏）]]"
create: 2025-10-16
---

## 1. 第一部分：问题的根源与挑战 (The "Why")

在快速发展的业务中，数据层的演进不可避免。平滑迁移的核心目标是在不中断线上服务的前提下，安全、可靠地完成底层数据的“搬家”。

**1.1 典型迁移场景（源于文章）：**
* **结构变更 (Schema Evolution):** 为海量数据的表增加、删除或修改字段。
* **扩容/缩容 (Sharding/Re-sharding):** 数据库分片数量发生变化，例如从 2 个库扩展到 3 个库，需要重分布数据。
* **存储介质更换 (Storage Migration):** 从一种数据库迁移到另一种，如 MySQL -> TiDB，或关系型数据库 -> NoSQL。

**1.2 核心挑战：**
* **数据量巨大：** 百亿级别的数据，全量拷贝耗时极长。
* **业务连续性：** 7x24 小时服务，不允许长时间停机。
* **数据一致性：** 在迁移过程中，旧库仍在写入，如何保证新旧两库的数据在切换瞬间是完全一致的？
* **风险控制：** 迁移过程复杂，如何验证迁移的正确性？如何做到可灰度、可回滚？

## 2. 第二部分：传统迁移方案的深度剖析 (The "Classic How")

本部分详细解析文章中提到的三种方案，并补充关键的实现细节。

### 2.1. 方案一：停机迁移 (Downtime Migration) - 简单但有损

* **核心思想：** 停止一切，专心搬家。
* **详细步骤：**
    1. **公告与停服：** 在业务低峰期（如凌晨）挂出维护公告，通过网关或应用层配置，关闭所有外部流量入口，确保数据库不再有任何写入。
    2. **离线数据迁移：** 运行一个预先开发好的数据迁移脚本/工具（如 `mysqldump` 或自研工具），将旧库数据完整地、一次性地导出并导入到新库。如果涉及结构变更或分片，该工具需内置转换逻辑。
    3. **服务升级与验证：** 部署新的应用程序代码，将其数据库连接指向新库。进行核心业务流程的冒烟测试，确保服务在新库上能正常工作。
    4. **恢复服务：** 开启流量入口，恢复线上服务。
* **优点：**
    * **逻辑最简单：** 数据是静态的，无需处理复杂的增量同步，一致性天然保证。
    * **实现成本低：** 只需一个一次性的迁移脚本。
* **致命缺点：**
    * **服务中断：** 对用户体验造成直接伤害，不符合高可用要求。
    * **高压操作窗口：** 整个过程必须在预定的维护窗口内完成。一旦迁移耗时超预期或中途出错，将面临巨大的修复压力和推迟开服的风险。**人压力越大，越容易出错。**

### 2.2. 方案二：追日志方案 (Log-Chasing) - 走向高可用

* **核心思想：** 先搬“家当”（全量），再同步“新物件”（增量）。
* **详细步骤：**
    1. **服务升级 - 记录变更：**
        * **侵入式改造：** 修改所有涉及写操作（`INSERT`, `UPDATE`, `DELETE`）的应用层代码。
        * **记录内容：** 当写操作成功后，将发生变更的**数据主键**（以及库名、表名）作为一条消息发送到消息队列（如 Kafka, RocketMQ）。**注意：只记录主键，不记录完整数据，以保证通用性和低开销。**
    2. **全量数据迁移：**
        * 在不影响线上服务（仍访问旧库）的情况下，运行一个工具将旧库的**存量数据**拷贝到新库。
        * 此过程可以限速、分批进行，没有严格的时间压力。
    3. **增量数据追平：**
        * 开发一个消费程序，订阅步骤 1 中的消息队列。
        * 对于收到的每一条主键，程序会**回到旧库**拉取该主键对应的**最新完整数据**。
        * 将拉取到的数据**覆盖写入**到新库中。
        * 这个程序会持续运行，不断追平在全量迁移及后续过程中产生的数据差异，这是一个“无限逼近”的过程。
    4. **数据校验：**
        * 开发一个独立的数据比对工具，持续、循环地检查新旧两库的数据一致性。
        * **具体实现见 2.4 节的深度解析。**
    5. **流量切换：**
        * 当校验工具显示数据差异率极低或为零时，准备切换。
        * 为了保证最终一致性，可采用**短暂锁库**（如文章提到的“秒级 readonly”）或更优雅的[[数据在线迁移方案#2.4. 关键工程实践深度解析 (对话精华)|应用层流量拦截]]。
        * 等待增量追平程序处理完最后几条日志后，将应用流量（读和写）全部切换到新库。
* **优点：**
    * **全程服务可用：** 实现了不停机迁移。
    * **迁移过程从容：** 全量和增量追平阶段没有严格的时间限制。
* **缺点：**
    * **应用代码侵入：** 核心痛点。需要在大量业务代码中增加日志逻辑，难以维护，且有遗漏风险。
    * **架构复杂：** 额外引入了日志记录、消费、数据回查等多个环节和组件，增加了系统的复杂度和潜在故障点。

### 2.3. 方案三：双写方案 (Dual-Write) - 另一种高可用思路

* **核心思想：** 从一开始就让新旧两库“同时变化”。
* **详细步骤：**
    1. **服务升级 - 实现双写：**
        * **侵入式改造：** 修改所有写操作的应用层代码。
        * **同步执行：** 在执行数据库写操作时，代码需要**同时向旧库和新库**发起同一个写请求。
        * **容错策略：** 必须考虑新库写入失败的情况。通常策略是：**以旧库成功为准**，新库写入失败可以只记录日志，后续通过数据校验修复，不影响主流程。
    2. **全量数据迁移：**
        * 与追日志方案相同，在双写逻辑上线后，开始将旧库的存量数据拷贝到新库。
    3. **数据一致性分析与校验：**
        * **理论上：** 全量迁移完成后，数据应该是一致的。因为在迁移过程中，任何对旧库的修改都会同步到新库。
        * **极限情况：** 文章中提到一个极限场景可能导致不一致（迁移工具刚读取某条数据 X -> 应用双删了 X -> 迁移工具将 X 写入新库，导致新库多一条数据）。
        * **实践上：** 无论理论如何，**数据校验是必不可少的最后防线**。校验方法同追日志方案。
    4. **流量切换：**
        * 校验数据完全一致后，将所有读流量切换到新库。
        * 确认新库稳定后，下线双写逻辑（只写新库），并最终下线旧库。
* **优点：**
    * **全程服务可用。**
    * **数据延迟低：** 增量数据是实时同步写入的，新库的数据状态非常接近旧库。
* **缺点：**
    * **应用代码侵入最严重：** 对业务逻辑的耦合最深，代码改造和后续清理的成本和风险都很大。
    * **性能开销：** 每次写操作都变成了两次数据库写入，对应用响应时间和数据库负载都有影响。

### 2.4. 关键工程实践深度解析 (对话精华)

1. **高效数据校验的实现：分块+校验和 (Chunking + Checksum)**
    * **问题：** 如何在不影响性能的情况下，校验百亿级动态数据的正确性？
    * **方案：**
        1. **分块 (Chunking):** 将表按主键（或其他有序索引）切分为固定大小的数据块，如每 1000-5000 条记录一块。
        2. **计算校验和 (Checksum):** 对每个数据块，在源库和目标库上分别执行聚合哈希计算。

            ```sql
            -- 精确计算一个数据块的哈希值
            SELECT
                MD5( -- 3. 使用 MD5/SHA1 生成最终的、定长的校验和
                    GROUP_CONCAT( -- 2. 将块内所有行的内容拼接成一个长字符串
                        CONCAT_WS(':', id, name, email, updated_at) -- 1. 用分隔符拼接单行所有关键字段
                        ORDER BY id -- 关键：必须排序，保证拼接顺序一致
                    )
                ) AS chunk_hash
            FROM users WHERE id BETWEEN 1 AND 1000;
            ```

        3. **对比与修复：** 校验工具只对比两个库返回的 `chunk_hash`。**仅当哈希值不一致时**，才启动详细对比模式，逐行比对该数据块，并以旧库为准，生成修复 SQL 来修正新库的数据。
2. **优雅的最终流量切换：应用层流量拦截**
    * **问题：** 文章提到的“秒级 readonly”会造成线上错误，如何避免？
    * **方案：** 将“硬中断”（锁库）变为“软暂停”（应用层控制）。
        1. **技术选型：** **AOP (面向切面编程) + 动态配置中心 (如 Nacos, Apollo)**。
        2. **实现：**
            * 定义一个切面（Aspect），拦截所有被特定注解（如 `@WriteOperation`）标记的数据库写操作方法。
            * 切面逻辑会实时监听配置中心的一个开关（如 `migration.write.paused`）。
            * **切换流程：**
                a. 在配置中心将开关置为 `true`。
                b. 所有新的写请求被切面拦截，不再执行，而是立即返回一个友好提示（如 HTTP 503 "Service Unavailable" 或自定义错误码）。
                c. 等待已在途中的、最后的增量数据同步完成（通常是毫秒级）。
                d. 在应用层或网关层，将所有流量的数据库连接指向**新库**。
                e. 在配置中心将开关置为 `false`，新库开始接收并处理写请求。
    * **优势：** 对业务代码**零侵入**，控制精准，影响时间极短，用户体验更佳。

## 3. 第三部分：现代终极方案 - 基于 CDC 的数据迁移 (The "Modern How")

这是业界最先进、最可靠的方案，核心是**将迁移逻辑与业务应用彻底解耦**。

### 3.1. 核心原理：变更数据捕获 (Change Data Capture - CDC)

* **思想：** 不再通过改造应用来记录变更，而是直接订阅并解析数据库自身的事务日志（如 MySQL 的 Binlog），从中提取数据变更事件。
* **优势：** **对业务应用完全零侵入**。无论业务如何复杂，应用代码一行都不用改。

### 3.2. Flink CDC：流批一体的自动化引擎

Flink CDC 是将 CDC 思想发扬光大的集大成者，它将复杂的迁移流程封装成了一个统一、自动化的 Flink 作业。

* **核心特性：流批一体 (Stream-Batch Unification)**
    * **一个作业，两个阶段：** 当你提交一个 Flink CDC 作业时，它会自动执行：
        1. **全量快照阶段 (Snapshot Phase):** 首先，它会并行地、高效地读取源表的**所有存量数据**（初始数据）。
        2. **增量捕获阶段 (Incremental Phase):** 当全量数据读取完毕后，作业**不会停止**，而是**无缝切换**到读取 Binlog 的模式，开始实时捕获所有后续的**增量变更**。
    * **一致性保证：** Flink 的检查点（Checkpoint）机制保证了从全量到增量的切换过程，以及整个运行过程中的**端到端精确一次（Exactly-Once）**语义，即使发生故障也能从上次的状态恢复，确保数据不重不漏。
* **如何应对复杂场景？** Flink 是一个强大的**数据处理引擎**，而不仅仅是搬运工。
    * **处理结构变更 (Schema Evolution):**
        在 Flink SQL 中，通过 `SELECT` 子句的丰富函数和表达式，可以轻松完成字段的映射、转换、新增和删除。
        
        ```sql
        -- 从旧结构 source_users 读取，转换后写入新结构 sink_users_v2
        INSERT INTO sink_users_v2
        SELECT
            id AS user_id,              -- 字段重命名
            UPPER(name) AS username,    -- 字段值转换
            email,                      -- 字段直通
            PROCTIME() AS create_time   -- 新增处理时间字段
        FROM source_users;
        ```

    * **处理多节点扩容/分片 (Sharding/Routing):**
        * Flink 提供了强大的路由能力，可以将一条数据流根据其内容分发到不同的目标（Sink）。
        * **简单路由：** 使用 `WHERE` 子句和多个 `INSERT` 语句。
        * **复杂路由：** 使用更底层的 DataStream API 和自定义 Sink，可以为每一条数据动态计算其目标表或目标库，实现任意复杂的分片逻辑。

## 4. 最终结论与方案演进路径

| 方案 | 核心原理 | 优点 | 缺点/代价 |
| :--- | :--- | :--- | :--- |
| **停机迁移** | 静态数据拷贝 | 逻辑简单，一致性天然保证 | **服务中断**，高压操作窗口 |
| **追日志方案** | 应用层记录主键，后台任务追平 | 服务可用，迁移过程从容 | **侵入应用代码**，架构复杂，有延迟 |
| **双写方案** | 应用层同步写入新旧两库 | 服务可用，数据延迟低 | **严重侵入应用代码**，性能开销，逻辑复杂 |
| **Flink CDC 方案** | **订阅数据库日志，流批一体处理** | **对应用零侵入**，一致性保障强，自动化程度高，能处理复杂转换和路由 | 需要引入 Flink 和相关组件，有一定学习和运维成本 |

**演进路径总结：**
数据迁移技术的发展，本质上是一个不断**将复杂性从业务应用中剥离出来**的过程。从最原始的**停机**，到侵入业务的**双写/追日志**，再到最终与业务彻底解耦的 **CDC 方案**，尤其是以 **Flink CDC** 为代表的流批一体引擎，为大规模、不停服、高可靠的数据迁移提供了当前最完善和优雅的解决方案。