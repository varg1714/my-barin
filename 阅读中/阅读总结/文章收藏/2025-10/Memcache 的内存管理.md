---
source:
  - "[[内存管理都不会，还做什么架构师？（第 105 讲，万字收藏）]]"
create: 2025-10-21
---

## 1. 第一部分：基础特性 (知其然)

Memcache 是一个高性能的分布式内存对象缓存系统，其核心特性架构师必须掌握：

* **核心职能**: 高性能的 KV 内存管理。
* **功能限制**:
    * Value 最大存储为 1MB。
    * 不支持复杂数据结构（如 Redis 的哈希、列表等）。
    * 不支持数据持久化。
* **核心优势**:
    * 支持 Key 过期。
    * 通过 Slab 内存分配机制，持续运行很少出现内存碎片，性能稳定。
    * 采用**非阻塞 IO 复用网络模型**和**监听/工作线程**的多线程模型，吞吐量高。

## 2. 第二部分：设计原理 (知其所以然)

理解其设计背后的“为什么”至关重要。

* **为何不支持复杂数据结构与持久化？**
    * **设计目标**: 其诞生初衷是“以服务的方式管理 KV 内存”，专注于解决分布式环境下的内存共享问题，而非提供功能丰富的数据库或缓存服务。
* **Key 过期如何实现？**
    * **懒淘汰 (Lazy Expiration)**: 不主动检查，而是在 `get` 操作时检查 item 的时间戳，若已过期则删除并返回 miss。
* **为何能避免内存碎片，保证性能？**
    * **提前分配内存 (Slab Allocator)**: 启动时预先申请大块内存，并按固定大小切分成 `chunk` 进行管理，用空间换取时间和性能的稳定性。
* **为何使用“监听/工作线程”模型？**
    * **目的**: 充分利用多核 CPU，提高并发处理能力和吞吐量。虽然会引入一些锁冲突，但对于提升整体性能来说收益远大于成本。

## 3. 第三部分：内核实现细节 (How)

### 3.1. 内存管理：Slab Allocator

这是 Memcache 内存管理的核心，旨在杜绝**外部内存碎片**。

* **核心概念**:
    * **Chunk**: 分配给用户的最小内存单元，大小固定。
    * **Slab**: 管理一组相同大小 `chunk` 的单元。Memcache 由多个 Slab 组成，分别管理不同尺寸的 `chunk`（如 128B, 256B, 512B...）。
    * **Item**: 用户存储的 KV 数据，最终存放在一个 `chunk` 中。
* **分配流程**:
    1. 当用户要存储一个 100B 的 `item` 时，系统会寻找能容纳它的最小 `slab`，即管理 128B `chunk` 的 `slab`。
    2. 从该 `slab` 的空闲 `chunk` 列表 (`free_chunk_list`) 中取出一个 128B 的 `chunk`。
    3. 将 100B 的 `item` 存入，剩余的 28B 空间被**浪费**，不再使用。

    ![Slab 分配示意图](https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOziah8wuTSoJjck4YRwtibCPSD9ib9KRo7gMZHIY8DwhwIPKltPiaofqnE9NryeK08GFw5w1aWxTNGlTQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=2)

* **避免外部碎片的原理**:
    * 内存碎片通常分为两种：**外部碎片**（内存中存在大量不连续的小空闲块，导致大块内存申请失败）和**内部碎片**（已分配的内存块中未被利用的部分）。
    * Memcache 的策略是**接受内部碎片以杜绝外部碎片**。上述例子中浪费的 28B 就是内部碎片。
    * 因为 `chunk` 的回收是**整块回收**，所以内存池中永远不会出现奇奇怪怪的小空洞，所有空闲空间都是规整的、可立即重用的 `chunk`。这保证了服务不会因长时间运行导致内存“千疮百孔”而性能下降，所以文中说“理论上不会出现内存碎片”。
* **内存淘汰：LRU (Least Recently Used)**
    * **触发时机**: 当某个 `slab` 的所有 `chunk` 都被用完时。
    * **淘汰策略**: 即使 `item` 设置为永久有效，也可能被淘汰。系统会通过 LRU 算法，找到该 `slab` 中“最近最少被使用”的 `item`，将其所在的 `chunk` 释放，用于存储新的 `item`。

### 3.2. 快速查找与扩容：哈希表

* **基本结构**: 使用标准的**哈希表 + 链表**结构来解决哈希冲突，实现 Key 的快速查找。
* **扩容机制 (Rehash)**:
    * **触发条件**: 当 `item` 总数达到哈希表长度的 1.5 倍时，启动扩容。
    * **迁移策略**: 由一个专门的后台线程执行，采用“分段迁移”策略，避免长时间锁住整个服务。
        1. **加锁**: 迁移线程会锁定 **旧哈希表** 中的一个桶（bucket）。
        2. **迁移**: 将该桶链表上的所有 `item` 重新计算哈希值，并放入新哈希表中。
        3. **解锁**: 完成后解锁该桶，然后处理下一个桶，直至全部迁移完毕。
    * **扩容期间的读写逻辑**:
        * 任何读写操作都会先根据 Key 计算出其在**旧表**中的桶位置。
        * 然后检查该桶的迁移状态：
            * **若该桶已迁移**：则直接去**新表**进行读写操作。
            * **若该桶未迁移**：则在**旧表**进行读写操作。
        * **核心优势**: 这种设计保证了任何时候一个 `item` 只可能存在于一个位置，**避免了需要查询两次（先查新表再查旧表）**，以最大化查询效率。

### 3.3. Key 过期机制：懒淘汰 (Lazy Expiration)

* **核心思想**: 不主动扫描，只在访问时检查。
* **实现**:
    1. `item` 结构中包含一个过期时间戳。
    2. 每次 `get` 请求时，先检查当前时间是否已超过该 `item` 的过期时间戳。
    3. 如果已过期，则释放该 `item` 占用的 `chunk`，并向客户端返回 `cache miss`。
* **优点**: 实现简单，资源消耗极低。

### 3.4. 网络模型：非阻塞 IO 复用与多线程

这是经典的高性能网络服务模型，通常指 **Reactor 模式** 的一种实现。

* **非阻塞 IO 复用**: 指使用 `epoll` (Linux) 或 `kqueue` (BSD) 等技术，让一个线程能同时监控大量网络连接（socket）的 IO 事件（如可读、可写），而无需为每个连接创建一个线程。
* **监听线程 (Listener/Master Thread)**:
    * **唯一职责**: 监听服务器端口，接受 (`accept()`) 新的客户端连接。
    * **分发**: 接受新连接后，通过轮询等策略将这个连接的 socket **分发**给一个工作线程去处理。
* **工作线程 (Worker Threads)**:
    * 通常有多个，数量与 CPU 核心数相关。
    * 每个工作线程内部都运行一个独立的**事件循环 (Event Loop)**，管理着一部分客户端连接。
    * 负责处理连接上的所有业务逻辑：读取请求、解析命令、操作数据、发送响应。
* **优势**: 既利用了 IO 复用的高并发特性，又通过多线程充分压榨了多核 CPU 的性能，实现了极高的吞吐量。