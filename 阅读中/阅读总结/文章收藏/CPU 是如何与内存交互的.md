---
source: "[[阅读中/文章列表/文章收藏/CPU 是如何与内存交互的]]"
create: 2025-09-16
---

## 1. 学习笔记：CPU 与内存交互的全景解析

这份笔记总结了从物理硬件（CPU Cache）到操作系统抽象（虚拟内存）的完整流程，解释了计算机系统如何高效、安全地管理和访问数据。

### 1.1. 基础：物理层面的速度差异 (CPU Cache)

* **核心矛盾**：CPU 的处理速度远超主存 (DRAM) 的读写速度。如果 CPU 每次都直接等待主存，性能将极其低下。
* **解决方案**：在 CPU 和主存之间加入多层高速缓存 (Cache)，由更快的 SRAM 实现。
    * **层级结构**：L1, L2, L3。L1 最快最小，离核心最近；L3 最慢最大，多核心共享。
    * **数据一致性**：在多核系统中，为保证各核心 Cache 中共享数据的一致性，采用了 **MESI 协议**。通过标记缓存行状态（修改 M、独占 E、共享 S、失效 I），并通过“写失效”广播机制来维护数据同步。

### 1.2. 抽象：虚拟内存 (Virtual Memory)

为了更高效、更安全地管理内存，操作系统引入了虚拟内存这一核心抽象。程序不再直接操作物理地址，而是操作虚拟地址。

**为什么需要虚拟内存？**

1.  **高效利用内存**
    无需将整个程序加载到物理内存，只需加载当前活跃的部分，使得小内存也能运行大程序。
2.  **内存隔离与保护**
    为每个进程提供独立的、连续的虚拟地址空间，防止进程间相互干扰。通过页表中的权限位（读/写/执行）提供硬件级别的安全保护。
3.  **简化内存管理**
    为程序员和链接器提供了简洁的内存模型。连续的虚拟页可以映射到不连续的物理页帧上，简化了内存分配。
4.  **共享内存**
    不同进程的虚拟地址可以映射到同一个物理页帧，实现高效的内存共享。

### 1.3. 核心机制：分页与页表 (Paging & Page Tables)

虚拟地址到物理地址的转换由 **内存管理单元 (MMU)** 硬件完成，其核心数据结构就是**页表 (Page Table)**。

* **基本原理**
    * 将虚拟地址空间和物理地址空间都划分为固定大小的块。
    * 虚拟地址空间的块称为 **页 (Page)**。
    * 物理地址空间的块称为 **页帧 (Page Frame)**。
    * **页表** 的作用就是记录 **虚拟页** 到 **物理页帧** 的映射关系。
* **地址结构**：一个虚拟地址被拆分为两部分：
    * **虚拟页号 (VPN)**：用作页表的**索引**，以找到对应的页表项 (PTE)。
    * **页内偏移 (Offset)**：指明数据在目标物理页帧内的具体位置。

页表与数据来源：页表的核心职责是建立 **虚拟页** 到 **物理页帧** 的映射，它本身并不关心物理页帧中的数据来源。根据数据来源的不同，内存页主要分为两类：

*  **文件支持页 (File-Backed Pages)**
    这类页的数据来自磁盘上的一个具体文件，例如程序的可执行代码、动态链接库（DLL）等。它们的“后备存储”就是磁盘上对应的源文件。
*  **匿名页 (Anonymous Pages)**
    这类页没有对应的磁盘文件，专门用于存放程序运行时动态产生的数据，例如程序在堆（Heap）上创建的数组、对象或是在栈（Stack）上使用的变量。
    *  **创建过程**
        当程序需要一块新的动态内存时（例如创建一个数组），操作系统会找到一个空闲的物理页帧，然后在页表中建立虚拟页到这个新页帧的映射。程序随后就可以直接向这块物理内存中写入数据。

        然后，它会再次修改页表里 `VP_A` 对应的 PTE：

        - **存在位 (Present Bit):** 设置为 `0` (表示数据已不在物理内存中)。
        - **在原本存储 PFN 的位置，现在记录数据在交换文件中的位置**。

        之后当程序再次访问这块内存区域时，会发现数据不在物理内存中，此时会触发缺页中断重新将其加载到物理内存中。

    *  **换出机制** 
        由于匿名页在磁盘上没有“家”，当物理内存不足需要将其换出时，操作系统会把它写入一个被称为 **交换文件 (Swap File)** 或 **页面文件 (Page File)** 的特殊磁盘空间中。

因此，页表中的 **存在位 (Present Bit)** 标志着一个虚拟页当前是否存在于物理内存中。如果不存在，其数据要么在其原始的后备文件里，要么就在交换文件里。

### 1.4. 实践挑战与解决方案：多级页表

* **单级页表的问题（以 32 位系统为例）**
    * **前提**：32 位地址空间 ($2^{32}$ B = 4 GB)，页面大小 4 KB ($2^{12}$ B)，页表项 (PTE) 大小 4 字节。
    * **计算过程**：
        1.  **页面总数** = 总地址空间 / 页面大小 = $2^{32} / 2^{12} = 2^{20}$ (约 100 万个页面)。
        2.  **页表总大小** = 页面总数 $\times$ PTE 大小 = $2^{20} \times 4 \text{ B} = 4 \text{ MB}$。
    * **问题**：每个进程都需要一个 4MB **连续的**物理内存来存放页表，即使程序本身很小，也造成了巨大的空间浪费。
* **解决方案：多级页表 (Multi-Level Page Tables)**
    * **核心思想**：“为页表建立页表”，将巨大的线性页表进行再次“分页”。
    * **32 位系统 (二级页表)**：
        * 将 4MB 的页表分割成 1024 个 4KB 的**二级页表**。
        * 创建一个 4KB 的**一级页表**（页目录），它有 1024 个条目，每个条目指向一个二级页表。
        * **虚拟地址拆分**：原来的 20 位 VPN 被拆分为两级索引。
            | 10 位 (一级索引) | 10 位 (二级索引) | 12 位 (偏移) |
    * **64 位系统 (四级页表)**：
        * 这是为 64 位架构（通常使用 48 位虚拟地址）设计的。
        * **虚拟地址拆分**：
            | 9 位 (L4) | 9 位 (L3) | 9 位 (L2) | 9 位 (L1) | 12 位 (偏移) |
        * 每一级的页表大小都巧妙地设计为 4KB ($2^9 \text{ 条目} \times 8 \text{ B/条目} = 4\text{KB}$)。

### 1.5. 深入细节：页表项 (PTE) 的结构

一个常见的误区是将虚拟地址和页表项混淆。**虚拟地址是查找的“钥匙”，而页表项是存储在页表中的“记录”**。

* **PTE 的内容**：它不仅包含地址信息，还包含控制位。
* **空间优化**：PTE 存储的不是完整的物理地址，而是**物理页帧号 (PFN)**。
    * 由于物理页帧地址总是页面大小（如 4KB）的整数倍，其地址的低 12 位永远是 0。
    * 因此，在 32 位 PTE 中，只需存储高 20 位的 PFN，剩下的 **12 位**就可以用来存储**标志位/控制位 (Flags)**。
* **PTE 结构 (32 位)**：
    | 20 位 (物理页帧号 - PFN) | 12 位 (标志位 - Flags) |
* **重要标志位**：
    * **Present (P) 位**：页面是否在物理内存中（否则触发缺页异常）。
    * **Read/Write (R/W) 位**：页面权限（只读或可读写）。
    * **User/Supervisor (U/S) 位**：用户模式/内核模式访问权限。
    * **Accessed (A) 位 / Dirty (D) 位**：用于页面替换算法（如 LRU）。

### 1.6. 性能加速器：TLB (Translation Lookaside Buffer)

* **性能瓶颈**：多级页表虽然节省了空间，但每次地址转换都需要多次访问内存（例如四级页表需要 4 次），这非常慢。
* **解决方案**：引入一个高速硬件缓存 **TLB**，专门缓存最近使用过的地址转换映射。
    * **缓存内容**：`{ 虚拟页号 (VPN) : 物理页帧号 (PFN) + 标志位 }`
* **工作流程**：
    1.  **TLB 命中 (Hit)**：CPU 直接从 TLB 获取 PFN，无需访问内存中的页表。这是**快速路径**，绝大多数情况都走这里。
    2.  **TLB 未命中 (Miss)**：CPU 必须执行完整的、缓慢的多级页表遍历（**慢速路径**）。找到映射关系后，会将其**存入 TLB**，以便下次快速访问。

### 1.7. 最终总结：一次内存访问的完整旅程

1.  CPU 生成一个**虚拟地址**。
2.  MMU 首先在 **TLB** 中查找该地址的虚拟页号 (VPN)。
3.  **如果 TLB 命中**，MMU 立即得到物理页帧号 (PFN)，与页内偏移量组合成**物理地址**。
4.  **如果 TLB 未命中**，MMU 开始遍历**多级页表**：
    * 从 CR3 寄存器获取一级页表基地址。
    * 使用虚拟地址的不同部分作为索引，逐级查找，直到找到最终的 PTE。
    * 从 PTE 中解析出 PFN 和权限位，并**将此映射关系存入 TLB**。
    * 与页内偏移量组合成**物理地址**。
5.  MMU 将**物理地址**发送给 **CPU Cache 系统**。
6.  Cache 系统检查 L1, L2, L3 是否有该地址的数据。
7.  **如果 Cache 命中**，数据被快速返回给 CPU。
8.  **如果 Cache 未命中**，才从**主存 (DRAM)** 中获取数据，并将其加载到 Cache 中，最后返回给 CPU。