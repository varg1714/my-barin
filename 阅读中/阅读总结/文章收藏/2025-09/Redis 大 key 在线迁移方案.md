---
source: "[[哈罗面试：有个 redis 大 key 需要在线优化_ 不能影响现有业务， 怎么优化？]]"
create: 2025-09-12
---

## 1. 文章核心内容分析

### 1.1. 什么是 Big Key？

文章首先明确了 Big Key 的定义：并非指 Key 本身大，而是指 **Key 对应的 Value 过大**。这包括两种情况：

* **单个 Value 体积过大**：例如一个 String 类型的 Key，其 Value 达到了 5MB。
* **集合类型成员过多**：例如一个 Hash、List 或 ZSET 类型的 Key，其成员数量达到上万个。

### 1.2. Big Key 的成因与危害

文章分析了 Big Key 产生的常见场景，如数据结构使用不当、垃圾数据未清理、业务预估不足以及热点事件（如网红粉丝列表）等。其主要危害包括：

* **阻塞请求**：Redis 是单线程模型，操作 Big Key 会耗费较长时间，阻塞后续请求。
* **内存增大**：可能引发 OOM (内存溢出) 或导致重要 Key 被内存淘汰策略逐出。
* **网络阻塞**：读取 Big Key 会占用大量网络带宽。
* **影响主从同步**：删除一个巨大的 Key 可能导致主库长时间阻塞，影响主从同步。

### 1.3. 在线优化方案（核心）

这是文章的重点，提供了一个六步走的平滑迁移方案，确保在优化过程中不影响线上业务：

| 步骤                   | 操作                                                                                       | 关键点                                                                                    |
| :------------------- | :--------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------- |
| **Step 1: 大 Key 拆分** | 将一个大 Key（如 `user:info:all`）按业务逻辑（如用户 ID 哈希）拆分成多个小 Key（如 `user:info:0` 到 `user:info:99`）。 | 这是解决问题的根本思路，化整为零。                                                                      |
| **Step 2: 同步双写**   | 修改应用代码，在执行写操作时，同时写入新 Key 和老 Key。                                                         | 保证在迁移过程中，新老数据的一致性，为后续切换做准备。                                                            |
| **Step 3: 渐进式迁移**  | 编写后台脚本，使用 `HSCAN` 命令分批次、小批量地将老 Key 中的数据迁移到对应的新 Key 中。                                    | **强调不能使用 `HGETALL`**，因为它会一次性加载所有数据，导致 Redis 阻塞。`HSCAN` 可以无阻塞地迭代数据。                     |
| **Step 4: 灰度切换**   | 数据迁移完成后，通过配置中心等方式，逐步将读请求从老 Key 切换到新 Key（例如，从 10% 流量开始，逐步增加到 100%）。                       | 包含**兜底设计**：当新 Key 查询不到时，先查老 Key，再查数据库，防止缓存穿透。                                          |
| **Step 5: 非阻塞删除**  | 确认所有读写流量都已切换到新 Key 后，使用 `UNLINK` 命令异步删除老 Key。                                            | **强调不能使用 `DEL`**，因为它会同步阻塞 Redis。对于特别巨大的 Key，甚至可以先用 `HSCAN` + `HDEL` 分批清空内容，最后再删除空 Key。 |
| **Step 6: 监控与回滚**  | 在整个过程中，实时监控 Redis 性能指标和业务指标，并准备好回滚预案（如通过配置中心一键切回老 Key）。                                  | 确保整个过程的安全可控。                                                                           |

### 1.4. 双写过程的数据一致性

双写过程中可能产生**并发冲突**：

* **写路径 A (线上双写)**：用户更新信息，应用层代码同时写入 `老 Key` 和 `新 Key`。
* **写路径 B (后台迁移)**：后台脚本从 `老 Key` 读取一批数据，然后写入 `新 Key`。

**冲突场景示例：**
1. **T1 时刻**：用户 A 更新了自己的信息。应用层通过“双写”逻辑，将用户 A 的**新数据**写入了 `新 Key` 中。
2. **T2 时刻**：后台迁移任务正好扫描到 `老 Key` 中用户 A 的**旧数据**。
3. **T3 时刻**：后台迁移任务将用户 A 的**旧数据**写入 `新 Key`，覆盖了 T1 时刻写入的**新数据**。

**结果**：数据不一致，最新的用户数据丢失了。

为了解决这个问题，确保最终数据的一致性，我们必须在写入 `新 Key` 时引入一个**冲突解决机制**。

#### 1.4.1. 版本号或时间戳机制 (最严谨)

这是最经典、最可靠的解决分布式系统数据一致性的方法。

**核心思想**：为每一份数据增加一个版本号或者最后更新的时间戳。在写入时，遵循“**只接受比当前版本更新的数据**”的原则。

**具体实施步骤：**

1. **改造数据结构**：在存储的用户信息 `info` 中增加一个字段，比如 `update_time` (时间戳) 或 `version` (版本号)。

    ```json
    {
      "name": "张三",
      "age": 30,
      "update_time": 1678886400000 
    }
    ```

2. **改造双写逻辑**：应用在执行更新操作时，生成当前的服务器时间戳，并将其与业务数据一同写入 `老 Key` 和 `新 Key`。
3. **改造迁移逻辑**：后台迁移脚本在从 `老 Key` 读取数据时，会一并读出 `update_time`。
4. **实现原子性的“比较并更新”**：这是最关键的一步。无论是“双写”还是“迁移”，在向 `新 Key` 写入数据时，都不能直接使用 `HSET`。而是需要执行一个原子操作，该操作包含以下逻辑：
    * 获取 `新 Key` 中该 `uid` 已有的数据。
    * 比较已有数据的时间戳和待写入数据的时间戳。
    * **只有当待写入数据的时间戳 > 已有数据的时间戳时，才执行写入操作。**

    由于 `GET` + `SET` 并非原子操作，在高并发下会出问题。因此，必须使用 **Redis Lua 脚本** 来保证这个“比较并更新”逻辑的原子性。

**Lua 脚本伪代码示例：**

```lua
-- KEYS[1]: 新的 hash key，例如 "user:info:10"
-- ARGV[1]: 用户 uid
-- ARGV[2]: 待写入的包含时间戳的 JSON 字符串
-- ARGV[3]: 待写入数据的时间戳

local existing_json = redis.call('HGET', KEYS[1], ARGV[1])

-- 如果新 Key 中还没有这个用户的数据，直接写入
if not existing_json then
  redis.call('HSET', KEYS[1], ARGV[1], ARGV[2])
  return 1
end

-- 解析已存在数据的时间戳
-- (实际实现中需要一个 JSON 解析库或在存入时将时间戳单独存)
local existing_ts = parse_timestamp_from_json(existing_json) 

-- 如果待写入数据的时间戳更大，则覆盖
if tonumber(ARGV[3]) > tonumber(existing_ts) then
  redis.call('HSET', KEYS[1], ARGV[1], ARGV[2])
  return 1
end

-- 否则，不执行任何操作
return 0
```

通过这种方式，无论是线上双写还是后台迁移，写入 `新 Key` 时都会经过 Lua 脚本的仲裁，旧数据永远无法覆盖新数据。

#### 1.4.2. 利用 `HSETNX` 的简化逻辑 (较简单)

如果业务场景可以接受“**迁移脚本不覆盖任何已存在于新 Key 的数据**”，那么可以采用一个更简单的策略。

**核心思想**：线上双写逻辑拥有绝对的写入优先权，而后台迁移只负责“填补空白”。

**具体实施步骤：**

1. **线上双写逻辑**：使用常规的 `HSET` 命令。这确保了用户的实时更新总能成功写入 `新 Key`，无论 `新 Key` 中是否有旧数据。

    ```java
    // 线上双写，强制覆盖
    redis.hset(newKey, uid.toString(), JSON.toJSONString(info));
    ```

2. **后台迁移逻辑**：使用 `HSETNX` (Set if Not Exists) 命令。这个命令只在 `field` (即 `uid`) 不存在时才会设置值。

    ```python
    # 后台迁移，如果 uid 已存在则不操作
    pipe.hsetnx(shard_key, uid, info)
    ```

**这种方式如何保证一致性？**

* **场景 1：线上更新先发生**
    1. 用户更新 -> `HSET` 写入 `新 Key`。
    2. 迁移脚本运行 -> `HSETNX` 尝试写入，但发现 `uid` 已存在，操作失败。
    3. **结果**：`新 Key` 中保留的是最新的数据。

* **场景 2：迁移先发生**
    1. 迁移脚本运行 -> `HSETNX` 写入旧数据到 `新 Key`。
    2. 用户更新 -> `HSET` 写入新数据，覆盖了 `新 Key` 中的旧数据。
    3. **结果**：`新 Key` 中最终保留的是最新的数据。

这种方案的优点是实现简单，无需修改数据结构，也无需使用 Lua 脚本。缺点是它假设了迁移开始后，所有在 `老 Key` 中的数据都比线上实时写入的数据要“旧”，这在绝大多数场景下是成立的。

#### 1.4.3. 总结与建议

| 方案 | 优点 | 缺点 | 适用场景 |
| :--- | :--- | :--- | :--- |
| **版本号/时间戳 + Lua** | 逻辑最严谨，数据绝对一致，无惧任何并发顺序。 | 实现稍复杂，需要改造数据结构和使用 Lua 脚本。 | 对数据一致性要求极高的金融、交易等场景。 |
| **`HSETNX` 简化逻辑** | 实现简单，无需改动数据结构，性能好。 | 逻辑上依赖“线上写”覆盖“迁移写”，严谨性略低于方案一。 | 大部分业务场景，如用户信息、帖子列表等，这种方案已足够可靠且易于实施。 |

## 2. 总结

这篇文章不仅回答了一个面试题，更提供了一套在生产环境中处理类似问题的成熟解决方案。其核心思想是 **“拆分、双写、渐进、灰度、监控”**，通过一系列精细化的操作，将一个高风险的变更过程分解为多个低风险、可控、可回滚的步骤，最终实现对 Redis 大 Key 的平滑、无感优化。

文章中反复强调**避免使用阻塞性命令**（如 `HGETALL`, `DEL`）并采用其非阻塞替代方案（如 `HSCAN`, `UNLINK`），这是 Redis 运维中的一个重要实践原则。