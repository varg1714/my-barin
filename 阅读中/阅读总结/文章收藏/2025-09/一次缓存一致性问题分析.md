---
source: "[[奇怪的缓存一致性问题]]"
create: 2025-09-15
---

这篇文章通过一个阿里天猫国际用户 Push 中心的真实案例，深入探讨了分布式系统中的缓存一致性问题。文章分为理论回顾、问题排查和解决方案三个部分。

## 1. 核心问题概述

系统在高并发场景下，出现查询投放计划（plan）为 `null` 的异常。经过排查，根本原因是在一个读写分离的架构中，由于不恰当的缓存更新策略，导致了数据不一致。

## 2. 系统架构与问题根源

文章中描述的系统分为两个独立的应用：

*   **配置端 (Configuration End):** 负责对投放计划（pushPlan）进行增、删、改操作。
*   **投放端 (Delivery End):** 负责高并发的查询操作，为了性能，使用了**二级缓存**（本地缓存 + Tair/Redis）。

**问题的根源在于：**
1.  **架构分离：** 配置端和投放端是两个独立的应用，各自有独立的缓存和数据库连接。
2.  **缓存更新策略不当：** 配置端采用“**先删缓存，再更新数据库**”的策略。
3.  **时序问题（Race Condition）：**
    *   配置端的一个定时任务（每 5 分钟）会更新数据。它首先**删除 Tair 缓存**。
    *   在配置端更新完数据库、且投放端的定时任务刷新 Tair 缓存**之前**，存在一个时间窗口。
    *   在这个窗口期内，投放端的请求会先查询本地缓存（可能已过期），然后查询 Tair 缓存，发现 Tair 中没有数据（已被配置端删除），于是返回 `null`，导致异常。


## 3. 理论知识回顾（八股文）

文章首先回顾了缓存相关的经典问题，为后续案例分析做铺垫：

*   **缓存三大问题：**
    *   **缓存穿透：** 查询不存在的数据，导致请求绕过缓存直接打到数据库。解决方案是**布隆过滤器**或**缓存空结果**。
    *   **缓存击穿：** 单个热点 Key 过期，大量并发请求瞬间打到数据库。解决方案是**热点数据永不过期**或**加锁/队列**。
    *   **缓存雪崩：** 大量 Key 同时集中过期，导致请求全部涌向数据库。解决方案是**过期时间加随机值**、**高可用缓存架构**等。
*   **数据一致性模型：**
    *   **实时强一致性：** 任何时刻所有客户端看到的数据都一样，适用于银行等金融系统。
    *   **最终一致性：** 系统保证在一段时间后数据最终会达到一致，适用于社交网络等对实时性要求不高的场景。
*   **缓存更新/失效策略：**
    *   **更新策略：** 直写缓存 (Write through)、写回缓存 (Write back)、绕写缓存 (Write around)。
    *   **失效策略：** 主动更新、定时失效、惰性加载。

## 4. 解决方案探讨

文章提出了两种解决方案：

**方案一：修改配置端（推荐）**
*   **核心思想：** 将“先删缓存”改为“**双写方案**”，即写完数据库后，**立即刷新缓存**。
*   **优点：** 这种方式可以有效避免因删除缓存导致的数据空窗期。
*   **延伸讨论：** 文章还详细对比了四种缓存与数据库更新策略的优缺点：
    *   先更新数据库，再更新缓存（推荐，一致性强）
    *   先更新缓存，再更新数据库（不推荐，数据库更新失败会导致长期不一致）
    *   先删缓存，再更新数据库（本文原方案，有窗口期问题）
    *   延时双删策略（“先删缓存，再更新数据库”的改良版，但实现复杂）

**方案二：修改投放端（存在问题）**
*   **核心思想：** 当投放端在 Tair 中未命中缓存时，主动去查询数据库并刷新 Tair。
*   **问题：** 这种方案在并发场景下依然可能导致数据不一致。例如，配置端删除了缓存，投放端查询后将旧数据写回了缓存，随后配置端才完成数据库更新，导致缓存中一直是旧数据。

## 5. 结论

文章的最终结论是：**不存在绝对最优的缓存一致性方案，只有最适合业务场景的方案。**

在设计系统时，需要综合考虑**系统性能、系统复杂度、业务对数据一致性的容忍度**等多个因素。强一致性虽然数据最准确，但通常会牺牲性能和增加系统复杂度。很多业务场景下，可以接受最终一致性。因此，选择合适的策略才是最优解。