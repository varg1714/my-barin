---
source:
  - "[[一文解析得物自建 Redis 最新技术演进]]"
create: 2025-11-24
---

## 1. 总体概况

这篇文章详细阐述了得物技术团队在过去三年中，如何将其自建 Redis 平台从基础建设阶段推向成熟化、规模化和自动化的过程。

* **规模背景**：管理 1000+ 集群，160T 内存，10W+ 节点，单集群 QPS 近千万。这属于中大型互联网公司的典型基础设施规模。
* **核心目标**：提升性能、降低成本、提高稳定性（SLA）以及提升运维效率。

## 2. 核心技术演进分析

### 2.1. 接入层架构变革：从 LB 到 SDK (DRedis)

这是该文章中最显著的架构升级点。

* **背景痛点**：早期使用传统的“域名 + LB（负载均衡）”方式，虽然对业务透明且兼容性好，但面临 LB 带宽瓶颈（单 LB 5Gb 上限）、网络攻击风险以及摘流延迟问题。
* **解决方案**：自研 DRedis SDK（支持 Java/Golang/C++）。
* **分析**：
    * **优势**：去中心化，消除了 LB 这一单点瓶颈；支持更灵活的路由策略（如“同可用区优先”）；客户端直连 Proxy 减少了一次网络跳转，降低了 RT（响应时间）。
    * **权衡**：引入了**富客户端（Rich Client）**模式。这意味着基础设施团队需要维护多语言版本的 SDK，且业务方升级 SDK 存在推广成本。一旦 SDK 出现 Bug，影响范围可能较广。

### 2.2. 高可用与容灾：同城双活与就近读

* **策略**：采用“中心写、就近读”方案。
* **技术难点**：在容器化部署 Proxy 的环境下，传统的 Service 难以实现精细的同区路由。
* **创新点**：利用 DRedis SDK 的能力，在客户端层面识别并优先连接同可用区的 Proxy，Proxy 再优先连接同区的 Server。
* **一致性挑战**：Redis 主从复制是异步的，就近读（读从库）可能读到旧数据。
* **应对措施**：得物提供了兜底方案，允许业务通过注解（`@NearRead`）或特定 API 强制指定是否开启就近读，或者通过 Key/前缀配置白名单。这是一种在**性能（低延迟）**与**一致性**之间务实的折衷处理。

### 2.3. Redis 内核定制与优化

得物并没有盲目追随社区最新版本，而是采取了“实用主义”的内核维护策略。

* **版本策略**：主力维护 4.0 和 6.2。
* **Feature Backport（特性回移植）**：将 Redis 6.x 的**多线程 IO** 能力移植回 Redis 4.0。
    * **分析**：这是一个高技术含量的决策。升级数千个集群的大版本风险极高，通过修改源码将新特性引入旧版本，既享受了性能红利（QPS 提升明显），又避免了大规模迁移的风险。
* **水平扩容优化**：实现了异步数据迁移，将扩容时间从 4 小时缩短至 10 分钟。这解决了 Redis 大集群运维中最大的痛点之一（扩容慢、影响业务 RT）。

### 2.4. 资源调度与自动化运维

* **混合部署**：Proxy（CPU 密集型）与 Server（内存密集型）混合部署。
    * **分析**：这是极佳的成本优化手段，充分利用了服务器的物理资源，避免了资源浪费。
* **全生命周期自动化**：从申请、部署、扩缩容到下线、故障自愈（Watchdog 拉起）均实现了自动化。
    * **分析**：对于管理 10W+ 节点的规模，自动化不是“锦上添花”而是“刚需”。特别是“闲置资源自动回收”和“垂直自动扩容”，直接关联到公司的 IT 成本控制。

## 3. 潜在挑战与盲点（客观审视）

虽然文章展示了成功的演进，但从行业角度看，仍有一些潜在的挑战或文章未提及的部分：

1. **SDK 绑定的长期维护成本**：
    * 文章提到支持 Java、Golang 和即将上线的 C++。随着公司技术栈的演进（如引入 Rust 或 Node.js），维护多语言 SDK 的一致性和功能同步将是一个持续的重投入。
    * 富客户端模式下，SDK 的升级覆盖率通常是一个运维难题。

2. **Proxy 的性能开销**：
    * 虽然 Proxy 提供了限流、路由等高级功能，但它增加了一层处理逻辑。文章未详细对比直连 Redis Cluster 与经过 Proxy 的延迟损耗（虽然 SDK 直连 Proxy 比经过 LB 快，但理论上仍慢于直连 Server）。

3. **强一致性场景的复杂性**：
    * 虽然提供了注解来控制就近读，但这将“判断是否需要强一致性”的责任推给了业务开发人员。在复杂的业务逻辑中，开发人员可能会误用，导致数据不一致问题。

4. **云原生化程度**：
    * 文章提到 Proxy + Server 混部在 ECS 上，而为了就近读才在容器环境部署 Proxy。这显示其 Redis 核心存储层可能仍主要依赖虚拟机（ECS），而非完全的 K8s 容器化（StatefulSet 等）。这在资源隔离和调度灵活性上可能不如完全容器化方案，但稳定性可能更高。

## 4. 总结

得物自建 Redis 的演进路线是一条**非常标准且成熟的互联网大厂中间件演进路径**：

1. **初期**：利用开源 + LB 快速搭建。
2. **中期**：遇到性能和管理瓶颈，开始自研 SDK 和管控平台。
3. **成熟期**：深入内核定制（多线程、异步迁移），精细化成本控制（混部），以及针对多活场景的高级路由策略。

**结论**：这篇文章证明了得物在基础架构领域具备较强的自研能力和工程化落地能力，特别是在解决大规模集群的**运维效率**和**成本控制**方面，其方案具有很高的行业参考价值。