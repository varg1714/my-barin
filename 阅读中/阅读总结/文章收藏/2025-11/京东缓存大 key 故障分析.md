---
source:
  - "[[真实案例解析缓存大热 key 的致命陷阱]]"
create: 2025-11-02
---

## 1. 背景与架构

* **场景**: 双十一大促期间，一个包含大量规则和奖励的“大型活动”上线。
* **架构**: 系统采用二级缓存来提升性能。
    * L1 Cache: 本地 JVM 缓存 (Caffeine/Guava Cache)，缓存 5 分钟。
    * L2 Cache: Redis 分布式缓存。
* **问题**: 该“大型活动”对象序列化后体积巨大（1.5M），构成了一个典型的**大 key**。

## 2. 事故现象

* 活动上线瞬间，系统核心 UMP 监控可用率由 100% 持续下降到 20%。
* 访问 Redis 的调用次数和查询性能断崖式下降。
* 产生连锁反应，影响其他核心接口，最终导致整个系统服务不可用。

## 3. 根本原因分析：两大陷阱的叠加效应

### 3.1. 陷阱一：缓存击穿 (Cache Breakdown)

* **定义**: 在高并发下，一个热点 key 恰好在缓存中失效，导致所有请求都直接穿透缓存，打到下一级存储（本文中是 Redis），造成其瞬时压力剧增。
* **事发过程**: 活动上线时，运营人员将活动数据写入 Redis，但此时所有应用服务器的**本地 JVM 缓存都是空的**。因此，海量用户的请求全部穿透了本地缓存，同时涌向 Redis 请求同一个大热 key。

### 3.2. 陷阱二：网络带宽瓶颈 (Network Bandwidth Bottleneck)

* **被忽略的瓶颈**: 团队预料到了大 key 和热 key，但忽略了**网络 I/O** 也是一个关键瓶颈，而不仅仅是 Redis 的 CPU 和内存。
* **致命计算**:
    * 大 key 体积: **1.5 MB**
    * Redis 单分片网络带宽限制: **200 Mbps** (兆比特每秒)
    * 并发上限: `200 Mbps / (1.5 MB * 8 bits/byte) = 200 / 12 ≈ 16.6` 次/秒。原文作者计算为 133 次，可能是对带宽的理解或单位换算有差异，但结论一致：**极少的并发请求就能瞬间打满网络带宽**。
* **雪崩过程**: 缓存击穿导致的高并发请求，瞬间占满了 Redis 服务器的网卡带宽。这使得 Redis 线程被阻塞在网络 I/O 上，无法处理包括其他 key 在内的任何请求，最终引发了更大范围的**缓存雪崩**。

## 4. 解决方案与优化措施

1. **大 key 治理 (更换序列化方式)**
    * **措施**: 将序列化方式由 JSON 调整为 **Protostuff**。
    * **效果**: 缓存对象大小由 **1.5M 减少到 0.5M (500k)**。Protostuff 作为二进制序列化方案，相比文本格式的 JSON，极大地减少了括号、引号、字段名等结构性开销。

2. **数据压缩 (Gzip)**
    * **措施**: 在将 Protostuff 序列化后的二进制数据存入 Redis 前，使用 Gzip 算法进行压缩。
    * **效果**: 缓存大小由 **500k 进一步压缩到 17k**。

3. **缓存回源优化 (防击穿)**
    * **措施**: 在本地缓存 miss 后，回源查询 Redis 的逻辑上增加**线程锁**（例如 `ReentrantLock` 或使用 `Caffeine` 自带的 `get(key, mappingFunction)` 原子加载机制）。
    * **效果**: 确保在同一 JVM 进程中，同一时间只有一个线程能去回源 Redis，其他线程等待结果。这从根本上解决了缓存击穿问题。

4. **监控和优化 Redis 配置**
    * **措施**: 定期监控 Redis 的网络传输情况，并根据业务实际情况调整限流配置。

## 5. 深入探讨与关键启示

### 5.1. 关于超高压缩比 (500k -> 17k) 的思考

这个接近 30:1 的压缩比是完全可能的，其背后原理是：

* **序列化 ≠ 压缩**:
    * **Protostuff (序列化)**: 优化的是**数据结构**的表达方式，将文本格式变为紧凑的二进制格式，减少了 `{}` `""` `fieldName` 等元数据开销。
    * **Gzip (压缩)**: 优化的是**数据内容**的冗余性，通过查找并替换重复的字节序列来减小体积。
* **内容高度冗余**: 文中“大型活动”包含“非常多的活动条件和活动奖励”，这意味着 Protostuff 序列化后的 500k 二进制数据中，存在大量重复内容：
    * **重复的字符串**: 如 "满 100 减 10"、"新人专享" 等文案。
    * **重复的结构**: 大量优惠券、奖励品的对象结构和大部分字段值可能完全相同。
    * **稀疏数据**: 大量字段为 `0`、`null`、`false` 等默认值。
    Gzip 算法正是利用了这种内容上的高度重复性，从而实现了惊人的压缩效果。

### 5.2. 总结与启示

1. **大 Key + 热 Key 是定时炸弹**: 必须在设计阶段就极力避免。如果无法避免，必须进行专项优化。
2. **网络是常被忽视的瓶颈**: 在评估系统性能时，除了 CPU 和内存，必须将网络 I/O 考虑在内，尤其是在处理大对象时。
3. **缓存击穿威力巨大**: 对于可预期的热点数据，务必使用**锁机制**或**原子加载**来防止缓存击穿。
4. **序列化和压缩是两把独立的利器**: 在追求极致性能时，可以组合使用。先用高效序列化（Protostuff/Kryo）减小结构开销，再用压缩算法（Gzip/Snappy/Zstd）消除内容冗余。
5. **预防大于治疗**: 在系统设计阶段充分考虑缓存策略，并在上线前进行充分的**压力测试**和性能评估，是避免线上事故的最佳途径。