---
source: https://mp.weixin.qq.com/s/8NSXj7kslBVG-12B4RY8Xw
create: 2025-11-03 11:33
read: true
knowledge: true
knowledge-date: 2025-11-03
tags:
  - 系统架构
summary: "[[大批量数据的定时任务优化]]"
---
《架构师之路：架构设计中的 100 个知识点》

109. 定时任务执行时间优化

  

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/YrezxckhYOzic5gelsmNiadVLFYPa0FtVD0jhJHj4klTic5R5OM32FpxdWSKV5dxXkL5VxXX6CAwsgVmsRwYib445Q/640?wx_fmt=jpeg#imgIndex=0)

这次回答星球内粉丝的提问。  
  
**问题抽象**：

1. 用户会员系统；

2. 用户会有分数流水，每个月要做一次分数统计，对不同分数等级的会员做不同业务处理；

  

**数据假设**：

![](https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOzCzozehdhicnKcexqjicMpUy2pVBJuvqqJibsCV9dqTCps55JBcGtMv8jmGMrHOCY0JNrGOWfLH35iaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=1)

1. 假设**用户**在 100w 级别；

2. 假设**用户日均** 1 条流水，也就是说日增流水数据量在 100W 级别，月新增流水在 3kW 级别，**3 个月流水数据量**在亿级别；

**常见解决方案**：

用一个定时任务，每个月的第一天计算一次。

```
_//(1) 查询出所有用户_

_uids[] = select uid from t_user;_

_//(2) 遍历每个用户_

_foreach $uid in uids[]{_

 _//(3) 查询用户 3 个月内分数流水_

 _scores[]= select score from t_flow_

 _where uid=$uid and time=[3 个月内];_

 _//(4) 遍历分数流水_

 _foreach $score in scores[]{_

 _//(5) 计算总分数_

 _sum+= $score;_

 _}_

 _//(6) 根据分数做业务处理_

 _switch(sum)_

 _升级降级，发优惠券，发奖励;_

_}_
```


**一个月执行一次的定时任务，会存在什么问题？**

计算量很大，处理的数据量很大，耗时很久，按照水友的说法，需要 1-2 天。

_画外音：外层循环 100W 级别用户；内层循环 9kW 级别流水；业务处理需要 10 几次数据库交互。_

**可不可以多线程并行处理？**

可以，每个用户的流水处理不耦合。

**改为多线程并行处理，例如按照用户拆分，会存在什么问题？**

每个线程都要访问数据库做业务处理，数据库有可能扛不住。

  

这类问题的**优化方向**是什么？

1. 同一份数据，减少重复计算次数；

2. 分摊 CPU 计算时间，尽量分散处理，而不是集中处理；

3. 减少单次计算数据量；

  

**如何减少同一份数据，重复计算次数？**

![](https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOzCzozehdhicnKcexqjicMpUy0dJibSyjGLTDFxrBCw7laVIpMML4hib2VB0G5Ce1Mq9Wbbib1S8Kp5faw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=2)

如上图，假设每一个方格是 1 个月的分数流水数据（约 3kW）。

3 月底计算时，要查询并计算 1 月，2 月，3 月三个月的 9kW 数据；

4 月底计算时，要查询并计算 2 月，3 月，4 月三个月的 9kW 数据；

…

会发现，2 月和 3 月的数据（粉色部分），被重复查询和计算了多次。  
_画外音：__该业务，每个月的数据会被计算 3 次。_

**新增**月积分流水汇总表，每次**只计算当月增量**：

_flow_month_sum(month, uid, flow_sum)_

1. 每到月底，只计算当月分数，数据量减少到 1/3，耗时也减少到 1/3；

2. 同时，把前 2 个月流水加和，就能得到最近 3 个月总分数（这个动作几乎不花时间）；

_画外音：该表的数量级和用户表数据量一致，100w 级别。_

这样一来，每条分数流水只会被计算一次。

  

**如何分摊 CPU 计算时间，减少单次计算数据量呢？**

业务需求是一个月重新计算一次分数，但一个月集中计算，数据量太大，耗时太久，可以将计算分摊到每天。

![](https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOzCzozehdhicnKcexqjicMpUyCMTkWHW75ic53YcCjUWvxdc3ABWSsPCtYrn3AuqoyOm9gxbHJUCJRbg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=3)

如上图，月积分流水汇总表，升级为，日积分流水汇总表。  

  

把每月 1 次集中计算，分摊为 30 次分散计算，每次计算数据量减少到 1/30，就只需要花几十分钟处理了。

  

甚至，每一个小时计算一次，每次计算数据量又能减少到 1/24，每次就只需要花几分钟处理了。

**虽然时间缩短了，但毕竟是定时任务，****能不能实时计算****分数流水呢？**

每天只新增 100w 分数流水，完全可以实时累加计算 “日积分流水汇总”。

![](https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOzCzozehdhicnKcexqjicMpUynNePy50Hj74iaOVU94iacTlvhSfBlicpCziaeqNbmDCliaTVzAD6icbEgv0A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=4)

使用 DTS(或者 canal) 增加一个分数流水表的监听，当用户的分数变化时，**实时**进行日分数流水累加，将 1 小时一次的定时任务计算，均匀分摊到 “每时每刻”，每天新增 100w 流水，数据库写压力每秒钟 10 多次，完全扛得住。

_画外音：如果不能使用 DTS/canal，可以使用 MQ。_

**总结**，对于这类一次性集中处理大量数据的定时任务，优化思路是：

1. 同一份数据，减少重复计算次数；

2. 分摊 CPU 计算时间，尽量分散处理（甚至可以实时），而不是集中处理；

3. 减少单次计算数据量；

大数据量定时任务执行时间优化，你学废了吗？

知其然，知其所以然。

**思路比结论更重要。**

== 全文完 ==

有架构合集吗？

合集一：《[流量从 10 万到 10 亿，一定会遇到的 80 个架构问题（8000 字长文）](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651974945&idx=1&sn=58ff54415ddf2dd52d03f47a6790344b&scene=21#wechat_redirect)》

画外音：从理论到实践，15 年架构师生涯的系统性总结。

合集二：《[关于即时通讯架构的一切！](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651975468&idx=1&sn=54ab265bee4998da9a0d32091699cb1d&scene=21#wechat_redirect)》

画外音：职业生涯前 5 年，都在做 IM 架构。

如何提问？

加入免费星球，一起技术交流。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/YrezxckhYOyHicSCibf68mt4pGa2pPmkZNbq2icyf4jsbKwnJJrtlH2sg6nZdy37BC6IaYlNJbu9iahHWBmDrOib6XQ/640?wx_fmt=jpeg&from=appmsg&randomid=g1weg7nk&wxfrom=5&wx_lazy=1&tp=webp#imgIndex=17)

欢迎预约直播：技术人的副业规划（完结篇）！

欢迎预约！